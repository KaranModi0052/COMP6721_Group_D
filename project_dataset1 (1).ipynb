{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLE6OPz6k516",
        "outputId": "1df3a142-8fb4-4e11-e9b3-7ee18d740558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as td\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import time"
      ],
      "metadata": {
        "id": "0cEF16PPnDig"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "def load_data(path,batch_size,input_size):\n",
        "    \n",
        "    normalize = transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ]) \n",
        "    transform_dict = {\"src\":  normalize}  \n",
        "    # train_path=path+\"/train\"\n",
        "    # test_path=path+\"/test\"\n",
        "    data = datasets.ImageFolder(root=path,transform=transform_dict[\"src\"])\n",
        "    # transform_dict1 = {\"test\":  normalize} \n",
        "    # test1 = datasets.ImageFolder(root=path,transform=transform_dict[\"test\"])\n",
        "    # transform_dict = {\"test\":  normalize}\n",
        "    # test= datasets.ImageFolder(root=path,transform=transform_dict[\"test\"])\n",
        "    # train_size = int((1- (test_split + val_split)) * len(data))\n",
        "    # test_size = int((1 - (val_split)) * len(data)) - train_size\n",
        "    # val_size = len(data) - train_size - test_size\n",
        "    train_size=int(0.75*len(data))\n",
        "    print(len(data))\n",
        "    test_size=int(len(data)-train_size)\n",
        "    train, test = td.random_split(data,[train_size,test_size])\n",
        "\n",
        "    data_loader_train = td.DataLoader(train,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    data_loader_test = td.DataLoader(test,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    # data_loader_val = td.DataLoader(val,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    return data_loader_train, data_loader_test"
      ],
      "metadata": {
        "id": "MyA9Qi8ynEnB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader_train,data_loader_test=load_data(r\"/content/gdrive/MyDrive/Colab Notebooks/Dataset1\",32,40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqSXf6JmJscK",
        "outputId": "6529e4c0-15b6-4f3e-e71d-d0f99e3261a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader_train.dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpU1i46EJ30T",
        "outputId": "b01c0882-87ca-4450-eb3c-363a35c5d0d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7f92c3558290>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        \n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        \n",
        "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        \n",
        "        #downsample if needed\n",
        "        if self.i_downsample is not None:\n",
        "            identity = self.i_downsample(identity)\n",
        "        #add identity\n",
        "        x+=identity\n",
        "        x=self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "N7sfZMPEKloN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "       \n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x.clone()\n",
        "\n",
        "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
        "      x = self.batch_norm2(self.conv2(x))\n",
        "\n",
        "      if self.i_downsample is not None:\n",
        "          identity = self.i_downsample(identity)\n",
        "      print(x.shape)\n",
        "      print(identity.shape)\n",
        "      x += identity\n",
        "      x = self.relu(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "1gNyUZOgKpY6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
        "        \n",
        "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
        "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
        "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
        "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
        "        ii_downsample = None\n",
        "        layers = []\n",
        "        \n",
        "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
        "            ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "            \n",
        "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
        "        self.in_channels = planes*ResBlock.expansion\n",
        "        \n",
        "        for i in range(blocks-1):\n",
        "            layers.append(ResBlock(self.in_channels, planes))\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "        \n",
        "        \n",
        "def ResNet50(num_classes, channels=3):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)\n",
        "    \n",
        "def ResNet101(num_classes, channels=3):\n",
        "    return ResNet(Bottleneck, [3,4,23,3], num_classes, channels)\n",
        "\n",
        "def ResNet152(num_classes, channels=3):\n",
        "    return ResNet(Bottleneck, [3,8,36,3], num_classes, channels)"
      ],
      "metadata": {
        "id": "lysX4QsSKrA_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "net = ResNet50(4).to('cuda')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
      ],
      "metadata": {
        "id": "yZIM8KPaKsrV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### Define and run your training loop here #########\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "net.to(device)\n",
        "\n",
        "num_epochs = 1\n",
        "total_steps = len(data_loader_train)\n",
        "t1 = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(data_loader_train):\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # Forward pass\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        print(\"kjnfjnrnkrn\",i)\n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(\"second time\",i)\n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            \n",
        "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwJjJwGVKwlG",
        "outputId": "3d135ab3-652d-4f0d-ccba-3daeeae28f3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "kjnfjnrnkrn 0\n",
            "second time 0\n",
            "kjnfjnrnkrn 1\n",
            "second time 1\n",
            "kjnfjnrnkrn 2\n",
            "second time 2\n",
            "kjnfjnrnkrn 3\n",
            "second time 3\n",
            "kjnfjnrnkrn 4\n",
            "second time 4\n",
            "kjnfjnrnkrn 5\n",
            "second time 5\n",
            "kjnfjnrnkrn 6\n",
            "second time 6\n",
            "kjnfjnrnkrn 7\n",
            "second time 7\n",
            "kjnfjnrnkrn 8\n",
            "second time 8\n",
            "kjnfjnrnkrn 9\n",
            "second time 9\n",
            "Epoch [1/1], Step [10/497], Loss: 1.2612, Accuracy: 59.38%\n",
            "kjnfjnrnkrn 10\n",
            "second time 10\n",
            "kjnfjnrnkrn 11\n",
            "second time 11\n",
            "kjnfjnrnkrn 12\n",
            "second time 12\n",
            "kjnfjnrnkrn 13\n",
            "second time 13\n",
            "kjnfjnrnkrn 14\n",
            "second time 14\n",
            "kjnfjnrnkrn 15\n",
            "second time 15\n",
            "kjnfjnrnkrn 16\n",
            "second time 16\n",
            "kjnfjnrnkrn 17\n",
            "second time 17\n",
            "kjnfjnrnkrn 18\n",
            "second time 18\n",
            "kjnfjnrnkrn 19\n",
            "second time 19\n",
            "Epoch [1/1], Step [20/497], Loss: 1.2624, Accuracy: 46.88%\n",
            "kjnfjnrnkrn 20\n",
            "second time 20\n",
            "kjnfjnrnkrn 21\n",
            "second time 21\n",
            "kjnfjnrnkrn 22\n",
            "second time 22\n",
            "kjnfjnrnkrn 23\n",
            "second time 23\n",
            "kjnfjnrnkrn 24\n",
            "second time 24\n",
            "kjnfjnrnkrn 25\n",
            "second time 25\n",
            "kjnfjnrnkrn 26\n",
            "second time 26\n",
            "kjnfjnrnkrn 27\n",
            "second time 27\n",
            "kjnfjnrnkrn 28\n",
            "second time 28\n",
            "kjnfjnrnkrn 29\n",
            "second time 29\n",
            "Epoch [1/1], Step [30/497], Loss: 1.2635, Accuracy: 59.38%\n",
            "kjnfjnrnkrn 30\n",
            "second time 30\n",
            "kjnfjnrnkrn 31\n",
            "second time 31\n",
            "kjnfjnrnkrn 32\n",
            "second time 32\n",
            "kjnfjnrnkrn 33\n",
            "second time 33\n",
            "kjnfjnrnkrn 34\n",
            "second time 34\n",
            "kjnfjnrnkrn 35\n",
            "second time 35\n",
            "kjnfjnrnkrn 36\n",
            "second time 36\n",
            "kjnfjnrnkrn 37\n",
            "second time 37\n",
            "kjnfjnrnkrn 38\n",
            "second time 38\n",
            "kjnfjnrnkrn 39\n",
            "second time 39\n",
            "Epoch [1/1], Step [40/497], Loss: 1.2911, Accuracy: 43.75%\n",
            "kjnfjnrnkrn 40\n",
            "second time 40\n",
            "kjnfjnrnkrn 41\n",
            "second time 41\n",
            "kjnfjnrnkrn 42\n",
            "second time 42\n",
            "kjnfjnrnkrn 43\n",
            "second time 43\n",
            "kjnfjnrnkrn 44\n",
            "second time 44\n",
            "kjnfjnrnkrn 45\n",
            "second time 45\n",
            "kjnfjnrnkrn 46\n",
            "second time 46\n",
            "kjnfjnrnkrn 47\n",
            "second time 47\n",
            "kjnfjnrnkrn 48\n",
            "second time 48\n",
            "kjnfjnrnkrn 49\n",
            "second time 49\n",
            "Epoch [1/1], Step [50/497], Loss: 1.2790, Accuracy: 56.25%\n",
            "kjnfjnrnkrn 50\n",
            "second time 50\n",
            "kjnfjnrnkrn 51\n",
            "second time 51\n",
            "kjnfjnrnkrn 52\n",
            "second time 52\n",
            "kjnfjnrnkrn 53\n",
            "second time 53\n",
            "kjnfjnrnkrn 54\n",
            "second time 54\n",
            "kjnfjnrnkrn 55\n",
            "second time 55\n",
            "kjnfjnrnkrn 56\n",
            "second time 56\n",
            "kjnfjnrnkrn 57\n",
            "second time 57\n",
            "kjnfjnrnkrn 58\n",
            "second time 58\n",
            "kjnfjnrnkrn 59\n",
            "second time 59\n",
            "Epoch [1/1], Step [60/497], Loss: 1.2740, Accuracy: 53.12%\n",
            "kjnfjnrnkrn 60\n",
            "second time 60\n",
            "kjnfjnrnkrn 61\n",
            "second time 61\n",
            "kjnfjnrnkrn 62\n",
            "second time 62\n",
            "kjnfjnrnkrn 63\n",
            "second time 63\n",
            "kjnfjnrnkrn 64\n",
            "second time 64\n",
            "kjnfjnrnkrn 65\n",
            "second time 65\n",
            "kjnfjnrnkrn 66\n",
            "second time 66\n",
            "kjnfjnrnkrn 67\n",
            "second time 67\n",
            "kjnfjnrnkrn 68\n",
            "second time 68\n",
            "kjnfjnrnkrn 69\n",
            "second time 69\n",
            "Epoch [1/1], Step [70/497], Loss: 1.2707, Accuracy: 50.00%\n",
            "kjnfjnrnkrn 70\n",
            "second time 70\n",
            "kjnfjnrnkrn 71\n",
            "second time 71\n",
            "kjnfjnrnkrn 72\n",
            "second time 72\n",
            "kjnfjnrnkrn 73\n",
            "second time 73\n",
            "kjnfjnrnkrn 74\n",
            "second time 74\n",
            "kjnfjnrnkrn 75\n",
            "second time 75\n",
            "kjnfjnrnkrn 76\n",
            "second time 76\n",
            "kjnfjnrnkrn 77\n",
            "second time 77\n",
            "kjnfjnrnkrn 78\n",
            "second time 78\n",
            "kjnfjnrnkrn 79\n",
            "second time 79\n",
            "Epoch [1/1], Step [80/497], Loss: 1.1895, Accuracy: 68.75%\n",
            "kjnfjnrnkrn 80\n",
            "second time 80\n",
            "kjnfjnrnkrn 81\n",
            "second time 81\n",
            "kjnfjnrnkrn 82\n",
            "second time 82\n",
            "kjnfjnrnkrn 83\n",
            "second time 83\n",
            "kjnfjnrnkrn 84\n",
            "second time 84\n",
            "kjnfjnrnkrn 85\n",
            "second time 85\n",
            "kjnfjnrnkrn 86\n",
            "second time 86\n",
            "kjnfjnrnkrn 87\n",
            "second time 87\n",
            "kjnfjnrnkrn 88\n",
            "second time 88\n",
            "kjnfjnrnkrn 89\n",
            "second time 89\n",
            "Epoch [1/1], Step [90/497], Loss: 1.3034, Accuracy: 37.50%\n",
            "kjnfjnrnkrn 90\n",
            "second time 90\n",
            "kjnfjnrnkrn 91\n",
            "second time 91\n",
            "kjnfjnrnkrn 92\n",
            "second time 92\n",
            "kjnfjnrnkrn 93\n",
            "second time 93\n",
            "kjnfjnrnkrn 94\n",
            "second time 94\n",
            "kjnfjnrnkrn 95\n",
            "second time 95\n",
            "kjnfjnrnkrn 96\n",
            "second time 96\n",
            "kjnfjnrnkrn 97\n",
            "second time 97\n",
            "kjnfjnrnkrn 98\n",
            "second time 98\n",
            "kjnfjnrnkrn 99\n",
            "second time 99\n",
            "Epoch [1/1], Step [100/497], Loss: 1.2621, Accuracy: 53.12%\n",
            "kjnfjnrnkrn 100\n",
            "second time 100\n",
            "kjnfjnrnkrn 101\n",
            "second time 101\n",
            "kjnfjnrnkrn 102\n",
            "second time 102\n",
            "kjnfjnrnkrn 103\n",
            "second time 103\n",
            "kjnfjnrnkrn 104\n",
            "second time 104\n",
            "kjnfjnrnkrn 105\n",
            "second time 105\n",
            "kjnfjnrnkrn 106\n",
            "second time 106\n",
            "kjnfjnrnkrn 107\n",
            "second time 107\n",
            "kjnfjnrnkrn 108\n",
            "second time 108\n",
            "kjnfjnrnkrn 109\n",
            "second time 109\n",
            "Epoch [1/1], Step [110/497], Loss: 1.3069, Accuracy: 43.75%\n",
            "kjnfjnrnkrn 110\n",
            "second time 110\n",
            "kjnfjnrnkrn 111\n",
            "second time 111\n",
            "kjnfjnrnkrn 112\n",
            "second time 112\n",
            "kjnfjnrnkrn 113\n",
            "second time 113\n",
            "kjnfjnrnkrn 114\n",
            "second time 114\n",
            "kjnfjnrnkrn 115\n",
            "second time 115\n",
            "kjnfjnrnkrn 116\n",
            "second time 116\n",
            "kjnfjnrnkrn 117\n",
            "second time 117\n",
            "kjnfjnrnkrn 118\n",
            "second time 118\n",
            "kjnfjnrnkrn 119\n",
            "second time 119\n",
            "Epoch [1/1], Step [120/497], Loss: 1.3222, Accuracy: 40.62%\n",
            "kjnfjnrnkrn 120\n",
            "second time 120\n",
            "kjnfjnrnkrn 121\n",
            "second time 121\n",
            "kjnfjnrnkrn 122\n",
            "second time 122\n",
            "kjnfjnrnkrn 123\n",
            "second time 123\n",
            "kjnfjnrnkrn 124\n",
            "second time 124\n",
            "kjnfjnrnkrn 125\n",
            "second time 125\n",
            "kjnfjnrnkrn 126\n",
            "second time 126\n",
            "kjnfjnrnkrn 127\n",
            "second time 127\n",
            "kjnfjnrnkrn 128\n",
            "second time 128\n",
            "kjnfjnrnkrn 129\n",
            "second time 129\n",
            "Epoch [1/1], Step [130/497], Loss: 1.3066, Accuracy: 18.75%\n",
            "kjnfjnrnkrn 130\n",
            "second time 130\n",
            "kjnfjnrnkrn 131\n",
            "second time 131\n",
            "kjnfjnrnkrn 132\n",
            "second time 132\n",
            "kjnfjnrnkrn 133\n",
            "second time 133\n",
            "kjnfjnrnkrn 134\n",
            "second time 134\n",
            "kjnfjnrnkrn 135\n",
            "second time 135\n",
            "kjnfjnrnkrn 136\n",
            "second time 136\n",
            "kjnfjnrnkrn 137\n",
            "second time 137\n",
            "kjnfjnrnkrn 138\n",
            "second time 138\n",
            "kjnfjnrnkrn 139\n",
            "second time 139\n",
            "Epoch [1/1], Step [140/497], Loss: 1.2501, Accuracy: 50.00%\n",
            "kjnfjnrnkrn 140\n",
            "second time 140\n",
            "kjnfjnrnkrn 141\n",
            "second time 141\n",
            "kjnfjnrnkrn 142\n",
            "second time 142\n",
            "kjnfjnrnkrn 143\n",
            "second time 143\n",
            "kjnfjnrnkrn 144\n",
            "second time 144\n",
            "kjnfjnrnkrn 145\n",
            "second time 145\n",
            "kjnfjnrnkrn 146\n",
            "second time 146\n",
            "kjnfjnrnkrn 147\n",
            "second time 147\n",
            "kjnfjnrnkrn 148\n",
            "second time 148\n",
            "kjnfjnrnkrn 149\n",
            "second time 149\n",
            "Epoch [1/1], Step [150/497], Loss: 1.2848, Accuracy: 37.50%\n",
            "kjnfjnrnkrn 150\n",
            "second time 150\n",
            "kjnfjnrnkrn 151\n",
            "second time 151\n",
            "kjnfjnrnkrn 152\n",
            "second time 152\n",
            "kjnfjnrnkrn 153\n",
            "second time 153\n",
            "kjnfjnrnkrn 154\n",
            "second time 154\n",
            "kjnfjnrnkrn 155\n",
            "second time 155\n",
            "kjnfjnrnkrn 156\n",
            "second time 156\n",
            "kjnfjnrnkrn 157\n",
            "second time 157\n",
            "kjnfjnrnkrn 158\n",
            "second time 158\n",
            "kjnfjnrnkrn 159\n",
            "second time 159\n",
            "Epoch [1/1], Step [160/497], Loss: 1.2573, Accuracy: 40.62%\n",
            "kjnfjnrnkrn 160\n",
            "second time 160\n",
            "kjnfjnrnkrn 161\n",
            "second time 161\n",
            "kjnfjnrnkrn 162\n",
            "second time 162\n",
            "kjnfjnrnkrn 163\n",
            "second time 163\n",
            "kjnfjnrnkrn 164\n",
            "second time 164\n",
            "kjnfjnrnkrn 165\n",
            "second time 165\n",
            "kjnfjnrnkrn 166\n",
            "second time 166\n",
            "kjnfjnrnkrn 167\n",
            "second time 167\n",
            "kjnfjnrnkrn 168\n",
            "second time 168\n",
            "kjnfjnrnkrn 169\n",
            "second time 169\n",
            "Epoch [1/1], Step [170/497], Loss: 1.3330, Accuracy: 46.88%\n",
            "kjnfjnrnkrn 170\n",
            "second time 170\n",
            "kjnfjnrnkrn 171\n",
            "second time 171\n",
            "kjnfjnrnkrn 172\n",
            "second time 172\n",
            "kjnfjnrnkrn 173\n",
            "second time 173\n",
            "kjnfjnrnkrn 174\n",
            "second time 174\n",
            "kjnfjnrnkrn 175\n",
            "second time 175\n",
            "kjnfjnrnkrn 176\n",
            "second time 176\n",
            "kjnfjnrnkrn 177\n",
            "second time 177\n",
            "kjnfjnrnkrn 178\n",
            "second time 178\n",
            "kjnfjnrnkrn 179\n",
            "second time 179\n",
            "Epoch [1/1], Step [180/497], Loss: 1.2904, Accuracy: 43.75%\n",
            "kjnfjnrnkrn 180\n",
            "second time 180\n",
            "kjnfjnrnkrn 181\n",
            "second time 181\n",
            "kjnfjnrnkrn 182\n",
            "second time 182\n",
            "kjnfjnrnkrn 183\n",
            "second time 183\n",
            "kjnfjnrnkrn 184\n",
            "second time 184\n",
            "kjnfjnrnkrn 185\n",
            "second time 185\n",
            "kjnfjnrnkrn 186\n",
            "second time 186\n",
            "kjnfjnrnkrn 187\n",
            "second time 187\n",
            "kjnfjnrnkrn 188\n",
            "second time 188\n",
            "kjnfjnrnkrn 189\n",
            "second time 189\n",
            "Epoch [1/1], Step [190/497], Loss: 1.2351, Accuracy: 65.62%\n",
            "kjnfjnrnkrn 190\n",
            "second time 190\n",
            "kjnfjnrnkrn 191\n",
            "second time 191\n",
            "kjnfjnrnkrn 192\n",
            "second time 192\n",
            "kjnfjnrnkrn 193\n",
            "second time 193\n",
            "kjnfjnrnkrn 194\n",
            "second time 194\n",
            "kjnfjnrnkrn 195\n",
            "second time 195\n",
            "kjnfjnrnkrn 196\n",
            "second time 196\n",
            "kjnfjnrnkrn 197\n",
            "second time 197\n",
            "kjnfjnrnkrn 198\n",
            "second time 198\n",
            "kjnfjnrnkrn 199\n",
            "second time 199\n",
            "Epoch [1/1], Step [200/497], Loss: 1.3370, Accuracy: 40.62%\n",
            "kjnfjnrnkrn 200\n",
            "second time 200\n",
            "kjnfjnrnkrn 201\n",
            "second time 201\n",
            "kjnfjnrnkrn 202\n",
            "second time 202\n",
            "kjnfjnrnkrn 203\n",
            "second time 203\n",
            "kjnfjnrnkrn 204\n",
            "second time 204\n",
            "kjnfjnrnkrn 205\n",
            "second time 205\n",
            "kjnfjnrnkrn 206\n",
            "second time 206\n",
            "kjnfjnrnkrn 207\n",
            "second time 207\n",
            "kjnfjnrnkrn 208\n",
            "second time 208\n",
            "kjnfjnrnkrn 209\n",
            "second time 209\n",
            "Epoch [1/1], Step [210/497], Loss: 1.2824, Accuracy: 50.00%\n",
            "kjnfjnrnkrn 210\n",
            "second time 210\n",
            "kjnfjnrnkrn 211\n",
            "second time 211\n",
            "kjnfjnrnkrn 212\n",
            "second time 212\n",
            "kjnfjnrnkrn 213\n",
            "second time 213\n",
            "kjnfjnrnkrn 214\n",
            "second time 214\n",
            "kjnfjnrnkrn 215\n",
            "second time 215\n",
            "kjnfjnrnkrn 216\n",
            "second time 216\n",
            "kjnfjnrnkrn 217\n",
            "second time 217\n",
            "kjnfjnrnkrn 218\n",
            "second time 218\n",
            "kjnfjnrnkrn 219\n",
            "second time 219\n",
            "Epoch [1/1], Step [220/497], Loss: 1.3067, Accuracy: 40.62%\n",
            "kjnfjnrnkrn 220\n",
            "second time 220\n",
            "kjnfjnrnkrn 221\n",
            "second time 221\n",
            "kjnfjnrnkrn 222\n",
            "second time 222\n",
            "kjnfjnrnkrn 223\n",
            "second time 223\n",
            "kjnfjnrnkrn 224\n",
            "second time 224\n",
            "kjnfjnrnkrn 225\n",
            "second time 225\n",
            "kjnfjnrnkrn 226\n",
            "second time 226\n",
            "kjnfjnrnkrn 227\n",
            "second time 227\n",
            "kjnfjnrnkrn 228\n",
            "second time 228\n",
            "kjnfjnrnkrn 229\n",
            "second time 229\n",
            "Epoch [1/1], Step [230/497], Loss: 1.3368, Accuracy: 46.88%\n",
            "kjnfjnrnkrn 230\n",
            "second time 230\n",
            "kjnfjnrnkrn 231\n",
            "second time 231\n",
            "kjnfjnrnkrn 232\n",
            "second time 232\n",
            "kjnfjnrnkrn 233\n",
            "second time 233\n",
            "kjnfjnrnkrn 234\n",
            "second time 234\n",
            "kjnfjnrnkrn 235\n",
            "second time 235\n",
            "kjnfjnrnkrn 236\n",
            "second time 236\n",
            "kjnfjnrnkrn 237\n",
            "second time 237\n",
            "kjnfjnrnkrn 238\n",
            "second time 238\n",
            "kjnfjnrnkrn 239\n",
            "second time 239\n",
            "Epoch [1/1], Step [240/497], Loss: 1.1835, Accuracy: 65.62%\n",
            "kjnfjnrnkrn 240\n",
            "second time 240\n",
            "kjnfjnrnkrn 241\n",
            "second time 241\n",
            "kjnfjnrnkrn 242\n",
            "second time 242\n",
            "kjnfjnrnkrn 243\n",
            "second time 243\n",
            "kjnfjnrnkrn 244\n",
            "second time 244\n",
            "kjnfjnrnkrn 245\n",
            "second time 245\n",
            "kjnfjnrnkrn 246\n",
            "second time 246\n",
            "kjnfjnrnkrn 247\n",
            "second time 247\n",
            "kjnfjnrnkrn 248\n",
            "second time 248\n",
            "kjnfjnrnkrn 249\n",
            "second time 249\n",
            "Epoch [1/1], Step [250/497], Loss: 1.3148, Accuracy: 37.50%\n",
            "kjnfjnrnkrn 250\n",
            "second time 250\n",
            "kjnfjnrnkrn 251\n",
            "second time 251\n",
            "kjnfjnrnkrn 252\n",
            "second time 252\n",
            "kjnfjnrnkrn 253\n",
            "second time 253\n",
            "kjnfjnrnkrn 254\n",
            "second time 254\n",
            "kjnfjnrnkrn 255\n",
            "second time 255\n",
            "kjnfjnrnkrn 256\n",
            "second time 256\n",
            "kjnfjnrnkrn 257\n",
            "second time 257\n",
            "kjnfjnrnkrn 258\n",
            "second time 258\n",
            "kjnfjnrnkrn 259\n",
            "second time 259\n",
            "Epoch [1/1], Step [260/497], Loss: 1.2983, Accuracy: 43.75%\n",
            "kjnfjnrnkrn 260\n",
            "second time 260\n",
            "kjnfjnrnkrn 261\n",
            "second time 261\n",
            "kjnfjnrnkrn 262\n",
            "second time 262\n",
            "kjnfjnrnkrn 263\n",
            "second time 263\n",
            "kjnfjnrnkrn 264\n",
            "second time 264\n",
            "kjnfjnrnkrn 265\n",
            "second time 265\n",
            "kjnfjnrnkrn 266\n",
            "second time 266\n",
            "kjnfjnrnkrn 267\n",
            "second time 267\n",
            "kjnfjnrnkrn 268\n",
            "second time 268\n",
            "kjnfjnrnkrn 269\n",
            "second time 269\n",
            "Epoch [1/1], Step [270/497], Loss: 1.2179, Accuracy: 56.25%\n",
            "kjnfjnrnkrn 270\n",
            "second time 270\n",
            "kjnfjnrnkrn 271\n",
            "second time 271\n",
            "kjnfjnrnkrn 272\n",
            "second time 272\n",
            "kjnfjnrnkrn 273\n",
            "second time 273\n",
            "kjnfjnrnkrn 274\n",
            "second time 274\n",
            "kjnfjnrnkrn 275\n",
            "second time 275\n",
            "kjnfjnrnkrn 276\n",
            "second time 276\n",
            "kjnfjnrnkrn 277\n",
            "second time 277\n",
            "kjnfjnrnkrn 278\n",
            "second time 278\n",
            "kjnfjnrnkrn 279\n",
            "second time 279\n",
            "Epoch [1/1], Step [280/497], Loss: 1.2858, Accuracy: 50.00%\n",
            "kjnfjnrnkrn 280\n",
            "second time 280\n",
            "kjnfjnrnkrn 281\n",
            "second time 281\n",
            "kjnfjnrnkrn 282\n",
            "second time 282\n",
            "kjnfjnrnkrn 283\n",
            "second time 283\n",
            "kjnfjnrnkrn 284\n",
            "second time 284\n",
            "kjnfjnrnkrn 285\n",
            "second time 285\n",
            "kjnfjnrnkrn 286\n",
            "second time 286\n",
            "kjnfjnrnkrn 287\n",
            "second time 287\n",
            "kjnfjnrnkrn 288\n",
            "second time 288\n",
            "kjnfjnrnkrn 289\n",
            "second time 289\n",
            "Epoch [1/1], Step [290/497], Loss: 1.2381, Accuracy: 53.12%\n",
            "kjnfjnrnkrn 290\n",
            "second time 290\n",
            "kjnfjnrnkrn 291\n",
            "second time 291\n",
            "kjnfjnrnkrn 292\n",
            "second time 292\n",
            "kjnfjnrnkrn 293\n",
            "second time 293\n",
            "kjnfjnrnkrn 294\n",
            "second time 294\n",
            "kjnfjnrnkrn 295\n",
            "second time 295\n",
            "kjnfjnrnkrn 296\n",
            "second time 296\n",
            "kjnfjnrnkrn 297\n",
            "second time 297\n",
            "kjnfjnrnkrn 298\n",
            "second time 298\n",
            "kjnfjnrnkrn 299\n",
            "second time 299\n",
            "Epoch [1/1], Step [300/497], Loss: 1.2814, Accuracy: 50.00%\n",
            "kjnfjnrnkrn 300\n",
            "second time 300\n",
            "kjnfjnrnkrn 301\n",
            "second time 301\n",
            "kjnfjnrnkrn 302\n",
            "second time 302\n",
            "kjnfjnrnkrn 303\n",
            "second time 303\n",
            "kjnfjnrnkrn 304\n",
            "second time 304\n",
            "kjnfjnrnkrn 305\n",
            "second time 305\n",
            "kjnfjnrnkrn 306\n",
            "second time 306\n",
            "kjnfjnrnkrn 307\n",
            "second time 307\n",
            "kjnfjnrnkrn 308\n",
            "second time 308\n",
            "kjnfjnrnkrn 309\n",
            "second time 309\n",
            "Epoch [1/1], Step [310/497], Loss: 1.3393, Accuracy: 31.25%\n",
            "kjnfjnrnkrn 310\n",
            "second time 310\n",
            "kjnfjnrnkrn 311\n",
            "second time 311\n",
            "kjnfjnrnkrn 312\n",
            "second time 312\n",
            "kjnfjnrnkrn 313\n",
            "second time 313\n",
            "kjnfjnrnkrn 314\n",
            "second time 314\n",
            "kjnfjnrnkrn 315\n",
            "second time 315\n",
            "kjnfjnrnkrn 316\n",
            "second time 316\n",
            "kjnfjnrnkrn 317\n",
            "second time 317\n",
            "kjnfjnrnkrn 318\n",
            "second time 318\n",
            "kjnfjnrnkrn 319\n",
            "second time 319\n",
            "Epoch [1/1], Step [320/497], Loss: 1.2307, Accuracy: 53.12%\n",
            "kjnfjnrnkrn 320\n",
            "second time 320\n",
            "kjnfjnrnkrn 321\n",
            "second time 321\n",
            "kjnfjnrnkrn 322\n",
            "second time 322\n",
            "kjnfjnrnkrn 323\n",
            "second time 323\n",
            "kjnfjnrnkrn 324\n",
            "second time 324\n",
            "kjnfjnrnkrn 325\n",
            "second time 325\n",
            "kjnfjnrnkrn 326\n",
            "second time 326\n",
            "kjnfjnrnkrn 327\n",
            "second time 327\n",
            "kjnfjnrnkrn 328\n",
            "second time 328\n",
            "kjnfjnrnkrn 329\n",
            "second time 329\n",
            "Epoch [1/1], Step [330/497], Loss: 1.1950, Accuracy: 71.88%\n",
            "kjnfjnrnkrn 330\n",
            "second time 330\n",
            "kjnfjnrnkrn 331\n",
            "second time 331\n",
            "kjnfjnrnkrn 332\n",
            "second time 332\n",
            "kjnfjnrnkrn 333\n",
            "second time 333\n",
            "kjnfjnrnkrn 334\n",
            "second time 334\n",
            "kjnfjnrnkrn 335\n",
            "second time 335\n",
            "kjnfjnrnkrn 336\n",
            "second time 336\n",
            "kjnfjnrnkrn 337\n",
            "second time 337\n",
            "kjnfjnrnkrn 338\n",
            "second time 338\n",
            "kjnfjnrnkrn 339\n",
            "second time 339\n",
            "Epoch [1/1], Step [340/497], Loss: 1.3438, Accuracy: 43.75%\n",
            "kjnfjnrnkrn 340\n",
            "second time 340\n",
            "kjnfjnrnkrn 341\n",
            "second time 341\n",
            "kjnfjnrnkrn 342\n",
            "second time 342\n",
            "kjnfjnrnkrn 343\n",
            "second time 343\n",
            "kjnfjnrnkrn 344\n",
            "second time 344\n",
            "kjnfjnrnkrn 345\n",
            "second time 345\n",
            "kjnfjnrnkrn 346\n",
            "second time 346\n",
            "kjnfjnrnkrn 347\n",
            "second time 347\n",
            "kjnfjnrnkrn 348\n",
            "second time 348\n",
            "kjnfjnrnkrn 349\n",
            "second time 349\n",
            "Epoch [1/1], Step [350/497], Loss: 1.2765, Accuracy: 46.88%\n",
            "kjnfjnrnkrn 350\n",
            "second time 350\n",
            "kjnfjnrnkrn 351\n",
            "second time 351\n",
            "kjnfjnrnkrn 352\n",
            "second time 352\n",
            "kjnfjnrnkrn 353\n",
            "second time 353\n",
            "kjnfjnrnkrn 354\n",
            "second time 354\n",
            "kjnfjnrnkrn 355\n",
            "second time 355\n",
            "kjnfjnrnkrn 356\n",
            "second time 356\n",
            "kjnfjnrnkrn 357\n",
            "second time 357\n",
            "kjnfjnrnkrn 358\n",
            "second time 358\n",
            "kjnfjnrnkrn 359\n",
            "second time 359\n",
            "Epoch [1/1], Step [360/497], Loss: 1.2612, Accuracy: 53.12%\n",
            "kjnfjnrnkrn 360\n",
            "second time 360\n",
            "kjnfjnrnkrn 361\n",
            "second time 361\n",
            "kjnfjnrnkrn 362\n",
            "second time 362\n",
            "kjnfjnrnkrn 363\n",
            "second time 363\n",
            "kjnfjnrnkrn 364\n",
            "second time 364\n",
            "kjnfjnrnkrn 365\n",
            "second time 365\n",
            "kjnfjnrnkrn 366\n",
            "second time 366\n",
            "kjnfjnrnkrn 367\n",
            "second time 367\n",
            "kjnfjnrnkrn 368\n",
            "second time 368\n",
            "kjnfjnrnkrn 369\n",
            "second time 369\n",
            "Epoch [1/1], Step [370/497], Loss: 1.2370, Accuracy: 62.50%\n",
            "kjnfjnrnkrn 370\n",
            "second time 370\n",
            "kjnfjnrnkrn 371\n",
            "second time 371\n",
            "kjnfjnrnkrn 372\n",
            "second time 372\n",
            "kjnfjnrnkrn 373\n",
            "second time 373\n",
            "kjnfjnrnkrn 374\n",
            "second time 374\n",
            "kjnfjnrnkrn 375\n",
            "second time 375\n",
            "kjnfjnrnkrn 376\n",
            "second time 376\n",
            "kjnfjnrnkrn 377\n",
            "second time 377\n",
            "kjnfjnrnkrn 378\n",
            "second time 378\n",
            "kjnfjnrnkrn 379\n",
            "second time 379\n",
            "Epoch [1/1], Step [380/497], Loss: 1.2538, Accuracy: 53.12%\n",
            "kjnfjnrnkrn 380\n",
            "second time 380\n",
            "kjnfjnrnkrn 381\n",
            "second time 381\n",
            "kjnfjnrnkrn 382\n",
            "second time 382\n",
            "kjnfjnrnkrn 383\n",
            "second time 383\n",
            "kjnfjnrnkrn 384\n",
            "second time 384\n",
            "kjnfjnrnkrn 385\n",
            "second time 385\n",
            "kjnfjnrnkrn 386\n",
            "second time 386\n",
            "kjnfjnrnkrn 387\n",
            "second time 387\n",
            "kjnfjnrnkrn 388\n",
            "second time 388\n",
            "kjnfjnrnkrn 389\n",
            "second time 389\n",
            "Epoch [1/1], Step [390/497], Loss: 1.2845, Accuracy: 25.00%\n",
            "kjnfjnrnkrn 390\n",
            "second time 390\n",
            "kjnfjnrnkrn 391\n",
            "second time 391\n",
            "kjnfjnrnkrn 392\n",
            "second time 392\n",
            "kjnfjnrnkrn 393\n",
            "second time 393\n",
            "kjnfjnrnkrn 394\n",
            "second time 394\n",
            "kjnfjnrnkrn 395\n",
            "second time 395\n",
            "kjnfjnrnkrn 396\n",
            "second time 396\n",
            "kjnfjnrnkrn 397\n",
            "second time 397\n",
            "kjnfjnrnkrn 398\n",
            "second time 398\n",
            "kjnfjnrnkrn 399\n",
            "second time 399\n",
            "Epoch [1/1], Step [400/497], Loss: 1.2359, Accuracy: 53.12%\n",
            "kjnfjnrnkrn 400\n",
            "second time 400\n",
            "kjnfjnrnkrn 401\n",
            "second time 401\n",
            "kjnfjnrnkrn 402\n",
            "second time 402\n",
            "kjnfjnrnkrn 403\n",
            "second time 403\n",
            "kjnfjnrnkrn 404\n",
            "second time 404\n",
            "kjnfjnrnkrn 405\n",
            "second time 405\n",
            "kjnfjnrnkrn 406\n",
            "second time 406\n",
            "kjnfjnrnkrn 407\n",
            "second time 407\n",
            "kjnfjnrnkrn 408\n",
            "second time 408\n",
            "kjnfjnrnkrn 409\n",
            "second time 409\n",
            "Epoch [1/1], Step [410/497], Loss: 1.3526, Accuracy: 28.12%\n",
            "kjnfjnrnkrn 410\n",
            "second time 410\n",
            "kjnfjnrnkrn 411\n",
            "second time 411\n",
            "kjnfjnrnkrn 412\n",
            "second time 412\n",
            "kjnfjnrnkrn 413\n",
            "second time 413\n",
            "kjnfjnrnkrn 414\n",
            "second time 414\n",
            "kjnfjnrnkrn 415\n",
            "second time 415\n",
            "kjnfjnrnkrn 416\n",
            "second time 416\n",
            "kjnfjnrnkrn 417\n",
            "second time 417\n",
            "kjnfjnrnkrn 418\n",
            "second time 418\n",
            "kjnfjnrnkrn 419\n",
            "second time 419\n",
            "Epoch [1/1], Step [420/497], Loss: 1.1469, Accuracy: 75.00%\n",
            "kjnfjnrnkrn 420\n",
            "second time 420\n",
            "kjnfjnrnkrn 421\n",
            "second time 421\n",
            "kjnfjnrnkrn 422\n",
            "second time 422\n",
            "kjnfjnrnkrn 423\n",
            "second time 423\n",
            "kjnfjnrnkrn 424\n",
            "second time 424\n",
            "kjnfjnrnkrn 425\n",
            "second time 425\n",
            "kjnfjnrnkrn 426\n",
            "second time 426\n",
            "kjnfjnrnkrn 427\n",
            "second time 427\n",
            "kjnfjnrnkrn 428\n",
            "second time 428\n",
            "kjnfjnrnkrn 429\n",
            "second time 429\n",
            "Epoch [1/1], Step [430/497], Loss: 1.3152, Accuracy: 40.62%\n",
            "kjnfjnrnkrn 430\n",
            "second time 430\n",
            "kjnfjnrnkrn 431\n",
            "second time 431\n",
            "kjnfjnrnkrn 432\n",
            "second time 432\n",
            "kjnfjnrnkrn 433\n",
            "second time 433\n",
            "kjnfjnrnkrn 434\n",
            "second time 434\n",
            "kjnfjnrnkrn 435\n",
            "second time 435\n",
            "kjnfjnrnkrn 436\n",
            "second time 436\n",
            "kjnfjnrnkrn 437\n",
            "second time 437\n",
            "kjnfjnrnkrn 438\n",
            "second time 438\n",
            "kjnfjnrnkrn 439\n",
            "second time 439\n",
            "Epoch [1/1], Step [440/497], Loss: 1.3012, Accuracy: 37.50%\n",
            "kjnfjnrnkrn 440\n",
            "second time 440\n",
            "kjnfjnrnkrn 441\n",
            "second time 441\n",
            "kjnfjnrnkrn 442\n",
            "second time 442\n",
            "kjnfjnrnkrn 443\n",
            "second time 443\n",
            "kjnfjnrnkrn 444\n",
            "second time 444\n",
            "kjnfjnrnkrn 445\n",
            "second time 445\n",
            "kjnfjnrnkrn 446\n",
            "second time 446\n",
            "kjnfjnrnkrn 447\n",
            "second time 447\n",
            "kjnfjnrnkrn 448\n",
            "second time 448\n",
            "kjnfjnrnkrn 449\n",
            "second time 449\n",
            "Epoch [1/1], Step [450/497], Loss: 1.3094, Accuracy: 46.88%\n",
            "kjnfjnrnkrn 450\n",
            "second time 450\n",
            "kjnfjnrnkrn 451\n",
            "second time 451\n",
            "kjnfjnrnkrn 452\n",
            "second time 452\n",
            "kjnfjnrnkrn 453\n",
            "second time 453\n",
            "kjnfjnrnkrn 454\n",
            "second time 454\n",
            "kjnfjnrnkrn 455\n",
            "second time 455\n",
            "kjnfjnrnkrn 456\n",
            "second time 456\n",
            "kjnfjnrnkrn 457\n",
            "second time 457\n",
            "kjnfjnrnkrn 458\n",
            "second time 458\n",
            "kjnfjnrnkrn 459\n",
            "second time 459\n",
            "Epoch [1/1], Step [460/497], Loss: 1.2755, Accuracy: 53.12%\n",
            "kjnfjnrnkrn 460\n",
            "second time 460\n",
            "kjnfjnrnkrn 461\n",
            "second time 461\n",
            "kjnfjnrnkrn 462\n",
            "second time 462\n",
            "kjnfjnrnkrn 463\n",
            "second time 463\n",
            "kjnfjnrnkrn 464\n",
            "second time 464\n",
            "kjnfjnrnkrn 465\n",
            "second time 465\n",
            "kjnfjnrnkrn 466\n",
            "second time 466\n",
            "kjnfjnrnkrn 467\n",
            "second time 467\n",
            "kjnfjnrnkrn 468\n",
            "second time 468\n",
            "kjnfjnrnkrn 469\n",
            "second time 469\n",
            "Epoch [1/1], Step [470/497], Loss: 1.2926, Accuracy: 50.00%\n",
            "kjnfjnrnkrn 470\n",
            "second time 470\n",
            "kjnfjnrnkrn 471\n",
            "second time 471\n",
            "kjnfjnrnkrn 472\n",
            "second time 472\n",
            "kjnfjnrnkrn 473\n",
            "second time 473\n",
            "kjnfjnrnkrn 474\n",
            "second time 474\n",
            "kjnfjnrnkrn 475\n",
            "second time 475\n",
            "kjnfjnrnkrn 476\n",
            "second time 476\n",
            "kjnfjnrnkrn 477\n",
            "second time 477\n",
            "kjnfjnrnkrn 478\n",
            "second time 478\n",
            "kjnfjnrnkrn 479\n",
            "second time 479\n",
            "Epoch [1/1], Step [480/497], Loss: 1.2578, Accuracy: 56.25%\n",
            "kjnfjnrnkrn 480\n",
            "second time 480\n",
            "kjnfjnrnkrn 481\n",
            "second time 481\n",
            "kjnfjnrnkrn 482\n",
            "second time 482\n",
            "kjnfjnrnkrn 483\n",
            "second time 483\n",
            "kjnfjnrnkrn 484\n",
            "second time 484\n",
            "kjnfjnrnkrn 485\n",
            "second time 485\n",
            "kjnfjnrnkrn 486\n",
            "second time 486\n",
            "kjnfjnrnkrn 487\n",
            "second time 487\n",
            "kjnfjnrnkrn 488\n",
            "second time 488\n",
            "kjnfjnrnkrn 489\n",
            "second time 489\n",
            "Epoch [1/1], Step [490/497], Loss: 1.2950, Accuracy: 50.00%\n",
            "kjnfjnrnkrn 490\n",
            "second time 490\n",
            "kjnfjnrnkrn 491\n",
            "second time 491\n",
            "kjnfjnrnkrn 492\n",
            "second time 492\n",
            "kjnfjnrnkrn 493\n",
            "second time 493\n",
            "kjnfjnrnkrn 494\n",
            "second time 494\n",
            "kjnfjnrnkrn 495\n",
            "second time 495\n",
            "kjnfjnrnkrn 496\n",
            "second time 496\n",
            "######## Training Finished in 2701.461512327194 seconds ###########\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## Write your code here #############\n",
        "net.eval() \n",
        "count=0\n",
        "with torch.no_grad(): \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in data_loader_test:\n",
        "        # count+=1\n",
        "        # print(count)\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Test Accuracy of the model on the {} test images: {} %'\n",
        "        .format(total, (correct / total) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX4VLvavK6il",
        "outputId": "c763cb2a-08f6-4834-cf95-e598fd250905"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 5292 test images: 49.35752078609221 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i2-qqitjLSbi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}