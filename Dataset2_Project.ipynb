{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM4roBshk-OR",
        "outputId": "53f8c5e1-bfeb-4d4a-d824-e01650c1322a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as td\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import time"
      ],
      "metadata": {
        "id": "qmhN_C-9stH0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "def load_data(path,batch_size,input_size):\n",
        "    \n",
        "    normalize = transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ]) \n",
        "    transform_dict = {\"src\":  normalize} \n",
        "    data = datasets.ImageFolder(root=path,transform=transform_dict[\"src\"])\n",
        "    # transform_dict1 = {\"test\":  normalize\n",
        "    train_size=int(0.75*len(data))\n",
        "    print(len(data))\n",
        "    test_size=int(len(data)-train_size)\n",
        "    train, test = td.random_split(data,[train_size,test_size])\n",
        "\n",
        "    data_loader_train = td.DataLoader(train,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    data_loader_test = td.DataLoader(test,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    # data_loader_val = td.DataLoader(val,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    return data_loader_train, data_loader_test"
      ],
      "metadata": {
        "id": "nUncT4fzdZNr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader_train,data_loader_test=load_data(r\"/content/gdrive/MyDrive/Colab Notebooks/archive\",32,64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIIN6QPydZLH",
        "outputId": "9e2c9e6c-fe14-49d9-9ed8-1c78e50f8f04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50\n",
        "net=resnet50(weights=None)\n",
        "resnet50(pretrained=False) \n",
        "# net = resNet50(22).to('cuda')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFpDWRWJBtan",
        "outputId": "fa222636-15cd-48dc-ac96-6a3f988e11d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### Define and run your training loop here #########\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "net.to(device)\n",
        "\n",
        "num_epochs = 5\n",
        "total_steps = len(data_loader_train)\n",
        "t1 = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(data_loader_train):\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # Forward pass\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # print(\"kjnfjnrnkrn\",i)\n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(\"second time\",i)\n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            \n",
        "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmK_9RNadrkg",
        "outputId": "ca1d7f28-3fbd-440f-a0c6-5b62d5d951ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Epoch [1/5], Step [10/163], Loss: 4.4735, Accuracy: 37.50%\n",
            "Epoch [1/5], Step [20/163], Loss: 2.1629, Accuracy: 12.50%\n",
            "Epoch [1/5], Step [30/163], Loss: 1.3594, Accuracy: 62.50%\n",
            "Epoch [1/5], Step [40/163], Loss: 2.4606, Accuracy: 62.50%\n",
            "Epoch [1/5], Step [50/163], Loss: 4.8421, Accuracy: 28.12%\n",
            "Epoch [1/5], Step [60/163], Loss: 2.2947, Accuracy: 28.12%\n",
            "Epoch [1/5], Step [70/163], Loss: 1.3247, Accuracy: 31.25%\n",
            "Epoch [1/5], Step [80/163], Loss: 1.6915, Accuracy: 50.00%\n",
            "Epoch [1/5], Step [90/163], Loss: 1.7728, Accuracy: 40.62%\n",
            "Epoch [1/5], Step [100/163], Loss: 1.6166, Accuracy: 40.62%\n",
            "Epoch [1/5], Step [110/163], Loss: 1.7031, Accuracy: 21.88%\n",
            "Epoch [1/5], Step [120/163], Loss: 1.7078, Accuracy: 34.38%\n",
            "Epoch [1/5], Step [130/163], Loss: 1.7261, Accuracy: 31.25%\n",
            "Epoch [1/5], Step [140/163], Loss: 1.6790, Accuracy: 31.25%\n",
            "Epoch [1/5], Step [150/163], Loss: 1.7636, Accuracy: 28.12%\n",
            "Epoch [1/5], Step [160/163], Loss: 1.6441, Accuracy: 43.75%\n",
            "Epoch [2/5], Step [10/163], Loss: 1.6981, Accuracy: 31.25%\n",
            "Epoch [2/5], Step [20/163], Loss: 1.6863, Accuracy: 34.38%\n",
            "Epoch [2/5], Step [30/163], Loss: 1.6218, Accuracy: 53.12%\n",
            "Epoch [2/5], Step [40/163], Loss: 1.6608, Accuracy: 50.00%\n",
            "Epoch [2/5], Step [50/163], Loss: 1.6925, Accuracy: 25.00%\n",
            "Epoch [2/5], Step [60/163], Loss: 1.6652, Accuracy: 31.25%\n",
            "Epoch [2/5], Step [70/163], Loss: 1.7015, Accuracy: 34.38%\n",
            "Epoch [2/5], Step [80/163], Loss: 1.6587, Accuracy: 46.88%\n",
            "Epoch [2/5], Step [90/163], Loss: 1.6827, Accuracy: 25.00%\n",
            "Epoch [2/5], Step [100/163], Loss: 1.6701, Accuracy: 37.50%\n",
            "Epoch [2/5], Step [110/163], Loss: 1.7066, Accuracy: 21.88%\n",
            "Epoch [2/5], Step [120/163], Loss: 1.6876, Accuracy: 28.12%\n",
            "Epoch [2/5], Step [130/163], Loss: 1.6540, Accuracy: 40.62%\n",
            "Epoch [2/5], Step [140/163], Loss: 1.6852, Accuracy: 21.88%\n",
            "Epoch [2/5], Step [150/163], Loss: 1.6678, Accuracy: 31.25%\n",
            "Epoch [2/5], Step [160/163], Loss: 1.6740, Accuracy: 31.25%\n",
            "Epoch [3/5], Step [10/163], Loss: 1.7038, Accuracy: 25.00%\n",
            "Epoch [3/5], Step [20/163], Loss: 1.6714, Accuracy: 34.38%\n",
            "Epoch [3/5], Step [30/163], Loss: 1.7052, Accuracy: 21.88%\n",
            "Epoch [3/5], Step [40/163], Loss: 1.6865, Accuracy: 25.00%\n",
            "Epoch [3/5], Step [50/163], Loss: 1.6489, Accuracy: 34.38%\n",
            "Epoch [3/5], Step [60/163], Loss: 1.6991, Accuracy: 25.00%\n",
            "Epoch [3/5], Step [70/163], Loss: 1.6773, Accuracy: 31.25%\n",
            "Epoch [3/5], Step [80/163], Loss: 1.6314, Accuracy: 46.88%\n",
            "Epoch [3/5], Step [90/163], Loss: 1.6627, Accuracy: 37.50%\n",
            "Epoch [3/5], Step [100/163], Loss: 1.6748, Accuracy: 34.38%\n",
            "Epoch [3/5], Step [110/163], Loss: 1.6536, Accuracy: 43.75%\n",
            "Epoch [3/5], Step [120/163], Loss: 1.6121, Accuracy: 46.88%\n",
            "Epoch [3/5], Step [130/163], Loss: 1.7244, Accuracy: 25.00%\n",
            "Epoch [3/5], Step [140/163], Loss: 1.6891, Accuracy: 34.38%\n",
            "Epoch [3/5], Step [150/163], Loss: 1.6613, Accuracy: 37.50%\n",
            "Epoch [3/5], Step [160/163], Loss: 1.6522, Accuracy: 43.75%\n",
            "Epoch [4/5], Step [10/163], Loss: 1.6966, Accuracy: 34.38%\n",
            "Epoch [4/5], Step [20/163], Loss: 1.6569, Accuracy: 40.62%\n",
            "Epoch [4/5], Step [40/163], Loss: 1.7111, Accuracy: 28.12%\n",
            "Epoch [4/5], Step [50/163], Loss: 1.6974, Accuracy: 31.25%\n",
            "Epoch [4/5], Step [60/163], Loss: 1.6755, Accuracy: 34.38%\n",
            "Epoch [4/5], Step [70/163], Loss: 1.7371, Accuracy: 25.00%\n",
            "Epoch [4/5], Step [80/163], Loss: 1.6894, Accuracy: 28.12%\n",
            "Epoch [4/5], Step [90/163], Loss: 1.7091, Accuracy: 31.25%\n",
            "Epoch [4/5], Step [100/163], Loss: 1.6009, Accuracy: 34.38%\n",
            "Epoch [4/5], Step [110/163], Loss: 1.7868, Accuracy: 25.00%\n",
            "Epoch [4/5], Step [120/163], Loss: 1.7010, Accuracy: 28.12%\n",
            "Epoch [4/5], Step [130/163], Loss: 1.6423, Accuracy: 31.25%\n",
            "Epoch [4/5], Step [140/163], Loss: 1.6456, Accuracy: 37.50%\n",
            "Epoch [4/5], Step [150/163], Loss: 1.6596, Accuracy: 28.12%\n",
            "Epoch [4/5], Step [160/163], Loss: 1.6864, Accuracy: 28.12%\n",
            "Epoch [5/5], Step [10/163], Loss: 1.6637, Accuracy: 37.50%\n",
            "Epoch [5/5], Step [20/163], Loss: 1.6699, Accuracy: 34.38%\n",
            "Epoch [5/5], Step [30/163], Loss: 1.6885, Accuracy: 34.38%\n",
            "Epoch [5/5], Step [40/163], Loss: 1.6312, Accuracy: 46.88%\n",
            "Epoch [5/5], Step [50/163], Loss: 1.6652, Accuracy: 40.62%\n",
            "Epoch [5/5], Step [60/163], Loss: 1.7035, Accuracy: 21.88%\n",
            "Epoch [5/5], Step [70/163], Loss: 1.6684, Accuracy: 34.38%\n",
            "Epoch [5/5], Step [80/163], Loss: 1.6897, Accuracy: 37.50%\n",
            "Epoch [5/5], Step [90/163], Loss: 1.7234, Accuracy: 21.88%\n",
            "Epoch [5/5], Step [100/163], Loss: 1.6576, Accuracy: 34.38%\n",
            "Epoch [5/5], Step [110/163], Loss: 1.6368, Accuracy: 50.00%\n",
            "Epoch [5/5], Step [120/163], Loss: 1.6251, Accuracy: 43.75%\n",
            "Epoch [5/5], Step [130/163], Loss: 1.6848, Accuracy: 43.75%\n",
            "Epoch [5/5], Step [140/163], Loss: 1.6868, Accuracy: 25.00%\n",
            "Epoch [5/5], Step [150/163], Loss: 1.6497, Accuracy: 40.62%\n",
            "Epoch [5/5], Step [160/163], Loss: 1.6522, Accuracy: 46.88%\n",
            "######## Training Finished in 1583.1344022750854 seconds ###########\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval() \n",
        "perds = []\n",
        "target = []\n",
        "with torch.no_grad(): \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in data_loader_test:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        perds.extend(predicted)\n",
        "        target.extend(labels)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Test Accuracy of the model on the {} test images: {} %'\n",
        "        .format(total, (correct / total) * 100))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGLZz7-NTB31",
        "outputId": "5f131da4-59ad-426a-927b-709b191bac2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 1733 test images: 34.10271206001154 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "sdSM9uiydwoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional import precision_recall\n",
        "from torchmetrics import F1Score\n",
        "from torchmetrics import ConfusionMatrix\n",
        "perds1 = torch.stack(perds)\n",
        "target1 = torch.stack(target)\n",
        "f1 = F1Score(num_classes=3).to(device)\n",
        "print(f1(perds1, target1))\n",
        "print(precision_recall(perds1, target1, average='macro', num_classes=3))\n",
        "confmat = ConfusionMatrix(num_classes=3).to(device)\n",
        "confmat(perds1, target1)"
      ],
      "metadata": {
        "id": "VVfQzdWLdwkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d686acd0-3072-4765-8e80-a1a161b6cd5e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3410, device='cuda:0')\n",
            "(tensor(0.1137, device='cuda:0'), tensor(0.3333, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[591,   0,   0],\n",
              "        [560,   0,   0],\n",
              "        [582,   0,   0]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "We6bEeLsCKmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}