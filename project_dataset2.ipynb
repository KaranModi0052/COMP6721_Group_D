{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLE6OPz6k516",
        "outputId": "72db4a82-44c2-4c3c-a6d1-6aee30ce0fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as td\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import time"
      ],
      "metadata": {
        "id": "0cEF16PPnDig"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "def load_data(path,batch_size,input_size):\n",
        "    \n",
        "    normalize = transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ]) \n",
        "    transform_dict = {\"src\":  normalize}  \n",
        "    # train_path=path+\"/train\"\n",
        "    # test_path=path+\"/test\"\n",
        "    data = datasets.ImageFolder(root=path,transform=transform_dict[\"src\"])\n",
        "    # transform_dict1 = {\"test\":  normalize} \n",
        "    # test1 = datasets.ImageFolder(root=path,transform=transform_dict[\"test\"])\n",
        "    # transform_dict = {\"test\":  normalize}\n",
        "    # test= datasets.ImageFolder(root=path,transform=transform_dict[\"test\"])\n",
        "    # train_size = int((1- (test_split + val_split)) * len(data))\n",
        "    # test_size = int((1 - (val_split)) * len(data)) - train_size\n",
        "    # val_size = len(data) - train_size - test_size\n",
        "    train_size=int(0.75*len(data))\n",
        "    test_size=int(len(data)-train_size)\n",
        "    train, test = td.random_split(data,[train_size,test_size])\n",
        "\n",
        "    data_loader_train = td.DataLoader(train,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    data_loader_test = td.DataLoader(test,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    # data_loader_val = td.DataLoader(val,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    return data_loader_train, data_loader_test"
      ],
      "metadata": {
        "id": "MyA9Qi8ynEnB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}