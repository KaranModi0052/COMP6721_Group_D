{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e79247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as td\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "308235d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.fromnumeric import shape\n",
    "def load_data(path,batch_size,input_size):\n",
    "    \n",
    "    normalize = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ]) \n",
    "    transform_dict = {\"src\":  normalize}  \n",
    "    # train_path=path+\"/train\"\n",
    "    # test_path=path+\"/test\"\n",
    "    data = datasets.ImageFolder(root=path,transform=transform_dict[\"src\"])\n",
    "    # transform_dict1 = {\"test\":  normalize} \n",
    "    # test1 = datasets.ImageFolder(root=path,transform=transform_dict[\"test\"])\n",
    "    # transform_dict = {\"test\":  normalize}\n",
    "    # test= datasets.ImageFolder(root=path,transform=transform_dict[\"test\"])\n",
    "    # train_size = int((1- (test_split + val_split)) * len(data))\n",
    "    # test_size = int((1 - (val_split)) * len(data)) - train_size\n",
    "    # val_size = len(data) - train_size - test_size\n",
    "    train_size=int(0.75*len(data))\n",
    "    test_size=int(len(data)-train_size)\n",
    "    train, test = td.random_split(data,[train_size,test_size])\n",
    "\n",
    "    data_loader_train = td.DataLoader(train,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
    "    data_loader_test = td.DataLoader(test,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
    "    # data_loader_val = td.DataLoader(val,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
    "    return data_loader_train, data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae6e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train,data_loader_test=load_data(r\"C:\\Users\\Admin\\Desktop\\COMP 6721\\Project\\datasets\\Dataset1\",32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d970676b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db79d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2=image.imread(r\"C:\\Users\\Admin\\Desktop\\COMP 6721\\Project\\datasets\\Dataset3\\train\\1.2.826.0.1.3680043.8.498.10144276773552601236124857108161469299-c.png\")\n",
    "# img2.shape\n",
    "# #                   1.2.826.0.1.3680043.8.498.10299385524344582994601970314833752000-c.png\")\n",
    "# # plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16170f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AlexNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256 * 6 * 6, 4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(4096, 4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2b7e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "net = AlexNet(4).to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8efa56f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Epoch [1/30], Step [10/497], Loss: 1.1097, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [20/497], Loss: 1.1852, Accuracy: 56.25%\n",
      "Epoch [1/30], Step [30/497], Loss: 0.9803, Accuracy: 65.62%\n",
      "Epoch [1/30], Step [40/497], Loss: 1.2921, Accuracy: 43.75%\n",
      "Epoch [1/30], Step [50/497], Loss: 1.2340, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [60/497], Loss: 1.0896, Accuracy: 56.25%\n",
      "Epoch [1/30], Step [70/497], Loss: 1.2237, Accuracy: 46.88%\n",
      "Epoch [1/30], Step [80/497], Loss: 1.2838, Accuracy: 37.50%\n",
      "Epoch [1/30], Step [90/497], Loss: 1.1380, Accuracy: 59.38%\n",
      "Epoch [1/30], Step [100/497], Loss: 1.1916, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [110/497], Loss: 1.2961, Accuracy: 37.50%\n",
      "Epoch [1/30], Step [120/497], Loss: 1.1366, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [130/497], Loss: 1.0741, Accuracy: 50.00%\n",
      "Epoch [1/30], Step [140/497], Loss: 1.0803, Accuracy: 59.38%\n",
      "Epoch [1/30], Step [150/497], Loss: 1.2920, Accuracy: 40.62%\n",
      "Epoch [1/30], Step [160/497], Loss: 1.1429, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [170/497], Loss: 1.1842, Accuracy: 40.62%\n",
      "Epoch [1/30], Step [180/497], Loss: 1.3090, Accuracy: 43.75%\n",
      "Epoch [1/30], Step [190/497], Loss: 1.4794, Accuracy: 34.38%\n",
      "Epoch [1/30], Step [200/497], Loss: 1.4129, Accuracy: 43.75%\n",
      "Epoch [1/30], Step [210/497], Loss: 1.2695, Accuracy: 37.50%\n",
      "Epoch [1/30], Step [220/497], Loss: 1.1423, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [230/497], Loss: 1.0477, Accuracy: 62.50%\n",
      "Epoch [1/30], Step [240/497], Loss: 1.2044, Accuracy: 43.75%\n",
      "Epoch [1/30], Step [250/497], Loss: 1.1618, Accuracy: 40.62%\n",
      "Epoch [1/30], Step [260/497], Loss: 1.2350, Accuracy: 46.88%\n",
      "Epoch [1/30], Step [270/497], Loss: 1.1004, Accuracy: 50.00%\n",
      "Epoch [1/30], Step [280/497], Loss: 1.1352, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [290/497], Loss: 1.2113, Accuracy: 37.50%\n",
      "Epoch [1/30], Step [300/497], Loss: 1.0040, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [310/497], Loss: 1.2134, Accuracy: 46.88%\n",
      "Epoch [1/30], Step [320/497], Loss: 1.3853, Accuracy: 40.62%\n",
      "Epoch [1/30], Step [330/497], Loss: 1.1590, Accuracy: 43.75%\n",
      "Epoch [1/30], Step [340/497], Loss: 1.4223, Accuracy: 40.62%\n",
      "Epoch [1/30], Step [350/497], Loss: 1.2111, Accuracy: 46.88%\n",
      "Epoch [1/30], Step [360/497], Loss: 1.1778, Accuracy: 59.38%\n",
      "Epoch [1/30], Step [370/497], Loss: 1.3386, Accuracy: 34.38%\n",
      "Epoch [1/30], Step [380/497], Loss: 1.2526, Accuracy: 21.88%\n",
      "Epoch [1/30], Step [390/497], Loss: 1.2000, Accuracy: 46.88%\n",
      "Epoch [1/30], Step [400/497], Loss: 1.0527, Accuracy: 56.25%\n",
      "Epoch [1/30], Step [410/497], Loss: 1.1858, Accuracy: 56.25%\n",
      "Epoch [1/30], Step [420/497], Loss: 1.1614, Accuracy: 53.12%\n",
      "Epoch [1/30], Step [430/497], Loss: 1.1584, Accuracy: 46.88%\n",
      "Epoch [1/30], Step [440/497], Loss: 1.0399, Accuracy: 50.00%\n",
      "Epoch [1/30], Step [450/497], Loss: 1.0662, Accuracy: 62.50%\n",
      "Epoch [1/30], Step [460/497], Loss: 1.2186, Accuracy: 37.50%\n",
      "Epoch [1/30], Step [470/497], Loss: 1.3898, Accuracy: 37.50%\n",
      "Epoch [1/30], Step [480/497], Loss: 1.2335, Accuracy: 46.88%\n",
      "Epoch [1/30], Step [490/497], Loss: 1.0243, Accuracy: 62.50%\n",
      "Epoch [2/30], Step [10/497], Loss: 1.1850, Accuracy: 46.88%\n",
      "Epoch [2/30], Step [20/497], Loss: 1.0426, Accuracy: 59.38%\n",
      "Epoch [2/30], Step [30/497], Loss: 1.1249, Accuracy: 59.38%\n",
      "Epoch [2/30], Step [40/497], Loss: 1.2435, Accuracy: 46.88%\n",
      "Epoch [2/30], Step [50/497], Loss: 1.2127, Accuracy: 43.75%\n",
      "Epoch [2/30], Step [60/497], Loss: 1.2309, Accuracy: 53.12%\n",
      "Epoch [2/30], Step [70/497], Loss: 1.2445, Accuracy: 40.62%\n",
      "Epoch [2/30], Step [80/497], Loss: 1.2304, Accuracy: 40.62%\n",
      "Epoch [2/30], Step [90/497], Loss: 1.1531, Accuracy: 53.12%\n",
      "Epoch [2/30], Step [100/497], Loss: 1.1644, Accuracy: 43.75%\n",
      "Epoch [2/30], Step [110/497], Loss: 1.0742, Accuracy: 56.25%\n",
      "Epoch [2/30], Step [120/497], Loss: 1.2233, Accuracy: 46.88%\n",
      "Epoch [2/30], Step [130/497], Loss: 1.2762, Accuracy: 46.88%\n",
      "Epoch [2/30], Step [140/497], Loss: 1.1571, Accuracy: 50.00%\n",
      "Epoch [2/30], Step [150/497], Loss: 1.2077, Accuracy: 37.50%\n",
      "Epoch [2/30], Step [160/497], Loss: 1.1343, Accuracy: 50.00%\n",
      "Epoch [2/30], Step [170/497], Loss: 1.0920, Accuracy: 56.25%\n",
      "Epoch [2/30], Step [180/497], Loss: 1.3244, Accuracy: 40.62%\n",
      "Epoch [2/30], Step [190/497], Loss: 1.2292, Accuracy: 50.00%\n",
      "Epoch [2/30], Step [200/497], Loss: 1.3188, Accuracy: 40.62%\n",
      "Epoch [2/30], Step [210/497], Loss: 1.1557, Accuracy: 56.25%\n",
      "Epoch [2/30], Step [220/497], Loss: 1.3016, Accuracy: 37.50%\n",
      "Epoch [2/30], Step [230/497], Loss: 1.1913, Accuracy: 50.00%\n",
      "Epoch [2/30], Step [240/497], Loss: 1.2679, Accuracy: 31.25%\n",
      "Epoch [2/30], Step [250/497], Loss: 1.1735, Accuracy: 46.88%\n",
      "Epoch [2/30], Step [260/497], Loss: 1.2058, Accuracy: 40.62%\n",
      "Epoch [2/30], Step [270/497], Loss: 1.3281, Accuracy: 37.50%\n",
      "Epoch [2/30], Step [280/497], Loss: 1.2865, Accuracy: 37.50%\n",
      "Epoch [2/30], Step [290/497], Loss: 1.2116, Accuracy: 50.00%\n",
      "Epoch [2/30], Step [300/497], Loss: 1.2554, Accuracy: 37.50%\n",
      "Epoch [2/30], Step [310/497], Loss: 1.2248, Accuracy: 46.88%\n",
      "Epoch [2/30], Step [320/497], Loss: 1.2617, Accuracy: 56.25%\n",
      "Epoch [2/30], Step [330/497], Loss: 1.1518, Accuracy: 50.00%\n",
      "Epoch [2/30], Step [340/497], Loss: 1.0595, Accuracy: 62.50%\n",
      "Epoch [2/30], Step [350/497], Loss: 1.3267, Accuracy: 37.50%\n",
      "Epoch [2/30], Step [360/497], Loss: 1.1670, Accuracy: 50.00%\n",
      "Epoch [2/30], Step [370/497], Loss: 1.1389, Accuracy: 59.38%\n",
      "Epoch [2/30], Step [380/497], Loss: 1.2655, Accuracy: 46.88%\n",
      "Epoch [2/30], Step [390/497], Loss: 1.0953, Accuracy: 56.25%\n",
      "Epoch [2/30], Step [400/497], Loss: 1.1516, Accuracy: 53.12%\n",
      "Epoch [2/30], Step [410/497], Loss: 1.1788, Accuracy: 43.75%\n",
      "Epoch [2/30], Step [420/497], Loss: 1.1012, Accuracy: 59.38%\n",
      "Epoch [2/30], Step [430/497], Loss: 1.1737, Accuracy: 43.75%\n",
      "Epoch [2/30], Step [440/497], Loss: 1.1235, Accuracy: 53.12%\n",
      "Epoch [2/30], Step [450/497], Loss: 1.2654, Accuracy: 31.25%\n",
      "Epoch [2/30], Step [460/497], Loss: 1.2505, Accuracy: 50.00%\n",
      "Epoch [2/30], Step [470/497], Loss: 1.0842, Accuracy: 53.12%\n",
      "Epoch [2/30], Step [480/497], Loss: 1.1240, Accuracy: 53.12%\n",
      "Epoch [2/30], Step [490/497], Loss: 1.0314, Accuracy: 65.62%\n",
      "Epoch [3/30], Step [10/497], Loss: 1.2217, Accuracy: 37.50%\n",
      "Epoch [3/30], Step [20/497], Loss: 1.2276, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [30/497], Loss: 1.1076, Accuracy: 53.12%\n",
      "Epoch [3/30], Step [40/497], Loss: 1.1164, Accuracy: 53.12%\n",
      "Epoch [3/30], Step [50/497], Loss: 1.1463, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [60/497], Loss: 1.1040, Accuracy: 53.12%\n",
      "Epoch [3/30], Step [70/497], Loss: 1.2803, Accuracy: 34.38%\n",
      "Epoch [3/30], Step [80/497], Loss: 1.0857, Accuracy: 56.25%\n",
      "Epoch [3/30], Step [90/497], Loss: 1.1058, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [100/497], Loss: 1.2152, Accuracy: 43.75%\n",
      "Epoch [3/30], Step [110/497], Loss: 1.0349, Accuracy: 56.25%\n",
      "Epoch [3/30], Step [120/497], Loss: 1.0817, Accuracy: 56.25%\n",
      "Epoch [3/30], Step [130/497], Loss: 1.0818, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [140/497], Loss: 1.1504, Accuracy: 46.88%\n",
      "Epoch [3/30], Step [150/497], Loss: 1.1456, Accuracy: 53.12%\n",
      "Epoch [3/30], Step [160/497], Loss: 1.1344, Accuracy: 56.25%\n",
      "Epoch [3/30], Step [170/497], Loss: 1.2299, Accuracy: 40.62%\n",
      "Epoch [3/30], Step [180/497], Loss: 1.1616, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [190/497], Loss: 1.2239, Accuracy: 43.75%\n",
      "Epoch [3/30], Step [200/497], Loss: 1.1903, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [210/497], Loss: 1.0543, Accuracy: 62.50%\n",
      "Epoch [3/30], Step [220/497], Loss: 1.2459, Accuracy: 43.75%\n",
      "Epoch [3/30], Step [230/497], Loss: 1.4351, Accuracy: 34.38%\n",
      "Epoch [3/30], Step [240/497], Loss: 1.0720, Accuracy: 53.12%\n",
      "Epoch [3/30], Step [250/497], Loss: 1.1896, Accuracy: 46.88%\n",
      "Epoch [3/30], Step [260/497], Loss: 1.1396, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [270/497], Loss: 1.0133, Accuracy: 56.25%\n",
      "Epoch [3/30], Step [280/497], Loss: 1.2083, Accuracy: 43.75%\n",
      "Epoch [3/30], Step [290/497], Loss: 1.1026, Accuracy: 53.12%\n",
      "Epoch [3/30], Step [300/497], Loss: 1.2230, Accuracy: 56.25%\n",
      "Epoch [3/30], Step [310/497], Loss: 1.1569, Accuracy: 40.62%\n",
      "Epoch [3/30], Step [320/497], Loss: 1.2327, Accuracy: 46.88%\n",
      "Epoch [3/30], Step [330/497], Loss: 1.1723, Accuracy: 43.75%\n",
      "Epoch [3/30], Step [340/497], Loss: 1.2249, Accuracy: 53.12%\n",
      "Epoch [3/30], Step [350/497], Loss: 1.1056, Accuracy: 46.88%\n",
      "Epoch [3/30], Step [360/497], Loss: 1.4536, Accuracy: 31.25%\n",
      "Epoch [3/30], Step [370/497], Loss: 1.0860, Accuracy: 46.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Step [380/497], Loss: 1.1856, Accuracy: 46.88%\n",
      "Epoch [3/30], Step [390/497], Loss: 1.2071, Accuracy: 59.38%\n",
      "Epoch [3/30], Step [400/497], Loss: 1.1819, Accuracy: 43.75%\n",
      "Epoch [3/30], Step [410/497], Loss: 1.3335, Accuracy: 40.62%\n",
      "Epoch [3/30], Step [420/497], Loss: 1.3944, Accuracy: 34.38%\n",
      "Epoch [3/30], Step [430/497], Loss: 1.1880, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [440/497], Loss: 1.2253, Accuracy: 43.75%\n",
      "Epoch [3/30], Step [450/497], Loss: 1.2136, Accuracy: 34.38%\n",
      "Epoch [3/30], Step [460/497], Loss: 1.0752, Accuracy: 56.25%\n",
      "Epoch [3/30], Step [470/497], Loss: 1.1715, Accuracy: 53.12%\n",
      "Epoch [3/30], Step [480/497], Loss: 1.2298, Accuracy: 50.00%\n",
      "Epoch [3/30], Step [490/497], Loss: 1.1889, Accuracy: 37.50%\n",
      "Epoch [4/30], Step [10/497], Loss: 1.1595, Accuracy: 59.38%\n",
      "Epoch [4/30], Step [20/497], Loss: 1.1248, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [30/497], Loss: 1.2143, Accuracy: 46.88%\n",
      "Epoch [4/30], Step [40/497], Loss: 1.1126, Accuracy: 59.38%\n",
      "Epoch [4/30], Step [50/497], Loss: 1.1977, Accuracy: 43.75%\n",
      "Epoch [4/30], Step [60/497], Loss: 1.1265, Accuracy: 43.75%\n",
      "Epoch [4/30], Step [70/497], Loss: 1.0989, Accuracy: 56.25%\n",
      "Epoch [4/30], Step [80/497], Loss: 1.1500, Accuracy: 46.88%\n",
      "Epoch [4/30], Step [90/497], Loss: 1.1711, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [100/497], Loss: 1.3196, Accuracy: 43.75%\n",
      "Epoch [4/30], Step [110/497], Loss: 1.2210, Accuracy: 46.88%\n",
      "Epoch [4/30], Step [120/497], Loss: 1.4021, Accuracy: 28.12%\n",
      "Epoch [4/30], Step [130/497], Loss: 1.2425, Accuracy: 43.75%\n",
      "Epoch [4/30], Step [140/497], Loss: 1.4581, Accuracy: 31.25%\n",
      "Epoch [4/30], Step [150/497], Loss: 1.0243, Accuracy: 62.50%\n",
      "Epoch [4/30], Step [160/497], Loss: 1.0880, Accuracy: 59.38%\n",
      "Epoch [4/30], Step [170/497], Loss: 1.3555, Accuracy: 43.75%\n",
      "Epoch [4/30], Step [180/497], Loss: 1.2211, Accuracy: 53.12%\n",
      "Epoch [4/30], Step [190/497], Loss: 1.1747, Accuracy: 43.75%\n",
      "Epoch [4/30], Step [200/497], Loss: 1.0943, Accuracy: 62.50%\n",
      "Epoch [4/30], Step [210/497], Loss: 1.2113, Accuracy: 40.62%\n",
      "Epoch [4/30], Step [220/497], Loss: 1.1803, Accuracy: 46.88%\n",
      "Epoch [4/30], Step [230/497], Loss: 1.3373, Accuracy: 43.75%\n",
      "Epoch [4/30], Step [240/497], Loss: 1.1896, Accuracy: 43.75%\n",
      "Epoch [4/30], Step [250/497], Loss: 1.1321, Accuracy: 53.12%\n",
      "Epoch [4/30], Step [260/497], Loss: 1.2147, Accuracy: 46.88%\n",
      "Epoch [4/30], Step [270/497], Loss: 1.2402, Accuracy: 53.12%\n",
      "Epoch [4/30], Step [280/497], Loss: 1.2043, Accuracy: 53.12%\n",
      "Epoch [4/30], Step [290/497], Loss: 1.0927, Accuracy: 56.25%\n",
      "Epoch [4/30], Step [300/497], Loss: 1.0948, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [310/497], Loss: 1.1570, Accuracy: 56.25%\n",
      "Epoch [4/30], Step [320/497], Loss: 1.1668, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [330/497], Loss: 1.1687, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [340/497], Loss: 1.3495, Accuracy: 46.88%\n",
      "Epoch [4/30], Step [350/497], Loss: 1.1344, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [360/497], Loss: 1.0567, Accuracy: 59.38%\n",
      "Epoch [4/30], Step [370/497], Loss: 1.2977, Accuracy: 34.38%\n",
      "Epoch [4/30], Step [380/497], Loss: 1.1597, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [390/497], Loss: 1.4732, Accuracy: 34.38%\n",
      "Epoch [4/30], Step [400/497], Loss: 1.2036, Accuracy: 46.88%\n",
      "Epoch [4/30], Step [410/497], Loss: 1.1167, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [420/497], Loss: 1.2182, Accuracy: 50.00%\n",
      "Epoch [4/30], Step [430/497], Loss: 1.2862, Accuracy: 37.50%\n",
      "Epoch [4/30], Step [440/497], Loss: 1.2076, Accuracy: 40.62%\n",
      "Epoch [4/30], Step [450/497], Loss: 1.0735, Accuracy: 62.50%\n",
      "Epoch [4/30], Step [460/497], Loss: 1.2922, Accuracy: 37.50%\n",
      "Epoch [4/30], Step [470/497], Loss: 1.0536, Accuracy: 65.62%\n",
      "Epoch [4/30], Step [480/497], Loss: 1.1515, Accuracy: 53.12%\n",
      "Epoch [4/30], Step [490/497], Loss: 1.1925, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [10/497], Loss: 1.0402, Accuracy: 56.25%\n",
      "Epoch [5/30], Step [20/497], Loss: 1.2511, Accuracy: 43.75%\n",
      "Epoch [5/30], Step [30/497], Loss: 1.3123, Accuracy: 40.62%\n",
      "Epoch [5/30], Step [40/497], Loss: 1.1509, Accuracy: 53.12%\n",
      "Epoch [5/30], Step [50/497], Loss: 1.1711, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [60/497], Loss: 1.3098, Accuracy: 46.88%\n",
      "Epoch [5/30], Step [70/497], Loss: 1.1412, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [80/497], Loss: 1.1965, Accuracy: 53.12%\n",
      "Epoch [5/30], Step [90/497], Loss: 1.2781, Accuracy: 40.62%\n",
      "Epoch [5/30], Step [100/497], Loss: 1.0525, Accuracy: 53.12%\n",
      "Epoch [5/30], Step [110/497], Loss: 1.0939, Accuracy: 59.38%\n",
      "Epoch [5/30], Step [120/497], Loss: 1.0638, Accuracy: 56.25%\n",
      "Epoch [5/30], Step [130/497], Loss: 1.2202, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [140/497], Loss: 1.1079, Accuracy: 59.38%\n",
      "Epoch [5/30], Step [150/497], Loss: 1.1909, Accuracy: 43.75%\n",
      "Epoch [5/30], Step [160/497], Loss: 1.0398, Accuracy: 71.88%\n",
      "Epoch [5/30], Step [170/497], Loss: 1.2991, Accuracy: 40.62%\n",
      "Epoch [5/30], Step [180/497], Loss: 1.2354, Accuracy: 46.88%\n",
      "Epoch [5/30], Step [190/497], Loss: 1.1347, Accuracy: 46.88%\n",
      "Epoch [5/30], Step [200/497], Loss: 1.0396, Accuracy: 56.25%\n",
      "Epoch [5/30], Step [210/497], Loss: 1.1452, Accuracy: 43.75%\n",
      "Epoch [5/30], Step [220/497], Loss: 1.0924, Accuracy: 53.12%\n",
      "Epoch [5/30], Step [230/497], Loss: 1.3985, Accuracy: 31.25%\n",
      "Epoch [5/30], Step [240/497], Loss: 1.1987, Accuracy: 46.88%\n",
      "Epoch [5/30], Step [250/497], Loss: 1.2296, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [260/497], Loss: 1.1521, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [270/497], Loss: 1.2161, Accuracy: 43.75%\n",
      "Epoch [5/30], Step [280/497], Loss: 1.2508, Accuracy: 46.88%\n",
      "Epoch [5/30], Step [290/497], Loss: 1.1554, Accuracy: 46.88%\n",
      "Epoch [5/30], Step [300/497], Loss: 1.4490, Accuracy: 31.25%\n",
      "Epoch [5/30], Step [310/497], Loss: 1.1661, Accuracy: 43.75%\n",
      "Epoch [5/30], Step [320/497], Loss: 1.2597, Accuracy: 37.50%\n",
      "Epoch [5/30], Step [330/497], Loss: 1.2673, Accuracy: 28.12%\n",
      "Epoch [5/30], Step [340/497], Loss: 1.1777, Accuracy: 46.88%\n",
      "Epoch [5/30], Step [350/497], Loss: 1.1066, Accuracy: 56.25%\n",
      "Epoch [5/30], Step [360/497], Loss: 1.0286, Accuracy: 59.38%\n",
      "Epoch [5/30], Step [370/497], Loss: 1.1960, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [380/497], Loss: 1.2993, Accuracy: 34.38%\n",
      "Epoch [5/30], Step [390/497], Loss: 1.2425, Accuracy: 43.75%\n",
      "Epoch [5/30], Step [400/497], Loss: 1.0986, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [410/497], Loss: 1.0419, Accuracy: 62.50%\n",
      "Epoch [5/30], Step [420/497], Loss: 1.1891, Accuracy: 40.62%\n",
      "Epoch [5/30], Step [430/497], Loss: 1.3419, Accuracy: 43.75%\n",
      "Epoch [5/30], Step [440/497], Loss: 1.1742, Accuracy: 40.62%\n",
      "Epoch [5/30], Step [450/497], Loss: 1.1327, Accuracy: 46.88%\n",
      "Epoch [5/30], Step [460/497], Loss: 1.3746, Accuracy: 31.25%\n",
      "Epoch [5/30], Step [470/497], Loss: 1.1106, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [480/497], Loss: 1.1687, Accuracy: 50.00%\n",
      "Epoch [5/30], Step [490/497], Loss: 1.0489, Accuracy: 59.38%\n",
      "Epoch [6/30], Step [10/497], Loss: 1.2959, Accuracy: 40.62%\n",
      "Epoch [6/30], Step [20/497], Loss: 1.0090, Accuracy: 59.38%\n",
      "Epoch [6/30], Step [30/497], Loss: 1.1024, Accuracy: 40.62%\n",
      "Epoch [6/30], Step [40/497], Loss: 1.0873, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [50/497], Loss: 1.1592, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [60/497], Loss: 1.2239, Accuracy: 31.25%\n",
      "Epoch [6/30], Step [70/497], Loss: 1.1387, Accuracy: 40.62%\n",
      "Epoch [6/30], Step [80/497], Loss: 1.2384, Accuracy: 56.25%\n",
      "Epoch [6/30], Step [90/497], Loss: 1.2045, Accuracy: 53.12%\n",
      "Epoch [6/30], Step [100/497], Loss: 0.9792, Accuracy: 62.50%\n",
      "Epoch [6/30], Step [110/497], Loss: 1.2393, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [120/497], Loss: 1.2739, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [130/497], Loss: 1.1234, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [140/497], Loss: 1.1169, Accuracy: 46.88%\n",
      "Epoch [6/30], Step [150/497], Loss: 1.1991, Accuracy: 53.12%\n",
      "Epoch [6/30], Step [160/497], Loss: 1.3273, Accuracy: 43.75%\n",
      "Epoch [6/30], Step [170/497], Loss: 1.1778, Accuracy: 46.88%\n",
      "Epoch [6/30], Step [180/497], Loss: 1.1057, Accuracy: 62.50%\n",
      "Epoch [6/30], Step [190/497], Loss: 1.1228, Accuracy: 53.12%\n",
      "Epoch [6/30], Step [200/497], Loss: 1.1447, Accuracy: 59.38%\n",
      "Epoch [6/30], Step [210/497], Loss: 1.2851, Accuracy: 31.25%\n",
      "Epoch [6/30], Step [220/497], Loss: 1.1506, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [230/497], Loss: 1.0513, Accuracy: 62.50%\n",
      "Epoch [6/30], Step [240/497], Loss: 1.0751, Accuracy: 53.12%\n",
      "Epoch [6/30], Step [250/497], Loss: 1.1497, Accuracy: 56.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Step [260/497], Loss: 1.0858, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [270/497], Loss: 0.9967, Accuracy: 68.75%\n",
      "Epoch [6/30], Step [280/497], Loss: 1.2384, Accuracy: 40.62%\n",
      "Epoch [6/30], Step [290/497], Loss: 1.3068, Accuracy: 40.62%\n",
      "Epoch [6/30], Step [300/497], Loss: 1.1690, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [310/497], Loss: 1.1110, Accuracy: 59.38%\n",
      "Epoch [6/30], Step [320/497], Loss: 1.2480, Accuracy: 40.62%\n",
      "Epoch [6/30], Step [330/497], Loss: 1.3127, Accuracy: 31.25%\n",
      "Epoch [6/30], Step [340/497], Loss: 1.2933, Accuracy: 43.75%\n",
      "Epoch [6/30], Step [350/497], Loss: 1.2542, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [360/497], Loss: 1.2313, Accuracy: 37.50%\n",
      "Epoch [6/30], Step [370/497], Loss: 1.3429, Accuracy: 43.75%\n",
      "Epoch [6/30], Step [380/497], Loss: 1.2756, Accuracy: 40.62%\n",
      "Epoch [6/30], Step [390/497], Loss: 1.2020, Accuracy: 46.88%\n",
      "Epoch [6/30], Step [400/497], Loss: 1.1309, Accuracy: 56.25%\n",
      "Epoch [6/30], Step [410/497], Loss: 1.2383, Accuracy: 43.75%\n",
      "Epoch [6/30], Step [420/497], Loss: 1.0667, Accuracy: 53.12%\n",
      "Epoch [6/30], Step [430/497], Loss: 1.3401, Accuracy: 53.12%\n",
      "Epoch [6/30], Step [440/497], Loss: 1.0587, Accuracy: 53.12%\n",
      "Epoch [6/30], Step [450/497], Loss: 1.2770, Accuracy: 40.62%\n",
      "Epoch [6/30], Step [460/497], Loss: 1.0983, Accuracy: 59.38%\n",
      "Epoch [6/30], Step [470/497], Loss: 1.1881, Accuracy: 50.00%\n",
      "Epoch [6/30], Step [480/497], Loss: 1.1694, Accuracy: 43.75%\n",
      "Epoch [6/30], Step [490/497], Loss: 1.1610, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [10/497], Loss: 1.2208, Accuracy: 53.12%\n",
      "Epoch [7/30], Step [20/497], Loss: 1.1903, Accuracy: 53.12%\n",
      "Epoch [7/30], Step [30/497], Loss: 1.2679, Accuracy: 43.75%\n",
      "Epoch [7/30], Step [40/497], Loss: 1.2539, Accuracy: 40.62%\n",
      "Epoch [7/30], Step [50/497], Loss: 1.1441, Accuracy: 59.38%\n",
      "Epoch [7/30], Step [60/497], Loss: 1.2748, Accuracy: 43.75%\n",
      "Epoch [7/30], Step [70/497], Loss: 1.2535, Accuracy: 34.38%\n",
      "Epoch [7/30], Step [80/497], Loss: 1.3542, Accuracy: 31.25%\n",
      "Epoch [7/30], Step [90/497], Loss: 1.2540, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [100/497], Loss: 1.2226, Accuracy: 40.62%\n",
      "Epoch [7/30], Step [110/497], Loss: 1.1847, Accuracy: 56.25%\n",
      "Epoch [7/30], Step [120/497], Loss: 1.3473, Accuracy: 34.38%\n",
      "Epoch [7/30], Step [130/497], Loss: 1.2275, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [140/497], Loss: 1.0162, Accuracy: 65.62%\n",
      "Epoch [7/30], Step [150/497], Loss: 1.1591, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [160/497], Loss: 1.0253, Accuracy: 68.75%\n",
      "Epoch [7/30], Step [170/497], Loss: 1.3250, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [180/497], Loss: 1.2785, Accuracy: 40.62%\n",
      "Epoch [7/30], Step [190/497], Loss: 1.1696, Accuracy: 62.50%\n",
      "Epoch [7/30], Step [200/497], Loss: 1.0636, Accuracy: 56.25%\n",
      "Epoch [7/30], Step [210/497], Loss: 1.0892, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [220/497], Loss: 1.2874, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [230/497], Loss: 1.0905, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [240/497], Loss: 1.3051, Accuracy: 43.75%\n",
      "Epoch [7/30], Step [250/497], Loss: 1.2635, Accuracy: 40.62%\n",
      "Epoch [7/30], Step [260/497], Loss: 1.2640, Accuracy: 40.62%\n",
      "Epoch [7/30], Step [270/497], Loss: 1.1721, Accuracy: 43.75%\n",
      "Epoch [7/30], Step [280/497], Loss: 1.2771, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [290/497], Loss: 1.1200, Accuracy: 53.12%\n",
      "Epoch [7/30], Step [300/497], Loss: 1.3320, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [310/497], Loss: 1.1242, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [320/497], Loss: 1.3270, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [330/497], Loss: 1.1733, Accuracy: 56.25%\n",
      "Epoch [7/30], Step [340/497], Loss: 1.2544, Accuracy: 56.25%\n",
      "Epoch [7/30], Step [350/497], Loss: 1.1833, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [360/497], Loss: 1.1299, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [370/497], Loss: 1.2006, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [380/497], Loss: 1.1464, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [390/497], Loss: 1.1807, Accuracy: 43.75%\n",
      "Epoch [7/30], Step [400/497], Loss: 1.2634, Accuracy: 40.62%\n",
      "Epoch [7/30], Step [410/497], Loss: 1.2243, Accuracy: 53.12%\n",
      "Epoch [7/30], Step [420/497], Loss: 1.1283, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [430/497], Loss: 1.2115, Accuracy: 53.12%\n",
      "Epoch [7/30], Step [440/497], Loss: 1.2625, Accuracy: 46.88%\n",
      "Epoch [7/30], Step [450/497], Loss: 1.1940, Accuracy: 53.12%\n",
      "Epoch [7/30], Step [460/497], Loss: 1.1764, Accuracy: 50.00%\n",
      "Epoch [7/30], Step [470/497], Loss: 1.2919, Accuracy: 43.75%\n",
      "Epoch [7/30], Step [480/497], Loss: 1.0330, Accuracy: 59.38%\n",
      "Epoch [7/30], Step [490/497], Loss: 1.1691, Accuracy: 46.88%\n",
      "Epoch [8/30], Step [10/497], Loss: 1.1775, Accuracy: 53.12%\n",
      "Epoch [8/30], Step [20/497], Loss: 1.1226, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [30/497], Loss: 1.2359, Accuracy: 37.50%\n",
      "Epoch [8/30], Step [40/497], Loss: 1.0736, Accuracy: 62.50%\n",
      "Epoch [8/30], Step [50/497], Loss: 1.2736, Accuracy: 34.38%\n",
      "Epoch [8/30], Step [60/497], Loss: 1.1320, Accuracy: 46.88%\n",
      "Epoch [8/30], Step [70/497], Loss: 1.1092, Accuracy: 62.50%\n",
      "Epoch [8/30], Step [80/497], Loss: 1.3860, Accuracy: 40.62%\n",
      "Epoch [8/30], Step [90/497], Loss: 1.1179, Accuracy: 46.88%\n",
      "Epoch [8/30], Step [100/497], Loss: 1.3280, Accuracy: 28.12%\n",
      "Epoch [8/30], Step [110/497], Loss: 1.3726, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [120/497], Loss: 1.2523, Accuracy: 46.88%\n",
      "Epoch [8/30], Step [130/497], Loss: 1.1653, Accuracy: 43.75%\n",
      "Epoch [8/30], Step [140/497], Loss: 1.0651, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [150/497], Loss: 1.2320, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [160/497], Loss: 1.2776, Accuracy: 40.62%\n",
      "Epoch [8/30], Step [170/497], Loss: 1.2610, Accuracy: 46.88%\n",
      "Epoch [8/30], Step [180/497], Loss: 1.2044, Accuracy: 56.25%\n",
      "Epoch [8/30], Step [190/497], Loss: 1.4217, Accuracy: 37.50%\n",
      "Epoch [8/30], Step [200/497], Loss: 1.1946, Accuracy: 43.75%\n",
      "Epoch [8/30], Step [210/497], Loss: 1.3781, Accuracy: 34.38%\n",
      "Epoch [8/30], Step [220/497], Loss: 1.1617, Accuracy: 56.25%\n",
      "Epoch [8/30], Step [230/497], Loss: 1.2342, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [240/497], Loss: 1.2625, Accuracy: 37.50%\n",
      "Epoch [8/30], Step [250/497], Loss: 1.3657, Accuracy: 34.38%\n",
      "Epoch [8/30], Step [260/497], Loss: 1.3110, Accuracy: 40.62%\n",
      "Epoch [8/30], Step [270/497], Loss: 1.1427, Accuracy: 43.75%\n",
      "Epoch [8/30], Step [280/497], Loss: 1.2047, Accuracy: 56.25%\n",
      "Epoch [8/30], Step [290/497], Loss: 1.2230, Accuracy: 34.38%\n",
      "Epoch [8/30], Step [300/497], Loss: 1.1929, Accuracy: 40.62%\n",
      "Epoch [8/30], Step [310/497], Loss: 1.1337, Accuracy: 59.38%\n",
      "Epoch [8/30], Step [320/497], Loss: 1.1058, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [330/497], Loss: 1.1589, Accuracy: 53.12%\n",
      "Epoch [8/30], Step [340/497], Loss: 1.1330, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [350/497], Loss: 1.2591, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [360/497], Loss: 1.2389, Accuracy: 46.88%\n",
      "Epoch [8/30], Step [370/497], Loss: 1.1046, Accuracy: 53.12%\n",
      "Epoch [8/30], Step [380/497], Loss: 1.2953, Accuracy: 40.62%\n",
      "Epoch [8/30], Step [390/497], Loss: 1.0802, Accuracy: 53.12%\n",
      "Epoch [8/30], Step [400/497], Loss: 1.0830, Accuracy: 56.25%\n",
      "Epoch [8/30], Step [410/497], Loss: 1.1083, Accuracy: 56.25%\n",
      "Epoch [8/30], Step [420/497], Loss: 1.2502, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [430/497], Loss: 1.1775, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [440/497], Loss: 1.0622, Accuracy: 62.50%\n",
      "Epoch [8/30], Step [450/497], Loss: 1.1156, Accuracy: 50.00%\n",
      "Epoch [8/30], Step [460/497], Loss: 1.1465, Accuracy: 53.12%\n",
      "Epoch [8/30], Step [470/497], Loss: 1.3519, Accuracy: 34.38%\n",
      "Epoch [8/30], Step [480/497], Loss: 1.1004, Accuracy: 43.75%\n",
      "Epoch [8/30], Step [490/497], Loss: 1.2076, Accuracy: 40.62%\n",
      "Epoch [9/30], Step [10/497], Loss: 1.1005, Accuracy: 53.12%\n",
      "Epoch [9/30], Step [20/497], Loss: 1.1683, Accuracy: 56.25%\n",
      "Epoch [9/30], Step [30/497], Loss: 1.2768, Accuracy: 34.38%\n",
      "Epoch [9/30], Step [40/497], Loss: 1.2324, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [50/497], Loss: 1.3156, Accuracy: 40.62%\n",
      "Epoch [9/30], Step [60/497], Loss: 1.3500, Accuracy: 37.50%\n",
      "Epoch [9/30], Step [70/497], Loss: 1.2433, Accuracy: 43.75%\n",
      "Epoch [9/30], Step [80/497], Loss: 1.2492, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [90/497], Loss: 1.2199, Accuracy: 50.00%\n",
      "Epoch [9/30], Step [100/497], Loss: 1.1877, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [110/497], Loss: 1.1999, Accuracy: 50.00%\n",
      "Epoch [9/30], Step [120/497], Loss: 1.2710, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [130/497], Loss: 1.2252, Accuracy: 37.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Step [140/497], Loss: 1.0318, Accuracy: 68.75%\n",
      "Epoch [9/30], Step [150/497], Loss: 1.3773, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [160/497], Loss: 1.1683, Accuracy: 50.00%\n",
      "Epoch [9/30], Step [170/497], Loss: 1.1545, Accuracy: 56.25%\n",
      "Epoch [9/30], Step [180/497], Loss: 1.1182, Accuracy: 50.00%\n",
      "Epoch [9/30], Step [190/497], Loss: 1.2163, Accuracy: 37.50%\n",
      "Epoch [9/30], Step [200/497], Loss: 1.1980, Accuracy: 25.00%\n",
      "Epoch [9/30], Step [210/497], Loss: 1.2280, Accuracy: 43.75%\n",
      "Epoch [9/30], Step [220/497], Loss: 1.2022, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [230/497], Loss: 1.1832, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [240/497], Loss: 1.2612, Accuracy: 40.62%\n",
      "Epoch [9/30], Step [250/497], Loss: 1.1892, Accuracy: 53.12%\n",
      "Epoch [9/30], Step [260/497], Loss: 1.2202, Accuracy: 53.12%\n",
      "Epoch [9/30], Step [270/497], Loss: 1.0702, Accuracy: 62.50%\n",
      "Epoch [9/30], Step [280/497], Loss: 1.2058, Accuracy: 50.00%\n",
      "Epoch [9/30], Step [290/497], Loss: 1.2658, Accuracy: 53.12%\n",
      "Epoch [9/30], Step [300/497], Loss: 1.3230, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [310/497], Loss: 1.1360, Accuracy: 34.38%\n",
      "Epoch [9/30], Step [320/497], Loss: 1.1339, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [330/497], Loss: 1.0197, Accuracy: 62.50%\n",
      "Epoch [9/30], Step [340/497], Loss: 1.2912, Accuracy: 46.88%\n",
      "Epoch [9/30], Step [350/497], Loss: 1.2208, Accuracy: 40.62%\n",
      "Epoch [9/30], Step [360/497], Loss: 1.0775, Accuracy: 56.25%\n",
      "Epoch [9/30], Step [370/497], Loss: 1.3938, Accuracy: 37.50%\n",
      "Epoch [9/30], Step [380/497], Loss: 1.2777, Accuracy: 43.75%\n",
      "Epoch [9/30], Step [390/497], Loss: 1.1456, Accuracy: 53.12%\n",
      "Epoch [9/30], Step [400/497], Loss: 1.2121, Accuracy: 53.12%\n",
      "Epoch [9/30], Step [410/497], Loss: 1.1614, Accuracy: 28.12%\n",
      "Epoch [9/30], Step [420/497], Loss: 1.2651, Accuracy: 40.62%\n",
      "Epoch [9/30], Step [430/497], Loss: 1.2931, Accuracy: 34.38%\n",
      "Epoch [9/30], Step [440/497], Loss: 1.1728, Accuracy: 50.00%\n",
      "Epoch [9/30], Step [450/497], Loss: 1.3239, Accuracy: 34.38%\n",
      "Epoch [9/30], Step [460/497], Loss: 1.0539, Accuracy: 62.50%\n",
      "Epoch [9/30], Step [470/497], Loss: 0.8947, Accuracy: 75.00%\n",
      "Epoch [9/30], Step [480/497], Loss: 1.1464, Accuracy: 53.12%\n",
      "Epoch [9/30], Step [490/497], Loss: 1.1143, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [10/497], Loss: 1.3132, Accuracy: 46.88%\n",
      "Epoch [10/30], Step [20/497], Loss: 1.1411, Accuracy: 53.12%\n",
      "Epoch [10/30], Step [30/497], Loss: 1.1400, Accuracy: 53.12%\n",
      "Epoch [10/30], Step [40/497], Loss: 1.2451, Accuracy: 43.75%\n",
      "Epoch [10/30], Step [50/497], Loss: 1.2371, Accuracy: 37.50%\n",
      "Epoch [10/30], Step [60/497], Loss: 1.2253, Accuracy: 43.75%\n",
      "Epoch [10/30], Step [70/497], Loss: 1.0797, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [80/497], Loss: 1.0823, Accuracy: 59.38%\n",
      "Epoch [10/30], Step [90/497], Loss: 1.3857, Accuracy: 40.62%\n",
      "Epoch [10/30], Step [100/497], Loss: 1.1463, Accuracy: 46.88%\n",
      "Epoch [10/30], Step [110/497], Loss: 1.2802, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [120/497], Loss: 1.1802, Accuracy: 56.25%\n",
      "Epoch [10/30], Step [130/497], Loss: 1.3000, Accuracy: 40.62%\n",
      "Epoch [10/30], Step [140/497], Loss: 1.0711, Accuracy: 56.25%\n",
      "Epoch [10/30], Step [150/497], Loss: 1.1163, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [160/497], Loss: 1.2642, Accuracy: 46.88%\n",
      "Epoch [10/30], Step [170/497], Loss: 1.1259, Accuracy: 59.38%\n",
      "Epoch [10/30], Step [180/497], Loss: 1.3155, Accuracy: 37.50%\n",
      "Epoch [10/30], Step [190/497], Loss: 1.2014, Accuracy: 37.50%\n",
      "Epoch [10/30], Step [200/497], Loss: 1.2124, Accuracy: 46.88%\n",
      "Epoch [10/30], Step [210/497], Loss: 1.1548, Accuracy: 53.12%\n",
      "Epoch [10/30], Step [220/497], Loss: 1.3702, Accuracy: 34.38%\n",
      "Epoch [10/30], Step [230/497], Loss: 1.0317, Accuracy: 56.25%\n",
      "Epoch [10/30], Step [240/497], Loss: 1.3278, Accuracy: 37.50%\n",
      "Epoch [10/30], Step [250/497], Loss: 1.1673, Accuracy: 56.25%\n",
      "Epoch [10/30], Step [260/497], Loss: 1.1735, Accuracy: 53.12%\n",
      "Epoch [10/30], Step [270/497], Loss: 1.1476, Accuracy: 53.12%\n",
      "Epoch [10/30], Step [280/497], Loss: 1.2088, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [290/497], Loss: 1.1836, Accuracy: 46.88%\n",
      "Epoch [10/30], Step [300/497], Loss: 1.1651, Accuracy: 46.88%\n",
      "Epoch [10/30], Step [310/497], Loss: 1.1732, Accuracy: 40.62%\n",
      "Epoch [10/30], Step [320/497], Loss: 1.4858, Accuracy: 25.00%\n",
      "Epoch [10/30], Step [330/497], Loss: 1.1218, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [340/497], Loss: 1.1529, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [350/497], Loss: 1.1716, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [360/497], Loss: 1.2285, Accuracy: 43.75%\n",
      "Epoch [10/30], Step [370/497], Loss: 1.2630, Accuracy: 43.75%\n",
      "Epoch [10/30], Step [380/497], Loss: 1.4224, Accuracy: 31.25%\n",
      "Epoch [10/30], Step [390/497], Loss: 1.1063, Accuracy: 53.12%\n",
      "Epoch [10/30], Step [400/497], Loss: 1.0332, Accuracy: 62.50%\n",
      "Epoch [10/30], Step [410/497], Loss: 1.1149, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [420/497], Loss: 1.2164, Accuracy: 43.75%\n",
      "Epoch [10/30], Step [430/497], Loss: 1.1846, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [440/497], Loss: 1.1375, Accuracy: 53.12%\n",
      "Epoch [10/30], Step [450/497], Loss: 1.2420, Accuracy: 43.75%\n",
      "Epoch [10/30], Step [460/497], Loss: 1.3677, Accuracy: 28.12%\n",
      "Epoch [10/30], Step [470/497], Loss: 1.1069, Accuracy: 59.38%\n",
      "Epoch [10/30], Step [480/497], Loss: 1.1538, Accuracy: 50.00%\n",
      "Epoch [10/30], Step [490/497], Loss: 1.2049, Accuracy: 37.50%\n",
      "Epoch [11/30], Step [10/497], Loss: 1.2482, Accuracy: 62.50%\n",
      "Epoch [11/30], Step [20/497], Loss: 1.0669, Accuracy: 56.25%\n",
      "Epoch [11/30], Step [30/497], Loss: 1.3480, Accuracy: 34.38%\n",
      "Epoch [11/30], Step [40/497], Loss: 1.1105, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [50/497], Loss: 1.0757, Accuracy: 53.12%\n",
      "Epoch [11/30], Step [60/497], Loss: 1.1593, Accuracy: 40.62%\n",
      "Epoch [11/30], Step [70/497], Loss: 1.2844, Accuracy: 40.62%\n",
      "Epoch [11/30], Step [80/497], Loss: 1.0491, Accuracy: 68.75%\n",
      "Epoch [11/30], Step [90/497], Loss: 1.3205, Accuracy: 40.62%\n",
      "Epoch [11/30], Step [100/497], Loss: 1.2753, Accuracy: 37.50%\n",
      "Epoch [11/30], Step [110/497], Loss: 1.1530, Accuracy: 56.25%\n",
      "Epoch [11/30], Step [120/497], Loss: 1.2537, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [130/497], Loss: 1.1639, Accuracy: 53.12%\n",
      "Epoch [11/30], Step [140/497], Loss: 1.3635, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [150/497], Loss: 1.1602, Accuracy: 37.50%\n",
      "Epoch [11/30], Step [160/497], Loss: 1.0209, Accuracy: 53.12%\n",
      "Epoch [11/30], Step [170/497], Loss: 1.1681, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [180/497], Loss: 1.2199, Accuracy: 34.38%\n",
      "Epoch [11/30], Step [190/497], Loss: 1.1102, Accuracy: 46.88%\n",
      "Epoch [11/30], Step [200/497], Loss: 1.3427, Accuracy: 31.25%\n",
      "Epoch [11/30], Step [210/497], Loss: 1.2848, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [220/497], Loss: 1.2038, Accuracy: 46.88%\n",
      "Epoch [11/30], Step [230/497], Loss: 1.1811, Accuracy: 46.88%\n",
      "Epoch [11/30], Step [240/497], Loss: 1.2052, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [250/497], Loss: 1.1258, Accuracy: 50.00%\n",
      "Epoch [11/30], Step [260/497], Loss: 1.1194, Accuracy: 59.38%\n",
      "Epoch [11/30], Step [270/497], Loss: 1.2012, Accuracy: 46.88%\n",
      "Epoch [11/30], Step [280/497], Loss: 1.3765, Accuracy: 46.88%\n",
      "Epoch [11/30], Step [290/497], Loss: 1.4188, Accuracy: 25.00%\n",
      "Epoch [11/30], Step [300/497], Loss: 1.3224, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [310/497], Loss: 1.1529, Accuracy: 62.50%\n",
      "Epoch [11/30], Step [320/497], Loss: 1.1738, Accuracy: 46.88%\n",
      "Epoch [11/30], Step [330/497], Loss: 1.2319, Accuracy: 46.88%\n",
      "Epoch [11/30], Step [340/497], Loss: 1.1571, Accuracy: 56.25%\n",
      "Epoch [11/30], Step [350/497], Loss: 1.1948, Accuracy: 50.00%\n",
      "Epoch [11/30], Step [360/497], Loss: 1.0429, Accuracy: 59.38%\n",
      "Epoch [11/30], Step [370/497], Loss: 1.2908, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [380/497], Loss: 1.2365, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [390/497], Loss: 1.1564, Accuracy: 59.38%\n",
      "Epoch [11/30], Step [400/497], Loss: 1.2383, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [410/497], Loss: 1.1402, Accuracy: 56.25%\n",
      "Epoch [11/30], Step [420/497], Loss: 1.2532, Accuracy: 25.00%\n",
      "Epoch [11/30], Step [430/497], Loss: 1.1627, Accuracy: 43.75%\n",
      "Epoch [11/30], Step [440/497], Loss: 1.4483, Accuracy: 31.25%\n",
      "Epoch [11/30], Step [450/497], Loss: 1.3320, Accuracy: 34.38%\n",
      "Epoch [11/30], Step [460/497], Loss: 1.0824, Accuracy: 62.50%\n",
      "Epoch [11/30], Step [470/497], Loss: 1.2510, Accuracy: 46.88%\n",
      "Epoch [11/30], Step [480/497], Loss: 1.2521, Accuracy: 40.62%\n",
      "Epoch [11/30], Step [490/497], Loss: 1.2605, Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Step [10/497], Loss: 1.1733, Accuracy: 37.50%\n",
      "Epoch [12/30], Step [20/497], Loss: 1.1342, Accuracy: 53.12%\n",
      "Epoch [12/30], Step [30/497], Loss: 1.2207, Accuracy: 46.88%\n",
      "Epoch [12/30], Step [40/497], Loss: 1.1291, Accuracy: 53.12%\n",
      "Epoch [12/30], Step [50/497], Loss: 1.0702, Accuracy: 56.25%\n",
      "Epoch [12/30], Step [60/497], Loss: 1.1431, Accuracy: 56.25%\n",
      "Epoch [12/30], Step [70/497], Loss: 1.2174, Accuracy: 50.00%\n",
      "Epoch [12/30], Step [80/497], Loss: 1.2040, Accuracy: 37.50%\n",
      "Epoch [12/30], Step [90/497], Loss: 1.2224, Accuracy: 43.75%\n",
      "Epoch [12/30], Step [100/497], Loss: 1.2216, Accuracy: 37.50%\n",
      "Epoch [12/30], Step [110/497], Loss: 1.2118, Accuracy: 37.50%\n",
      "Epoch [12/30], Step [120/497], Loss: 1.1194, Accuracy: 53.12%\n",
      "Epoch [12/30], Step [130/497], Loss: 1.0470, Accuracy: 62.50%\n",
      "Epoch [12/30], Step [140/497], Loss: 1.1169, Accuracy: 59.38%\n",
      "Epoch [12/30], Step [150/497], Loss: 1.2253, Accuracy: 34.38%\n",
      "Epoch [12/30], Step [160/497], Loss: 1.1819, Accuracy: 40.62%\n",
      "Epoch [12/30], Step [170/497], Loss: 1.2676, Accuracy: 43.75%\n",
      "Epoch [12/30], Step [180/497], Loss: 1.3743, Accuracy: 34.38%\n",
      "Epoch [12/30], Step [190/497], Loss: 1.2008, Accuracy: 50.00%\n",
      "Epoch [12/30], Step [200/497], Loss: 1.0020, Accuracy: 53.12%\n",
      "Epoch [12/30], Step [210/497], Loss: 1.2418, Accuracy: 43.75%\n",
      "Epoch [12/30], Step [220/497], Loss: 1.3177, Accuracy: 43.75%\n",
      "Epoch [12/30], Step [230/497], Loss: 1.0767, Accuracy: 50.00%\n",
      "Epoch [12/30], Step [240/497], Loss: 1.1797, Accuracy: 53.12%\n",
      "Epoch [12/30], Step [250/497], Loss: 1.2602, Accuracy: 40.62%\n",
      "Epoch [12/30], Step [260/497], Loss: 1.1557, Accuracy: 46.88%\n",
      "Epoch [12/30], Step [270/497], Loss: 1.1915, Accuracy: 46.88%\n",
      "Epoch [12/30], Step [280/497], Loss: 1.2985, Accuracy: 37.50%\n",
      "Epoch [12/30], Step [290/497], Loss: 1.2287, Accuracy: 46.88%\n",
      "Epoch [12/30], Step [300/497], Loss: 1.1800, Accuracy: 46.88%\n",
      "Epoch [12/30], Step [310/497], Loss: 1.1961, Accuracy: 50.00%\n",
      "Epoch [12/30], Step [320/497], Loss: 0.9875, Accuracy: 62.50%\n",
      "Epoch [12/30], Step [330/497], Loss: 1.1645, Accuracy: 40.62%\n",
      "Epoch [12/30], Step [340/497], Loss: 1.2455, Accuracy: 37.50%\n",
      "Epoch [12/30], Step [350/497], Loss: 1.1609, Accuracy: 40.62%\n",
      "Epoch [12/30], Step [360/497], Loss: 1.0376, Accuracy: 59.38%\n",
      "Epoch [12/30], Step [370/497], Loss: 1.0204, Accuracy: 56.25%\n",
      "Epoch [12/30], Step [380/497], Loss: 1.1995, Accuracy: 50.00%\n",
      "Epoch [12/30], Step [390/497], Loss: 1.2257, Accuracy: 53.12%\n",
      "Epoch [12/30], Step [400/497], Loss: 1.0894, Accuracy: 56.25%\n",
      "Epoch [12/30], Step [410/497], Loss: 1.1973, Accuracy: 43.75%\n",
      "Epoch [12/30], Step [420/497], Loss: 1.3197, Accuracy: 46.88%\n",
      "Epoch [12/30], Step [430/497], Loss: 1.0042, Accuracy: 59.38%\n",
      "Epoch [12/30], Step [440/497], Loss: 1.0661, Accuracy: 56.25%\n",
      "Epoch [12/30], Step [450/497], Loss: 1.3919, Accuracy: 43.75%\n",
      "Epoch [12/30], Step [460/497], Loss: 1.2167, Accuracy: 43.75%\n",
      "Epoch [12/30], Step [470/497], Loss: 1.0557, Accuracy: 65.62%\n",
      "Epoch [12/30], Step [480/497], Loss: 1.2837, Accuracy: 40.62%\n",
      "Epoch [12/30], Step [490/497], Loss: 1.3812, Accuracy: 34.38%\n",
      "Epoch [13/30], Step [10/497], Loss: 1.2049, Accuracy: 53.12%\n",
      "Epoch [13/30], Step [20/497], Loss: 1.1205, Accuracy: 53.12%\n",
      "Epoch [13/30], Step [30/497], Loss: 1.0438, Accuracy: 50.00%\n",
      "Epoch [13/30], Step [40/497], Loss: 1.1062, Accuracy: 50.00%\n",
      "Epoch [13/30], Step [50/497], Loss: 1.1956, Accuracy: 53.12%\n",
      "Epoch [13/30], Step [60/497], Loss: 1.1468, Accuracy: 50.00%\n",
      "Epoch [13/30], Step [70/497], Loss: 1.3245, Accuracy: 40.62%\n",
      "Epoch [13/30], Step [80/497], Loss: 1.1224, Accuracy: 53.12%\n",
      "Epoch [13/30], Step [90/497], Loss: 1.3584, Accuracy: 37.50%\n",
      "Epoch [13/30], Step [100/497], Loss: 1.2106, Accuracy: 50.00%\n",
      "Epoch [13/30], Step [110/497], Loss: 1.2310, Accuracy: 40.62%\n",
      "Epoch [13/30], Step [120/497], Loss: 1.1594, Accuracy: 50.00%\n",
      "Epoch [13/30], Step [130/497], Loss: 1.4061, Accuracy: 21.88%\n",
      "Epoch [13/30], Step [140/497], Loss: 1.1560, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [150/497], Loss: 1.1919, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [160/497], Loss: 1.1575, Accuracy: 56.25%\n",
      "Epoch [13/30], Step [170/497], Loss: 1.2519, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [180/497], Loss: 1.2437, Accuracy: 50.00%\n",
      "Epoch [13/30], Step [190/497], Loss: 1.1391, Accuracy: 56.25%\n",
      "Epoch [13/30], Step [200/497], Loss: 1.1236, Accuracy: 56.25%\n",
      "Epoch [13/30], Step [210/497], Loss: 1.0606, Accuracy: 56.25%\n",
      "Epoch [13/30], Step [220/497], Loss: 1.1904, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [230/497], Loss: 1.1882, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [240/497], Loss: 1.2019, Accuracy: 53.12%\n",
      "Epoch [13/30], Step [250/497], Loss: 1.2437, Accuracy: 34.38%\n",
      "Epoch [13/30], Step [260/497], Loss: 1.1095, Accuracy: 56.25%\n",
      "Epoch [13/30], Step [270/497], Loss: 1.2791, Accuracy: 37.50%\n",
      "Epoch [13/30], Step [280/497], Loss: 1.1513, Accuracy: 50.00%\n",
      "Epoch [13/30], Step [290/497], Loss: 1.3555, Accuracy: 37.50%\n",
      "Epoch [13/30], Step [300/497], Loss: 1.1497, Accuracy: 53.12%\n",
      "Epoch [13/30], Step [310/497], Loss: 1.2281, Accuracy: 40.62%\n",
      "Epoch [13/30], Step [320/497], Loss: 1.1242, Accuracy: 53.12%\n",
      "Epoch [13/30], Step [330/497], Loss: 1.1031, Accuracy: 46.88%\n",
      "Epoch [13/30], Step [340/497], Loss: 1.2242, Accuracy: 46.88%\n",
      "Epoch [13/30], Step [350/497], Loss: 1.1240, Accuracy: 62.50%\n",
      "Epoch [13/30], Step [360/497], Loss: 1.3564, Accuracy: 37.50%\n",
      "Epoch [13/30], Step [370/497], Loss: 1.2938, Accuracy: 50.00%\n",
      "Epoch [13/30], Step [380/497], Loss: 1.3278, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [390/497], Loss: 1.0470, Accuracy: 62.50%\n",
      "Epoch [13/30], Step [400/497], Loss: 1.1593, Accuracy: 46.88%\n",
      "Epoch [13/30], Step [410/497], Loss: 1.2683, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [420/497], Loss: 1.1792, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [430/497], Loss: 1.1929, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [440/497], Loss: 1.3022, Accuracy: 31.25%\n",
      "Epoch [13/30], Step [450/497], Loss: 1.1750, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [460/497], Loss: 1.3706, Accuracy: 28.12%\n",
      "Epoch [13/30], Step [470/497], Loss: 1.1378, Accuracy: 43.75%\n",
      "Epoch [13/30], Step [480/497], Loss: 1.1599, Accuracy: 56.25%\n",
      "Epoch [13/30], Step [490/497], Loss: 1.3141, Accuracy: 21.88%\n",
      "Epoch [14/30], Step [10/497], Loss: 1.0595, Accuracy: 59.38%\n",
      "Epoch [14/30], Step [20/497], Loss: 1.1901, Accuracy: 37.50%\n",
      "Epoch [14/30], Step [30/497], Loss: 1.2237, Accuracy: 46.88%\n",
      "Epoch [14/30], Step [40/497], Loss: 1.0820, Accuracy: 56.25%\n",
      "Epoch [14/30], Step [50/497], Loss: 1.2303, Accuracy: 50.00%\n",
      "Epoch [14/30], Step [60/497], Loss: 1.2830, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [70/497], Loss: 1.1321, Accuracy: 53.12%\n",
      "Epoch [14/30], Step [80/497], Loss: 1.3032, Accuracy: 40.62%\n",
      "Epoch [14/30], Step [90/497], Loss: 1.0838, Accuracy: 62.50%\n",
      "Epoch [14/30], Step [100/497], Loss: 1.3768, Accuracy: 28.12%\n",
      "Epoch [14/30], Step [110/497], Loss: 1.1037, Accuracy: 50.00%\n",
      "Epoch [14/30], Step [120/497], Loss: 1.2415, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [130/497], Loss: 1.2879, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [140/497], Loss: 1.2099, Accuracy: 40.62%\n",
      "Epoch [14/30], Step [150/497], Loss: 1.2434, Accuracy: 46.88%\n",
      "Epoch [14/30], Step [160/497], Loss: 1.0412, Accuracy: 62.50%\n",
      "Epoch [14/30], Step [170/497], Loss: 1.3479, Accuracy: 34.38%\n",
      "Epoch [14/30], Step [180/497], Loss: 1.0037, Accuracy: 59.38%\n",
      "Epoch [14/30], Step [190/497], Loss: 1.3093, Accuracy: 40.62%\n",
      "Epoch [14/30], Step [200/497], Loss: 1.1499, Accuracy: 46.88%\n",
      "Epoch [14/30], Step [210/497], Loss: 1.2890, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [220/497], Loss: 1.1773, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [230/497], Loss: 1.2950, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [240/497], Loss: 1.1657, Accuracy: 53.12%\n",
      "Epoch [14/30], Step [250/497], Loss: 1.2553, Accuracy: 31.25%\n",
      "Epoch [14/30], Step [260/497], Loss: 1.1983, Accuracy: 53.12%\n",
      "Epoch [14/30], Step [270/497], Loss: 1.2661, Accuracy: 34.38%\n",
      "Epoch [14/30], Step [280/497], Loss: 1.1311, Accuracy: 53.12%\n",
      "Epoch [14/30], Step [290/497], Loss: 1.1398, Accuracy: 59.38%\n",
      "Epoch [14/30], Step [300/497], Loss: 1.1250, Accuracy: 56.25%\n",
      "Epoch [14/30], Step [310/497], Loss: 1.1088, Accuracy: 46.88%\n",
      "Epoch [14/30], Step [320/497], Loss: 1.2178, Accuracy: 50.00%\n",
      "Epoch [14/30], Step [330/497], Loss: 1.1587, Accuracy: 53.12%\n",
      "Epoch [14/30], Step [340/497], Loss: 1.1960, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [350/497], Loss: 1.0896, Accuracy: 53.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Step [360/497], Loss: 1.2971, Accuracy: 37.50%\n",
      "Epoch [14/30], Step [370/497], Loss: 1.2531, Accuracy: 46.88%\n",
      "Epoch [14/30], Step [380/497], Loss: 1.3458, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [390/497], Loss: 1.3638, Accuracy: 37.50%\n",
      "Epoch [14/30], Step [400/497], Loss: 1.2474, Accuracy: 40.62%\n",
      "Epoch [14/30], Step [410/497], Loss: 1.2464, Accuracy: 40.62%\n",
      "Epoch [14/30], Step [420/497], Loss: 1.1891, Accuracy: 46.88%\n",
      "Epoch [14/30], Step [430/497], Loss: 1.0765, Accuracy: 59.38%\n",
      "Epoch [14/30], Step [440/497], Loss: 1.1231, Accuracy: 56.25%\n",
      "Epoch [14/30], Step [450/497], Loss: 1.4296, Accuracy: 34.38%\n",
      "Epoch [14/30], Step [460/497], Loss: 1.2942, Accuracy: 43.75%\n",
      "Epoch [14/30], Step [470/497], Loss: 1.0812, Accuracy: 62.50%\n",
      "Epoch [14/30], Step [480/497], Loss: 1.1243, Accuracy: 56.25%\n",
      "Epoch [14/30], Step [490/497], Loss: 1.1925, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [10/497], Loss: 1.1342, Accuracy: 53.12%\n",
      "Epoch [15/30], Step [20/497], Loss: 1.2085, Accuracy: 43.75%\n",
      "Epoch [15/30], Step [30/497], Loss: 1.1790, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [40/497], Loss: 1.2211, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [50/497], Loss: 1.0169, Accuracy: 75.00%\n",
      "Epoch [15/30], Step [60/497], Loss: 1.1550, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [70/497], Loss: 1.1498, Accuracy: 43.75%\n",
      "Epoch [15/30], Step [80/497], Loss: 1.1823, Accuracy: 50.00%\n",
      "Epoch [15/30], Step [90/497], Loss: 1.1101, Accuracy: 50.00%\n",
      "Epoch [15/30], Step [100/497], Loss: 1.2729, Accuracy: 43.75%\n",
      "Epoch [15/30], Step [110/497], Loss: 1.1539, Accuracy: 62.50%\n",
      "Epoch [15/30], Step [120/497], Loss: 1.1981, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [130/497], Loss: 1.2940, Accuracy: 37.50%\n",
      "Epoch [15/30], Step [140/497], Loss: 1.2277, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [150/497], Loss: 1.0835, Accuracy: 53.12%\n",
      "Epoch [15/30], Step [160/497], Loss: 1.2912, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [170/497], Loss: 1.2273, Accuracy: 40.62%\n",
      "Epoch [15/30], Step [180/497], Loss: 1.1269, Accuracy: 53.12%\n",
      "Epoch [15/30], Step [190/497], Loss: 1.0736, Accuracy: 59.38%\n",
      "Epoch [15/30], Step [200/497], Loss: 1.2466, Accuracy: 37.50%\n",
      "Epoch [15/30], Step [210/497], Loss: 1.1673, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [220/497], Loss: 1.1285, Accuracy: 53.12%\n",
      "Epoch [15/30], Step [230/497], Loss: 1.2689, Accuracy: 40.62%\n",
      "Epoch [15/30], Step [240/497], Loss: 1.1457, Accuracy: 56.25%\n",
      "Epoch [15/30], Step [250/497], Loss: 1.1963, Accuracy: 37.50%\n",
      "Epoch [15/30], Step [260/497], Loss: 1.1438, Accuracy: 50.00%\n",
      "Epoch [15/30], Step [270/497], Loss: 1.2664, Accuracy: 37.50%\n",
      "Epoch [15/30], Step [280/497], Loss: 1.1978, Accuracy: 43.75%\n",
      "Epoch [15/30], Step [290/497], Loss: 1.1246, Accuracy: 53.12%\n",
      "Epoch [15/30], Step [300/497], Loss: 1.3015, Accuracy: 40.62%\n",
      "Epoch [15/30], Step [310/497], Loss: 1.3890, Accuracy: 31.25%\n",
      "Epoch [15/30], Step [320/497], Loss: 1.0536, Accuracy: 56.25%\n",
      "Epoch [15/30], Step [330/497], Loss: 1.1233, Accuracy: 53.12%\n",
      "Epoch [15/30], Step [340/497], Loss: 1.0659, Accuracy: 50.00%\n",
      "Epoch [15/30], Step [350/497], Loss: 1.1734, Accuracy: 50.00%\n",
      "Epoch [15/30], Step [360/497], Loss: 1.1448, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [370/497], Loss: 1.1700, Accuracy: 50.00%\n",
      "Epoch [15/30], Step [380/497], Loss: 1.1731, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [390/497], Loss: 1.3862, Accuracy: 40.62%\n",
      "Epoch [15/30], Step [400/497], Loss: 1.2058, Accuracy: 37.50%\n",
      "Epoch [15/30], Step [410/497], Loss: 1.1831, Accuracy: 53.12%\n",
      "Epoch [15/30], Step [420/497], Loss: 1.1782, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [430/497], Loss: 1.2258, Accuracy: 40.62%\n",
      "Epoch [15/30], Step [440/497], Loss: 1.1335, Accuracy: 46.88%\n",
      "Epoch [15/30], Step [450/497], Loss: 1.2516, Accuracy: 40.62%\n",
      "Epoch [15/30], Step [460/497], Loss: 1.0599, Accuracy: 50.00%\n",
      "Epoch [15/30], Step [470/497], Loss: 1.2569, Accuracy: 40.62%\n",
      "Epoch [15/30], Step [480/497], Loss: 1.0991, Accuracy: 56.25%\n",
      "Epoch [15/30], Step [490/497], Loss: 1.2337, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [10/497], Loss: 1.1046, Accuracy: 50.00%\n",
      "Epoch [16/30], Step [20/497], Loss: 1.3106, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [30/497], Loss: 1.2642, Accuracy: 53.12%\n",
      "Epoch [16/30], Step [40/497], Loss: 1.1994, Accuracy: 43.75%\n",
      "Epoch [16/30], Step [50/497], Loss: 1.1576, Accuracy: 56.25%\n",
      "Epoch [16/30], Step [60/497], Loss: 1.3039, Accuracy: 37.50%\n",
      "Epoch [16/30], Step [70/497], Loss: 1.2302, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [80/497], Loss: 1.2022, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [90/497], Loss: 1.0863, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [100/497], Loss: 1.3658, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [110/497], Loss: 1.2148, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [120/497], Loss: 1.2078, Accuracy: 53.12%\n",
      "Epoch [16/30], Step [130/497], Loss: 1.1668, Accuracy: 43.75%\n",
      "Epoch [16/30], Step [140/497], Loss: 1.0593, Accuracy: 50.00%\n",
      "Epoch [16/30], Step [150/497], Loss: 1.1517, Accuracy: 53.12%\n",
      "Epoch [16/30], Step [160/497], Loss: 1.1525, Accuracy: 43.75%\n",
      "Epoch [16/30], Step [170/497], Loss: 1.3399, Accuracy: 37.50%\n",
      "Epoch [16/30], Step [180/497], Loss: 1.2386, Accuracy: 59.38%\n",
      "Epoch [16/30], Step [190/497], Loss: 1.2052, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [200/497], Loss: 1.3804, Accuracy: 37.50%\n",
      "Epoch [16/30], Step [210/497], Loss: 1.2982, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [220/497], Loss: 1.3731, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [230/497], Loss: 1.1476, Accuracy: 62.50%\n",
      "Epoch [16/30], Step [240/497], Loss: 1.3608, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [250/497], Loss: 1.0707, Accuracy: 62.50%\n",
      "Epoch [16/30], Step [260/497], Loss: 1.3211, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [270/497], Loss: 1.1607, Accuracy: 56.25%\n",
      "Epoch [16/30], Step [280/497], Loss: 1.2479, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [290/497], Loss: 1.1824, Accuracy: 53.12%\n",
      "Epoch [16/30], Step [300/497], Loss: 1.2438, Accuracy: 53.12%\n",
      "Epoch [16/30], Step [310/497], Loss: 1.1336, Accuracy: 56.25%\n",
      "Epoch [16/30], Step [320/497], Loss: 1.1030, Accuracy: 75.00%\n",
      "Epoch [16/30], Step [330/497], Loss: 1.1488, Accuracy: 53.12%\n",
      "Epoch [16/30], Step [340/497], Loss: 0.9894, Accuracy: 65.62%\n",
      "Epoch [16/30], Step [350/497], Loss: 1.3548, Accuracy: 37.50%\n",
      "Epoch [16/30], Step [360/497], Loss: 1.1770, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [370/497], Loss: 1.1872, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [380/497], Loss: 1.2381, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [390/497], Loss: 1.1355, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [400/497], Loss: 1.3269, Accuracy: 37.50%\n",
      "Epoch [16/30], Step [410/497], Loss: 1.0945, Accuracy: 59.38%\n",
      "Epoch [16/30], Step [420/497], Loss: 1.3179, Accuracy: 40.62%\n",
      "Epoch [16/30], Step [430/497], Loss: 1.2069, Accuracy: 43.75%\n",
      "Epoch [16/30], Step [440/497], Loss: 1.0275, Accuracy: 59.38%\n",
      "Epoch [16/30], Step [450/497], Loss: 1.0476, Accuracy: 56.25%\n",
      "Epoch [16/30], Step [460/497], Loss: 1.2662, Accuracy: 46.88%\n",
      "Epoch [16/30], Step [470/497], Loss: 1.0822, Accuracy: 56.25%\n",
      "Epoch [16/30], Step [480/497], Loss: 1.2822, Accuracy: 43.75%\n",
      "Epoch [16/30], Step [490/497], Loss: 1.1500, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [10/497], Loss: 1.1738, Accuracy: 56.25%\n",
      "Epoch [17/30], Step [20/497], Loss: 1.1525, Accuracy: 56.25%\n",
      "Epoch [17/30], Step [30/497], Loss: 1.2488, Accuracy: 37.50%\n",
      "Epoch [17/30], Step [40/497], Loss: 1.3457, Accuracy: 43.75%\n",
      "Epoch [17/30], Step [50/497], Loss: 1.2483, Accuracy: 43.75%\n",
      "Epoch [17/30], Step [60/497], Loss: 1.1964, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [70/497], Loss: 1.0735, Accuracy: 59.38%\n",
      "Epoch [17/30], Step [80/497], Loss: 1.4027, Accuracy: 34.38%\n",
      "Epoch [17/30], Step [90/497], Loss: 1.1608, Accuracy: 43.75%\n",
      "Epoch [17/30], Step [100/497], Loss: 1.1994, Accuracy: 53.12%\n",
      "Epoch [17/30], Step [110/497], Loss: 1.1038, Accuracy: 53.12%\n",
      "Epoch [17/30], Step [120/497], Loss: 1.2636, Accuracy: 40.62%\n",
      "Epoch [17/30], Step [130/497], Loss: 1.2422, Accuracy: 40.62%\n",
      "Epoch [17/30], Step [140/497], Loss: 1.1891, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [150/497], Loss: 1.1592, Accuracy: 56.25%\n",
      "Epoch [17/30], Step [160/497], Loss: 1.3635, Accuracy: 34.38%\n",
      "Epoch [17/30], Step [170/497], Loss: 1.2228, Accuracy: 46.88%\n",
      "Epoch [17/30], Step [180/497], Loss: 1.1433, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [190/497], Loss: 1.3141, Accuracy: 43.75%\n",
      "Epoch [17/30], Step [200/497], Loss: 1.2119, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [210/497], Loss: 1.1835, Accuracy: 46.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Step [220/497], Loss: 1.3412, Accuracy: 34.38%\n",
      "Epoch [17/30], Step [230/497], Loss: 1.1591, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [240/497], Loss: 1.3578, Accuracy: 37.50%\n",
      "Epoch [17/30], Step [250/497], Loss: 1.2678, Accuracy: 46.88%\n",
      "Epoch [17/30], Step [260/497], Loss: 1.0576, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [270/497], Loss: 1.2002, Accuracy: 40.62%\n",
      "Epoch [17/30], Step [280/497], Loss: 1.1705, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [290/497], Loss: 1.2740, Accuracy: 31.25%\n",
      "Epoch [17/30], Step [300/497], Loss: 1.3457, Accuracy: 43.75%\n",
      "Epoch [17/30], Step [310/497], Loss: 1.0405, Accuracy: 59.38%\n",
      "Epoch [17/30], Step [320/497], Loss: 1.1591, Accuracy: 56.25%\n",
      "Epoch [17/30], Step [330/497], Loss: 1.3403, Accuracy: 37.50%\n",
      "Epoch [17/30], Step [340/497], Loss: 1.2404, Accuracy: 43.75%\n",
      "Epoch [17/30], Step [350/497], Loss: 1.1235, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [360/497], Loss: 1.1927, Accuracy: 53.12%\n",
      "Epoch [17/30], Step [370/497], Loss: 0.9855, Accuracy: 65.62%\n",
      "Epoch [17/30], Step [380/497], Loss: 1.1507, Accuracy: 43.75%\n",
      "Epoch [17/30], Step [390/497], Loss: 1.2254, Accuracy: 46.88%\n",
      "Epoch [17/30], Step [400/497], Loss: 1.2353, Accuracy: 56.25%\n",
      "Epoch [17/30], Step [410/497], Loss: 0.9997, Accuracy: 53.12%\n",
      "Epoch [17/30], Step [420/497], Loss: 1.2846, Accuracy: 37.50%\n",
      "Epoch [17/30], Step [430/497], Loss: 1.2605, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [440/497], Loss: 1.1698, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [450/497], Loss: 1.2925, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [460/497], Loss: 1.2251, Accuracy: 46.88%\n",
      "Epoch [17/30], Step [470/497], Loss: 1.4707, Accuracy: 25.00%\n",
      "Epoch [17/30], Step [480/497], Loss: 1.2445, Accuracy: 50.00%\n",
      "Epoch [17/30], Step [490/497], Loss: 1.2109, Accuracy: 40.62%\n",
      "Epoch [18/30], Step [10/497], Loss: 1.3219, Accuracy: 43.75%\n",
      "Epoch [18/30], Step [20/497], Loss: 1.2266, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [30/497], Loss: 1.1310, Accuracy: 50.00%\n",
      "Epoch [18/30], Step [40/497], Loss: 1.2787, Accuracy: 53.12%\n",
      "Epoch [18/30], Step [50/497], Loss: 1.1844, Accuracy: 43.75%\n",
      "Epoch [18/30], Step [60/497], Loss: 1.0887, Accuracy: 62.50%\n",
      "Epoch [18/30], Step [70/497], Loss: 1.3081, Accuracy: 43.75%\n",
      "Epoch [18/30], Step [80/497], Loss: 1.3127, Accuracy: 50.00%\n",
      "Epoch [18/30], Step [90/497], Loss: 1.3532, Accuracy: 31.25%\n",
      "Epoch [18/30], Step [100/497], Loss: 1.2424, Accuracy: 40.62%\n",
      "Epoch [18/30], Step [110/497], Loss: 1.1382, Accuracy: 50.00%\n",
      "Epoch [18/30], Step [120/497], Loss: 1.2011, Accuracy: 46.88%\n",
      "Epoch [18/30], Step [130/497], Loss: 1.1195, Accuracy: 56.25%\n",
      "Epoch [18/30], Step [140/497], Loss: 1.2915, Accuracy: 31.25%\n",
      "Epoch [18/30], Step [150/497], Loss: 1.1069, Accuracy: 59.38%\n",
      "Epoch [18/30], Step [160/497], Loss: 1.3275, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [170/497], Loss: 1.0955, Accuracy: 56.25%\n",
      "Epoch [18/30], Step [180/497], Loss: 1.3060, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [190/497], Loss: 1.2163, Accuracy: 53.12%\n",
      "Epoch [18/30], Step [200/497], Loss: 1.0735, Accuracy: 56.25%\n",
      "Epoch [18/30], Step [210/497], Loss: 1.2827, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [220/497], Loss: 1.1554, Accuracy: 46.88%\n",
      "Epoch [18/30], Step [230/497], Loss: 1.1034, Accuracy: 59.38%\n",
      "Epoch [18/30], Step [240/497], Loss: 1.2517, Accuracy: 46.88%\n",
      "Epoch [18/30], Step [250/497], Loss: 1.3219, Accuracy: 43.75%\n",
      "Epoch [18/30], Step [260/497], Loss: 1.2805, Accuracy: 34.38%\n",
      "Epoch [18/30], Step [270/497], Loss: 1.1856, Accuracy: 40.62%\n",
      "Epoch [18/30], Step [280/497], Loss: 1.1425, Accuracy: 43.75%\n",
      "Epoch [18/30], Step [290/497], Loss: 1.1815, Accuracy: 62.50%\n",
      "Epoch [18/30], Step [300/497], Loss: 1.3667, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [310/497], Loss: 1.2430, Accuracy: 34.38%\n",
      "Epoch [18/30], Step [320/497], Loss: 1.0124, Accuracy: 53.12%\n",
      "Epoch [18/30], Step [330/497], Loss: 1.2239, Accuracy: 43.75%\n",
      "Epoch [18/30], Step [340/497], Loss: 1.2638, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [350/497], Loss: 1.1329, Accuracy: 53.12%\n",
      "Epoch [18/30], Step [360/497], Loss: 1.3672, Accuracy: 43.75%\n",
      "Epoch [18/30], Step [370/497], Loss: 1.1499, Accuracy: 53.12%\n",
      "Epoch [18/30], Step [380/497], Loss: 0.9943, Accuracy: 50.00%\n",
      "Epoch [18/30], Step [390/497], Loss: 1.2846, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [400/497], Loss: 0.9845, Accuracy: 59.38%\n",
      "Epoch [18/30], Step [410/497], Loss: 1.2274, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [420/497], Loss: 1.2604, Accuracy: 50.00%\n",
      "Epoch [18/30], Step [430/497], Loss: 1.2279, Accuracy: 50.00%\n",
      "Epoch [18/30], Step [440/497], Loss: 1.1100, Accuracy: 53.12%\n",
      "Epoch [18/30], Step [450/497], Loss: 1.2807, Accuracy: 34.38%\n",
      "Epoch [18/30], Step [460/497], Loss: 1.3021, Accuracy: 46.88%\n",
      "Epoch [18/30], Step [470/497], Loss: 1.4281, Accuracy: 37.50%\n",
      "Epoch [18/30], Step [480/497], Loss: 1.1856, Accuracy: 34.38%\n",
      "Epoch [18/30], Step [490/497], Loss: 1.2641, Accuracy: 43.75%\n",
      "Epoch [19/30], Step [10/497], Loss: 1.2951, Accuracy: 43.75%\n",
      "Epoch [19/30], Step [20/497], Loss: 1.5115, Accuracy: 40.62%\n",
      "Epoch [19/30], Step [30/497], Loss: 1.1499, Accuracy: 53.12%\n",
      "Epoch [19/30], Step [40/497], Loss: 1.1366, Accuracy: 50.00%\n",
      "Epoch [19/30], Step [50/497], Loss: 1.0125, Accuracy: 59.38%\n",
      "Epoch [19/30], Step [60/497], Loss: 1.2471, Accuracy: 37.50%\n",
      "Epoch [19/30], Step [70/497], Loss: 1.2038, Accuracy: 50.00%\n",
      "Epoch [19/30], Step [80/497], Loss: 1.2301, Accuracy: 40.62%\n",
      "Epoch [19/30], Step [90/497], Loss: 1.3800, Accuracy: 46.88%\n",
      "Epoch [19/30], Step [100/497], Loss: 1.0968, Accuracy: 59.38%\n",
      "Epoch [19/30], Step [110/497], Loss: 1.1141, Accuracy: 53.12%\n",
      "Epoch [19/30], Step [120/497], Loss: 1.3253, Accuracy: 37.50%\n",
      "Epoch [19/30], Step [130/497], Loss: 1.1922, Accuracy: 46.88%\n",
      "Epoch [19/30], Step [140/497], Loss: 1.1742, Accuracy: 56.25%\n",
      "Epoch [19/30], Step [150/497], Loss: 1.2557, Accuracy: 50.00%\n",
      "Epoch [19/30], Step [160/497], Loss: 1.2168, Accuracy: 43.75%\n",
      "Epoch [19/30], Step [170/497], Loss: 1.1235, Accuracy: 53.12%\n",
      "Epoch [19/30], Step [180/497], Loss: 1.2101, Accuracy: 53.12%\n",
      "Epoch [19/30], Step [190/497], Loss: 1.2515, Accuracy: 43.75%\n",
      "Epoch [19/30], Step [200/497], Loss: 1.0841, Accuracy: 56.25%\n",
      "Epoch [19/30], Step [210/497], Loss: 0.9760, Accuracy: 59.38%\n",
      "Epoch [19/30], Step [220/497], Loss: 1.0112, Accuracy: 62.50%\n",
      "Epoch [19/30], Step [230/497], Loss: 1.0800, Accuracy: 56.25%\n",
      "Epoch [19/30], Step [240/497], Loss: 1.0237, Accuracy: 56.25%\n",
      "Epoch [19/30], Step [250/497], Loss: 1.1430, Accuracy: 43.75%\n",
      "Epoch [19/30], Step [260/497], Loss: 1.2319, Accuracy: 59.38%\n",
      "Epoch [19/30], Step [270/497], Loss: 1.3557, Accuracy: 40.62%\n",
      "Epoch [19/30], Step [280/497], Loss: 1.1302, Accuracy: 40.62%\n",
      "Epoch [19/30], Step [290/497], Loss: 1.2251, Accuracy: 40.62%\n",
      "Epoch [19/30], Step [300/497], Loss: 1.0299, Accuracy: 56.25%\n",
      "Epoch [19/30], Step [310/497], Loss: 1.2713, Accuracy: 50.00%\n",
      "Epoch [19/30], Step [320/497], Loss: 1.0961, Accuracy: 71.88%\n",
      "Epoch [19/30], Step [330/497], Loss: 1.2443, Accuracy: 43.75%\n",
      "Epoch [19/30], Step [340/497], Loss: 1.1049, Accuracy: 53.12%\n",
      "Epoch [19/30], Step [350/497], Loss: 1.0389, Accuracy: 71.88%\n",
      "Epoch [19/30], Step [360/497], Loss: 1.3862, Accuracy: 37.50%\n",
      "Epoch [19/30], Step [370/497], Loss: 1.2263, Accuracy: 40.62%\n",
      "Epoch [19/30], Step [380/497], Loss: 1.0422, Accuracy: 59.38%\n",
      "Epoch [19/30], Step [390/497], Loss: 1.0504, Accuracy: 56.25%\n",
      "Epoch [19/30], Step [400/497], Loss: 1.3524, Accuracy: 50.00%\n",
      "Epoch [19/30], Step [410/497], Loss: 1.2581, Accuracy: 40.62%\n",
      "Epoch [19/30], Step [420/497], Loss: 1.2670, Accuracy: 43.75%\n",
      "Epoch [19/30], Step [430/497], Loss: 1.1309, Accuracy: 53.12%\n",
      "Epoch [19/30], Step [440/497], Loss: 1.2123, Accuracy: 62.50%\n",
      "Epoch [19/30], Step [450/497], Loss: 1.3571, Accuracy: 34.38%\n",
      "Epoch [19/30], Step [460/497], Loss: 1.2013, Accuracy: 59.38%\n",
      "Epoch [19/30], Step [470/497], Loss: 1.2390, Accuracy: 50.00%\n",
      "Epoch [19/30], Step [480/497], Loss: 1.3467, Accuracy: 25.00%\n",
      "Epoch [19/30], Step [490/497], Loss: 1.1399, Accuracy: 50.00%\n",
      "Epoch [20/30], Step [10/497], Loss: 1.1629, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [20/497], Loss: 1.4749, Accuracy: 34.38%\n",
      "Epoch [20/30], Step [30/497], Loss: 1.2293, Accuracy: 43.75%\n",
      "Epoch [20/30], Step [40/497], Loss: 1.3476, Accuracy: 37.50%\n",
      "Epoch [20/30], Step [50/497], Loss: 0.9511, Accuracy: 59.38%\n",
      "Epoch [20/30], Step [60/497], Loss: 1.2797, Accuracy: 28.12%\n",
      "Epoch [20/30], Step [70/497], Loss: 1.1731, Accuracy: 43.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Step [80/497], Loss: 1.2020, Accuracy: 50.00%\n",
      "Epoch [20/30], Step [90/497], Loss: 1.1900, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [100/497], Loss: 1.0262, Accuracy: 53.12%\n",
      "Epoch [20/30], Step [110/497], Loss: 1.2393, Accuracy: 56.25%\n",
      "Epoch [20/30], Step [120/497], Loss: 1.2184, Accuracy: 53.12%\n",
      "Epoch [20/30], Step [130/497], Loss: 1.3101, Accuracy: 40.62%\n",
      "Epoch [20/30], Step [140/497], Loss: 1.3433, Accuracy: 37.50%\n",
      "Epoch [20/30], Step [150/497], Loss: 1.2101, Accuracy: 40.62%\n",
      "Epoch [20/30], Step [160/497], Loss: 1.3293, Accuracy: 31.25%\n",
      "Epoch [20/30], Step [170/497], Loss: 1.0855, Accuracy: 43.75%\n",
      "Epoch [20/30], Step [180/497], Loss: 1.3561, Accuracy: 40.62%\n",
      "Epoch [20/30], Step [190/497], Loss: 1.0873, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [200/497], Loss: 1.2269, Accuracy: 43.75%\n",
      "Epoch [20/30], Step [210/497], Loss: 1.0887, Accuracy: 50.00%\n",
      "Epoch [20/30], Step [220/497], Loss: 1.2534, Accuracy: 43.75%\n",
      "Epoch [20/30], Step [230/497], Loss: 1.0451, Accuracy: 59.38%\n",
      "Epoch [20/30], Step [240/497], Loss: 1.2895, Accuracy: 50.00%\n",
      "Epoch [20/30], Step [250/497], Loss: 1.2149, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [260/497], Loss: 1.1476, Accuracy: 53.12%\n",
      "Epoch [20/30], Step [270/497], Loss: 1.1563, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [280/497], Loss: 1.0782, Accuracy: 40.62%\n",
      "Epoch [20/30], Step [290/497], Loss: 1.1029, Accuracy: 53.12%\n",
      "Epoch [20/30], Step [300/497], Loss: 1.1614, Accuracy: 40.62%\n",
      "Epoch [20/30], Step [310/497], Loss: 1.2646, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [320/497], Loss: 1.3017, Accuracy: 43.75%\n",
      "Epoch [20/30], Step [330/497], Loss: 1.2756, Accuracy: 37.50%\n",
      "Epoch [20/30], Step [340/497], Loss: 1.2763, Accuracy: 56.25%\n",
      "Epoch [20/30], Step [350/497], Loss: 1.1254, Accuracy: 53.12%\n",
      "Epoch [20/30], Step [360/497], Loss: 1.2645, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [370/497], Loss: 1.0360, Accuracy: 62.50%\n",
      "Epoch [20/30], Step [380/497], Loss: 1.2259, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [390/497], Loss: 1.2049, Accuracy: 53.12%\n",
      "Epoch [20/30], Step [400/497], Loss: 1.4282, Accuracy: 40.62%\n",
      "Epoch [20/30], Step [410/497], Loss: 1.2982, Accuracy: 50.00%\n",
      "Epoch [20/30], Step [420/497], Loss: 1.1920, Accuracy: 50.00%\n",
      "Epoch [20/30], Step [430/497], Loss: 1.1880, Accuracy: 50.00%\n",
      "Epoch [20/30], Step [440/497], Loss: 1.3556, Accuracy: 31.25%\n",
      "Epoch [20/30], Step [450/497], Loss: 1.1104, Accuracy: 53.12%\n",
      "Epoch [20/30], Step [460/497], Loss: 1.1952, Accuracy: 50.00%\n",
      "Epoch [20/30], Step [470/497], Loss: 1.1951, Accuracy: 46.88%\n",
      "Epoch [20/30], Step [480/497], Loss: 0.9835, Accuracy: 71.88%\n",
      "Epoch [20/30], Step [490/497], Loss: 1.2731, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [10/497], Loss: 1.2723, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [20/497], Loss: 1.2700, Accuracy: 50.00%\n",
      "Epoch [21/30], Step [30/497], Loss: 1.1684, Accuracy: 50.00%\n",
      "Epoch [21/30], Step [40/497], Loss: 1.1989, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [50/497], Loss: 1.1699, Accuracy: 50.00%\n",
      "Epoch [21/30], Step [60/497], Loss: 1.1597, Accuracy: 56.25%\n",
      "Epoch [21/30], Step [70/497], Loss: 1.0642, Accuracy: 50.00%\n",
      "Epoch [21/30], Step [80/497], Loss: 1.1510, Accuracy: 56.25%\n",
      "Epoch [21/30], Step [90/497], Loss: 1.2817, Accuracy: 37.50%\n",
      "Epoch [21/30], Step [100/497], Loss: 1.1254, Accuracy: 56.25%\n",
      "Epoch [21/30], Step [110/497], Loss: 1.0239, Accuracy: 59.38%\n",
      "Epoch [21/30], Step [120/497], Loss: 1.1416, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [130/497], Loss: 1.3139, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [140/497], Loss: 1.1630, Accuracy: 50.00%\n",
      "Epoch [21/30], Step [150/497], Loss: 1.0966, Accuracy: 62.50%\n",
      "Epoch [21/30], Step [160/497], Loss: 1.0436, Accuracy: 59.38%\n",
      "Epoch [21/30], Step [170/497], Loss: 1.2108, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [180/497], Loss: 1.1833, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [190/497], Loss: 1.1768, Accuracy: 50.00%\n",
      "Epoch [21/30], Step [200/497], Loss: 1.2278, Accuracy: 43.75%\n",
      "Epoch [21/30], Step [210/497], Loss: 1.0974, Accuracy: 56.25%\n",
      "Epoch [21/30], Step [220/497], Loss: 1.2469, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [230/497], Loss: 1.3220, Accuracy: 34.38%\n",
      "Epoch [21/30], Step [240/497], Loss: 1.2086, Accuracy: 43.75%\n",
      "Epoch [21/30], Step [250/497], Loss: 1.2308, Accuracy: 37.50%\n",
      "Epoch [21/30], Step [260/497], Loss: 1.0623, Accuracy: 59.38%\n",
      "Epoch [21/30], Step [270/497], Loss: 1.0829, Accuracy: 53.12%\n",
      "Epoch [21/30], Step [280/497], Loss: 1.1182, Accuracy: 56.25%\n",
      "Epoch [21/30], Step [290/497], Loss: 1.2619, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [300/497], Loss: 1.2296, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [310/497], Loss: 1.2478, Accuracy: 37.50%\n",
      "Epoch [21/30], Step [320/497], Loss: 1.2990, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [330/497], Loss: 1.1676, Accuracy: 50.00%\n",
      "Epoch [21/30], Step [340/497], Loss: 1.2005, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [350/497], Loss: 1.2621, Accuracy: 53.12%\n",
      "Epoch [21/30], Step [360/497], Loss: 1.2333, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [370/497], Loss: 1.1533, Accuracy: 53.12%\n",
      "Epoch [21/30], Step [380/497], Loss: 1.0488, Accuracy: 53.12%\n",
      "Epoch [21/30], Step [390/497], Loss: 1.1213, Accuracy: 50.00%\n",
      "Epoch [21/30], Step [400/497], Loss: 1.4124, Accuracy: 37.50%\n",
      "Epoch [21/30], Step [410/497], Loss: 1.3570, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [420/497], Loss: 1.2490, Accuracy: 43.75%\n",
      "Epoch [21/30], Step [430/497], Loss: 1.4770, Accuracy: 34.38%\n",
      "Epoch [21/30], Step [440/497], Loss: 1.1404, Accuracy: 46.88%\n",
      "Epoch [21/30], Step [450/497], Loss: 1.2401, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [460/497], Loss: 1.2042, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [470/497], Loss: 1.3580, Accuracy: 37.50%\n",
      "Epoch [21/30], Step [480/497], Loss: 1.2059, Accuracy: 40.62%\n",
      "Epoch [21/30], Step [490/497], Loss: 1.0699, Accuracy: 62.50%\n",
      "Epoch [22/30], Step [10/497], Loss: 1.2261, Accuracy: 46.88%\n",
      "Epoch [22/30], Step [20/497], Loss: 1.3582, Accuracy: 43.75%\n",
      "Epoch [22/30], Step [30/497], Loss: 1.1752, Accuracy: 59.38%\n",
      "Epoch [22/30], Step [40/497], Loss: 1.2608, Accuracy: 37.50%\n",
      "Epoch [22/30], Step [50/497], Loss: 1.2280, Accuracy: 46.88%\n",
      "Epoch [22/30], Step [60/497], Loss: 1.1414, Accuracy: 62.50%\n",
      "Epoch [22/30], Step [70/497], Loss: 1.3814, Accuracy: 40.62%\n",
      "Epoch [22/30], Step [80/497], Loss: 1.1482, Accuracy: 46.88%\n",
      "Epoch [22/30], Step [90/497], Loss: 1.2299, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [100/497], Loss: 1.0649, Accuracy: 56.25%\n",
      "Epoch [22/30], Step [110/497], Loss: 1.2049, Accuracy: 56.25%\n",
      "Epoch [22/30], Step [120/497], Loss: 1.1498, Accuracy: 50.00%\n",
      "Epoch [22/30], Step [130/497], Loss: 1.2278, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [140/497], Loss: 1.1527, Accuracy: 50.00%\n",
      "Epoch [22/30], Step [150/497], Loss: 1.1912, Accuracy: 43.75%\n",
      "Epoch [22/30], Step [160/497], Loss: 1.2563, Accuracy: 37.50%\n",
      "Epoch [22/30], Step [170/497], Loss: 1.0118, Accuracy: 65.62%\n",
      "Epoch [22/30], Step [180/497], Loss: 1.0822, Accuracy: 56.25%\n",
      "Epoch [22/30], Step [190/497], Loss: 1.1960, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [200/497], Loss: 1.2326, Accuracy: 43.75%\n",
      "Epoch [22/30], Step [210/497], Loss: 1.3534, Accuracy: 34.38%\n",
      "Epoch [22/30], Step [220/497], Loss: 1.1107, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [230/497], Loss: 1.1130, Accuracy: 50.00%\n",
      "Epoch [22/30], Step [240/497], Loss: 1.0474, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [250/497], Loss: 1.1099, Accuracy: 56.25%\n",
      "Epoch [22/30], Step [260/497], Loss: 1.2907, Accuracy: 43.75%\n",
      "Epoch [22/30], Step [270/497], Loss: 1.3525, Accuracy: 28.12%\n",
      "Epoch [22/30], Step [280/497], Loss: 1.1005, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [290/497], Loss: 1.2439, Accuracy: 56.25%\n",
      "Epoch [22/30], Step [300/497], Loss: 1.0449, Accuracy: 46.88%\n",
      "Epoch [22/30], Step [310/497], Loss: 1.2551, Accuracy: 46.88%\n",
      "Epoch [22/30], Step [320/497], Loss: 1.1697, Accuracy: 37.50%\n",
      "Epoch [22/30], Step [330/497], Loss: 1.1861, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [340/497], Loss: 1.0160, Accuracy: 59.38%\n",
      "Epoch [22/30], Step [350/497], Loss: 1.1818, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [360/497], Loss: 1.3995, Accuracy: 50.00%\n",
      "Epoch [22/30], Step [370/497], Loss: 1.1594, Accuracy: 50.00%\n",
      "Epoch [22/30], Step [380/497], Loss: 1.1809, Accuracy: 56.25%\n",
      "Epoch [22/30], Step [390/497], Loss: 1.1560, Accuracy: 50.00%\n",
      "Epoch [22/30], Step [400/497], Loss: 1.1400, Accuracy: 56.25%\n",
      "Epoch [22/30], Step [410/497], Loss: 1.1513, Accuracy: 50.00%\n",
      "Epoch [22/30], Step [420/497], Loss: 1.1027, Accuracy: 65.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Step [430/497], Loss: 1.3535, Accuracy: 37.50%\n",
      "Epoch [22/30], Step [440/497], Loss: 1.2711, Accuracy: 31.25%\n",
      "Epoch [22/30], Step [450/497], Loss: 1.0490, Accuracy: 46.88%\n",
      "Epoch [22/30], Step [460/497], Loss: 1.1241, Accuracy: 53.12%\n",
      "Epoch [22/30], Step [470/497], Loss: 1.0585, Accuracy: 46.88%\n",
      "Epoch [22/30], Step [480/497], Loss: 1.1754, Accuracy: 56.25%\n",
      "Epoch [22/30], Step [490/497], Loss: 1.1674, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [10/497], Loss: 1.1878, Accuracy: 43.75%\n",
      "Epoch [23/30], Step [20/497], Loss: 1.2782, Accuracy: 37.50%\n",
      "Epoch [23/30], Step [30/497], Loss: 1.2288, Accuracy: 50.00%\n",
      "Epoch [23/30], Step [40/497], Loss: 1.1072, Accuracy: 50.00%\n",
      "Epoch [23/30], Step [50/497], Loss: 1.1483, Accuracy: 50.00%\n",
      "Epoch [23/30], Step [60/497], Loss: 1.1193, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [70/497], Loss: 1.0423, Accuracy: 59.38%\n",
      "Epoch [23/30], Step [80/497], Loss: 1.3847, Accuracy: 31.25%\n",
      "Epoch [23/30], Step [90/497], Loss: 1.1301, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [100/497], Loss: 1.1427, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [110/497], Loss: 1.2356, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [120/497], Loss: 1.1310, Accuracy: 40.62%\n",
      "Epoch [23/30], Step [130/497], Loss: 1.1966, Accuracy: 40.62%\n",
      "Epoch [23/30], Step [140/497], Loss: 1.1640, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [150/497], Loss: 1.1857, Accuracy: 46.88%\n",
      "Epoch [23/30], Step [160/497], Loss: 1.2361, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [170/497], Loss: 1.1536, Accuracy: 40.62%\n",
      "Epoch [23/30], Step [180/497], Loss: 1.1740, Accuracy: 56.25%\n",
      "Epoch [23/30], Step [190/497], Loss: 1.1296, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [200/497], Loss: 1.1562, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [210/497], Loss: 1.1053, Accuracy: 43.75%\n",
      "Epoch [23/30], Step [220/497], Loss: 1.1386, Accuracy: 46.88%\n",
      "Epoch [23/30], Step [230/497], Loss: 1.2093, Accuracy: 50.00%\n",
      "Epoch [23/30], Step [240/497], Loss: 1.2840, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [250/497], Loss: 1.1952, Accuracy: 46.88%\n",
      "Epoch [23/30], Step [260/497], Loss: 1.0687, Accuracy: 59.38%\n",
      "Epoch [23/30], Step [270/497], Loss: 0.9628, Accuracy: 68.75%\n",
      "Epoch [23/30], Step [280/497], Loss: 1.0692, Accuracy: 62.50%\n",
      "Epoch [23/30], Step [290/497], Loss: 1.2869, Accuracy: 37.50%\n",
      "Epoch [23/30], Step [300/497], Loss: 1.2955, Accuracy: 43.75%\n",
      "Epoch [23/30], Step [310/497], Loss: 1.2030, Accuracy: 50.00%\n",
      "Epoch [23/30], Step [320/497], Loss: 1.3204, Accuracy: 34.38%\n",
      "Epoch [23/30], Step [330/497], Loss: 1.2433, Accuracy: 50.00%\n",
      "Epoch [23/30], Step [340/497], Loss: 1.1053, Accuracy: 56.25%\n",
      "Epoch [23/30], Step [350/497], Loss: 1.1050, Accuracy: 56.25%\n",
      "Epoch [23/30], Step [360/497], Loss: 1.1555, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [370/497], Loss: 1.1402, Accuracy: 53.12%\n",
      "Epoch [23/30], Step [380/497], Loss: 1.1542, Accuracy: 37.50%\n",
      "Epoch [23/30], Step [390/497], Loss: 1.1879, Accuracy: 46.88%\n",
      "Epoch [23/30], Step [400/497], Loss: 1.0766, Accuracy: 59.38%\n",
      "Epoch [23/30], Step [410/497], Loss: 1.2510, Accuracy: 37.50%\n",
      "Epoch [23/30], Step [420/497], Loss: 1.2132, Accuracy: 50.00%\n",
      "Epoch [23/30], Step [430/497], Loss: 1.1129, Accuracy: 40.62%\n",
      "Epoch [23/30], Step [440/497], Loss: 1.1911, Accuracy: 43.75%\n",
      "Epoch [23/30], Step [450/497], Loss: 1.0235, Accuracy: 62.50%\n",
      "Epoch [23/30], Step [460/497], Loss: 1.4122, Accuracy: 37.50%\n",
      "Epoch [23/30], Step [470/497], Loss: 1.3241, Accuracy: 40.62%\n",
      "Epoch [23/30], Step [480/497], Loss: 1.1400, Accuracy: 50.00%\n",
      "Epoch [23/30], Step [490/497], Loss: 1.0513, Accuracy: 56.25%\n",
      "Epoch [24/30], Step [10/497], Loss: 1.1174, Accuracy: 53.12%\n",
      "Epoch [24/30], Step [20/497], Loss: 1.2212, Accuracy: 46.88%\n",
      "Epoch [24/30], Step [30/497], Loss: 1.0888, Accuracy: 62.50%\n",
      "Epoch [24/30], Step [40/497], Loss: 1.2226, Accuracy: 40.62%\n",
      "Epoch [24/30], Step [50/497], Loss: 1.1822, Accuracy: 50.00%\n",
      "Epoch [24/30], Step [60/497], Loss: 1.2107, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [70/497], Loss: 1.2677, Accuracy: 46.88%\n",
      "Epoch [24/30], Step [80/497], Loss: 1.2292, Accuracy: 37.50%\n",
      "Epoch [24/30], Step [90/497], Loss: 1.0044, Accuracy: 62.50%\n",
      "Epoch [24/30], Step [100/497], Loss: 1.1970, Accuracy: 56.25%\n",
      "Epoch [24/30], Step [110/497], Loss: 1.2027, Accuracy: 50.00%\n",
      "Epoch [24/30], Step [120/497], Loss: 1.2838, Accuracy: 50.00%\n",
      "Epoch [24/30], Step [130/497], Loss: 1.1993, Accuracy: 46.88%\n",
      "Epoch [24/30], Step [140/497], Loss: 1.3068, Accuracy: 37.50%\n",
      "Epoch [24/30], Step [150/497], Loss: 1.1117, Accuracy: 53.12%\n",
      "Epoch [24/30], Step [160/497], Loss: 1.2936, Accuracy: 28.12%\n",
      "Epoch [24/30], Step [170/497], Loss: 1.0771, Accuracy: 59.38%\n",
      "Epoch [24/30], Step [180/497], Loss: 1.2309, Accuracy: 40.62%\n",
      "Epoch [24/30], Step [190/497], Loss: 1.2500, Accuracy: 46.88%\n",
      "Epoch [24/30], Step [200/497], Loss: 1.2683, Accuracy: 37.50%\n",
      "Epoch [24/30], Step [210/497], Loss: 1.2535, Accuracy: 46.88%\n",
      "Epoch [24/30], Step [220/497], Loss: 1.1465, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [230/497], Loss: 1.0896, Accuracy: 65.62%\n",
      "Epoch [24/30], Step [240/497], Loss: 1.1599, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [250/497], Loss: 1.2735, Accuracy: 34.38%\n",
      "Epoch [24/30], Step [260/497], Loss: 1.2896, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [270/497], Loss: 1.1049, Accuracy: 56.25%\n",
      "Epoch [24/30], Step [280/497], Loss: 1.2326, Accuracy: 40.62%\n",
      "Epoch [24/30], Step [290/497], Loss: 1.3400, Accuracy: 40.62%\n",
      "Epoch [24/30], Step [300/497], Loss: 1.1736, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [310/497], Loss: 1.1698, Accuracy: 62.50%\n",
      "Epoch [24/30], Step [320/497], Loss: 1.3132, Accuracy: 40.62%\n",
      "Epoch [24/30], Step [330/497], Loss: 1.2117, Accuracy: 50.00%\n",
      "Epoch [24/30], Step [340/497], Loss: 1.1408, Accuracy: 56.25%\n",
      "Epoch [24/30], Step [350/497], Loss: 1.0828, Accuracy: 56.25%\n",
      "Epoch [24/30], Step [360/497], Loss: 1.2551, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [370/497], Loss: 1.1676, Accuracy: 56.25%\n",
      "Epoch [24/30], Step [380/497], Loss: 1.3090, Accuracy: 34.38%\n",
      "Epoch [24/30], Step [390/497], Loss: 1.2894, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [400/497], Loss: 1.2844, Accuracy: 46.88%\n",
      "Epoch [24/30], Step [410/497], Loss: 1.1198, Accuracy: 46.88%\n",
      "Epoch [24/30], Step [420/497], Loss: 1.2089, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [430/497], Loss: 0.9215, Accuracy: 65.62%\n",
      "Epoch [24/30], Step [440/497], Loss: 1.2096, Accuracy: 50.00%\n",
      "Epoch [24/30], Step [450/497], Loss: 1.0445, Accuracy: 59.38%\n",
      "Epoch [24/30], Step [460/497], Loss: 1.0267, Accuracy: 62.50%\n",
      "Epoch [24/30], Step [470/497], Loss: 1.2627, Accuracy: 43.75%\n",
      "Epoch [24/30], Step [480/497], Loss: 1.1947, Accuracy: 53.12%\n",
      "Epoch [24/30], Step [490/497], Loss: 1.1582, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [10/497], Loss: 1.1701, Accuracy: 37.50%\n",
      "Epoch [25/30], Step [20/497], Loss: 1.2703, Accuracy: 40.62%\n",
      "Epoch [25/30], Step [30/497], Loss: 1.1100, Accuracy: 53.12%\n",
      "Epoch [25/30], Step [40/497], Loss: 1.1222, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [50/497], Loss: 1.2138, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [60/497], Loss: 1.1692, Accuracy: 53.12%\n",
      "Epoch [25/30], Step [70/497], Loss: 1.2066, Accuracy: 46.88%\n",
      "Epoch [25/30], Step [80/497], Loss: 1.1411, Accuracy: 53.12%\n",
      "Epoch [25/30], Step [90/497], Loss: 1.2478, Accuracy: 53.12%\n",
      "Epoch [25/30], Step [100/497], Loss: 1.1375, Accuracy: 46.88%\n",
      "Epoch [25/30], Step [110/497], Loss: 1.0530, Accuracy: 62.50%\n",
      "Epoch [25/30], Step [120/497], Loss: 1.2752, Accuracy: 37.50%\n",
      "Epoch [25/30], Step [130/497], Loss: 1.1512, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [140/497], Loss: 1.3399, Accuracy: 40.62%\n",
      "Epoch [25/30], Step [150/497], Loss: 1.1253, Accuracy: 56.25%\n",
      "Epoch [25/30], Step [160/497], Loss: 1.2412, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [170/497], Loss: 1.1679, Accuracy: 43.75%\n",
      "Epoch [25/30], Step [180/497], Loss: 1.1816, Accuracy: 43.75%\n",
      "Epoch [25/30], Step [190/497], Loss: 1.0859, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [200/497], Loss: 1.0083, Accuracy: 65.62%\n",
      "Epoch [25/30], Step [210/497], Loss: 1.3126, Accuracy: 46.88%\n",
      "Epoch [25/30], Step [220/497], Loss: 1.2331, Accuracy: 40.62%\n",
      "Epoch [25/30], Step [230/497], Loss: 1.1251, Accuracy: 56.25%\n",
      "Epoch [25/30], Step [240/497], Loss: 1.2326, Accuracy: 40.62%\n",
      "Epoch [25/30], Step [250/497], Loss: 1.1544, Accuracy: 46.88%\n",
      "Epoch [25/30], Step [260/497], Loss: 1.2660, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [270/497], Loss: 1.0776, Accuracy: 59.38%\n",
      "Epoch [25/30], Step [280/497], Loss: 1.2437, Accuracy: 53.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Step [290/497], Loss: 1.2235, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [300/497], Loss: 1.2294, Accuracy: 37.50%\n",
      "Epoch [25/30], Step [310/497], Loss: 1.2953, Accuracy: 34.38%\n",
      "Epoch [25/30], Step [320/497], Loss: 1.2434, Accuracy: 37.50%\n",
      "Epoch [25/30], Step [330/497], Loss: 1.3171, Accuracy: 37.50%\n",
      "Epoch [25/30], Step [340/497], Loss: 1.1888, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [350/497], Loss: 1.1842, Accuracy: 46.88%\n",
      "Epoch [25/30], Step [360/497], Loss: 1.2999, Accuracy: 40.62%\n",
      "Epoch [25/30], Step [370/497], Loss: 1.1449, Accuracy: 56.25%\n",
      "Epoch [25/30], Step [380/497], Loss: 1.1628, Accuracy: 37.50%\n",
      "Epoch [25/30], Step [390/497], Loss: 1.0481, Accuracy: 53.12%\n",
      "Epoch [25/30], Step [400/497], Loss: 1.1795, Accuracy: 46.88%\n",
      "Epoch [25/30], Step [410/497], Loss: 1.2343, Accuracy: 43.75%\n",
      "Epoch [25/30], Step [420/497], Loss: 1.1345, Accuracy: 53.12%\n",
      "Epoch [25/30], Step [430/497], Loss: 1.0454, Accuracy: 56.25%\n",
      "Epoch [25/30], Step [440/497], Loss: 1.1868, Accuracy: 59.38%\n",
      "Epoch [25/30], Step [450/497], Loss: 1.1413, Accuracy: 56.25%\n",
      "Epoch [25/30], Step [460/497], Loss: 1.1616, Accuracy: 50.00%\n",
      "Epoch [25/30], Step [470/497], Loss: 1.2020, Accuracy: 46.88%\n",
      "Epoch [25/30], Step [480/497], Loss: 1.0255, Accuracy: 56.25%\n",
      "Epoch [25/30], Step [490/497], Loss: 1.0545, Accuracy: 56.25%\n",
      "Epoch [26/30], Step [10/497], Loss: 1.1052, Accuracy: 46.88%\n",
      "Epoch [26/30], Step [20/497], Loss: 0.9268, Accuracy: 65.62%\n",
      "Epoch [26/30], Step [30/497], Loss: 1.1211, Accuracy: 40.62%\n",
      "Epoch [26/30], Step [40/497], Loss: 1.2439, Accuracy: 53.12%\n",
      "Epoch [26/30], Step [50/497], Loss: 1.1708, Accuracy: 50.00%\n",
      "Epoch [26/30], Step [60/497], Loss: 1.4127, Accuracy: 34.38%\n",
      "Epoch [26/30], Step [70/497], Loss: 1.1995, Accuracy: 43.75%\n",
      "Epoch [26/30], Step [80/497], Loss: 1.1920, Accuracy: 43.75%\n",
      "Epoch [26/30], Step [90/497], Loss: 1.1501, Accuracy: 56.25%\n",
      "Epoch [26/30], Step [100/497], Loss: 1.3911, Accuracy: 40.62%\n",
      "Epoch [26/30], Step [110/497], Loss: 1.3487, Accuracy: 43.75%\n",
      "Epoch [26/30], Step [120/497], Loss: 1.3538, Accuracy: 40.62%\n",
      "Epoch [26/30], Step [130/497], Loss: 1.1264, Accuracy: 53.12%\n",
      "Epoch [26/30], Step [140/497], Loss: 1.0905, Accuracy: 53.12%\n",
      "Epoch [26/30], Step [150/497], Loss: 1.2894, Accuracy: 37.50%\n",
      "Epoch [26/30], Step [160/497], Loss: 1.1058, Accuracy: 56.25%\n",
      "Epoch [26/30], Step [170/497], Loss: 1.2149, Accuracy: 43.75%\n",
      "Epoch [26/30], Step [180/497], Loss: 0.9934, Accuracy: 65.62%\n",
      "Epoch [26/30], Step [190/497], Loss: 1.1688, Accuracy: 56.25%\n",
      "Epoch [26/30], Step [200/497], Loss: 1.2681, Accuracy: 56.25%\n",
      "Epoch [26/30], Step [210/497], Loss: 1.2769, Accuracy: 56.25%\n",
      "Epoch [26/30], Step [220/497], Loss: 1.3942, Accuracy: 37.50%\n",
      "Epoch [26/30], Step [230/497], Loss: 1.3124, Accuracy: 37.50%\n",
      "Epoch [26/30], Step [240/497], Loss: 1.2102, Accuracy: 40.62%\n",
      "Epoch [26/30], Step [250/497], Loss: 1.0589, Accuracy: 53.12%\n",
      "Epoch [26/30], Step [260/497], Loss: 1.2425, Accuracy: 37.50%\n",
      "Epoch [26/30], Step [270/497], Loss: 1.3328, Accuracy: 43.75%\n",
      "Epoch [26/30], Step [280/497], Loss: 1.4257, Accuracy: 34.38%\n",
      "Epoch [26/30], Step [290/497], Loss: 1.1016, Accuracy: 50.00%\n",
      "Epoch [26/30], Step [300/497], Loss: 1.3235, Accuracy: 43.75%\n",
      "Epoch [26/30], Step [310/497], Loss: 1.1592, Accuracy: 40.62%\n",
      "Epoch [26/30], Step [320/497], Loss: 1.1042, Accuracy: 46.88%\n",
      "Epoch [26/30], Step [330/497], Loss: 1.3099, Accuracy: 53.12%\n",
      "Epoch [26/30], Step [340/497], Loss: 1.0910, Accuracy: 50.00%\n",
      "Epoch [26/30], Step [350/497], Loss: 1.1533, Accuracy: 50.00%\n",
      "Epoch [26/30], Step [360/497], Loss: 1.1647, Accuracy: 56.25%\n",
      "Epoch [26/30], Step [370/497], Loss: 1.4059, Accuracy: 37.50%\n",
      "Epoch [26/30], Step [380/497], Loss: 1.0954, Accuracy: 59.38%\n",
      "Epoch [26/30], Step [390/497], Loss: 1.1857, Accuracy: 56.25%\n",
      "Epoch [26/30], Step [400/497], Loss: 1.2106, Accuracy: 46.88%\n",
      "Epoch [26/30], Step [410/497], Loss: 1.2479, Accuracy: 46.88%\n",
      "Epoch [26/30], Step [420/497], Loss: 1.1762, Accuracy: 43.75%\n",
      "Epoch [26/30], Step [430/497], Loss: 1.3389, Accuracy: 40.62%\n",
      "Epoch [26/30], Step [440/497], Loss: 1.0351, Accuracy: 65.62%\n",
      "Epoch [26/30], Step [450/497], Loss: 1.1815, Accuracy: 53.12%\n",
      "Epoch [26/30], Step [460/497], Loss: 1.2617, Accuracy: 34.38%\n",
      "Epoch [26/30], Step [470/497], Loss: 1.2992, Accuracy: 31.25%\n",
      "Epoch [26/30], Step [480/497], Loss: 1.3209, Accuracy: 43.75%\n",
      "Epoch [26/30], Step [490/497], Loss: 1.3039, Accuracy: 34.38%\n",
      "Epoch [27/30], Step [10/497], Loss: 1.2585, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [20/497], Loss: 1.0555, Accuracy: 56.25%\n",
      "Epoch [27/30], Step [30/497], Loss: 1.1797, Accuracy: 46.88%\n",
      "Epoch [27/30], Step [40/497], Loss: 1.2955, Accuracy: 40.62%\n",
      "Epoch [27/30], Step [50/497], Loss: 1.1400, Accuracy: 50.00%\n",
      "Epoch [27/30], Step [60/497], Loss: 1.1680, Accuracy: 50.00%\n",
      "Epoch [27/30], Step [70/497], Loss: 1.0527, Accuracy: 53.12%\n",
      "Epoch [27/30], Step [80/497], Loss: 1.2168, Accuracy: 50.00%\n",
      "Epoch [27/30], Step [90/497], Loss: 1.1906, Accuracy: 46.88%\n",
      "Epoch [27/30], Step [100/497], Loss: 1.1282, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [110/497], Loss: 1.1833, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [120/497], Loss: 1.1414, Accuracy: 56.25%\n",
      "Epoch [27/30], Step [130/497], Loss: 1.1313, Accuracy: 62.50%\n",
      "Epoch [27/30], Step [140/497], Loss: 1.1379, Accuracy: 53.12%\n",
      "Epoch [27/30], Step [150/497], Loss: 1.3850, Accuracy: 37.50%\n",
      "Epoch [27/30], Step [160/497], Loss: 1.0402, Accuracy: 56.25%\n",
      "Epoch [27/30], Step [170/497], Loss: 1.0119, Accuracy: 53.12%\n",
      "Epoch [27/30], Step [180/497], Loss: 1.0599, Accuracy: 56.25%\n",
      "Epoch [27/30], Step [190/497], Loss: 1.1441, Accuracy: 40.62%\n",
      "Epoch [27/30], Step [200/497], Loss: 1.1474, Accuracy: 56.25%\n",
      "Epoch [27/30], Step [210/497], Loss: 1.2390, Accuracy: 40.62%\n",
      "Epoch [27/30], Step [220/497], Loss: 1.1615, Accuracy: 59.38%\n",
      "Epoch [27/30], Step [230/497], Loss: 1.2450, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [240/497], Loss: 1.1142, Accuracy: 56.25%\n",
      "Epoch [27/30], Step [250/497], Loss: 1.0985, Accuracy: 56.25%\n",
      "Epoch [27/30], Step [260/497], Loss: 1.0550, Accuracy: 56.25%\n",
      "Epoch [27/30], Step [270/497], Loss: 1.3571, Accuracy: 34.38%\n",
      "Epoch [27/30], Step [280/497], Loss: 1.3361, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [290/497], Loss: 1.0649, Accuracy: 59.38%\n",
      "Epoch [27/30], Step [300/497], Loss: 1.1764, Accuracy: 50.00%\n",
      "Epoch [27/30], Step [310/497], Loss: 1.2955, Accuracy: 34.38%\n",
      "Epoch [27/30], Step [320/497], Loss: 1.0818, Accuracy: 53.12%\n",
      "Epoch [27/30], Step [330/497], Loss: 1.1325, Accuracy: 53.12%\n",
      "Epoch [27/30], Step [340/497], Loss: 1.0924, Accuracy: 62.50%\n",
      "Epoch [27/30], Step [350/497], Loss: 1.2591, Accuracy: 46.88%\n",
      "Epoch [27/30], Step [360/497], Loss: 1.2129, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [370/497], Loss: 1.3282, Accuracy: 40.62%\n",
      "Epoch [27/30], Step [380/497], Loss: 1.2621, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [390/497], Loss: 1.2498, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [400/497], Loss: 1.2987, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [410/497], Loss: 1.2993, Accuracy: 31.25%\n",
      "Epoch [27/30], Step [420/497], Loss: 1.1649, Accuracy: 37.50%\n",
      "Epoch [27/30], Step [430/497], Loss: 1.3426, Accuracy: 43.75%\n",
      "Epoch [27/30], Step [440/497], Loss: 0.9519, Accuracy: 68.75%\n",
      "Epoch [27/30], Step [450/497], Loss: 1.3104, Accuracy: 37.50%\n",
      "Epoch [27/30], Step [460/497], Loss: 1.3821, Accuracy: 34.38%\n",
      "Epoch [27/30], Step [470/497], Loss: 1.4277, Accuracy: 34.38%\n",
      "Epoch [27/30], Step [480/497], Loss: 1.1984, Accuracy: 50.00%\n",
      "Epoch [27/30], Step [490/497], Loss: 1.0031, Accuracy: 68.75%\n",
      "Epoch [28/30], Step [10/497], Loss: 1.2684, Accuracy: 37.50%\n",
      "Epoch [28/30], Step [20/497], Loss: 1.2914, Accuracy: 34.38%\n",
      "Epoch [28/30], Step [30/497], Loss: 1.2489, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [40/497], Loss: 1.1595, Accuracy: 53.12%\n",
      "Epoch [28/30], Step [50/497], Loss: 0.9038, Accuracy: 78.12%\n",
      "Epoch [28/30], Step [60/497], Loss: 1.1322, Accuracy: 65.62%\n",
      "Epoch [28/30], Step [70/497], Loss: 1.3316, Accuracy: 40.62%\n",
      "Epoch [28/30], Step [80/497], Loss: 1.3006, Accuracy: 37.50%\n",
      "Epoch [28/30], Step [90/497], Loss: 1.1042, Accuracy: 59.38%\n",
      "Epoch [28/30], Step [100/497], Loss: 1.1708, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [110/497], Loss: 1.2588, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [120/497], Loss: 1.0990, Accuracy: 59.38%\n",
      "Epoch [28/30], Step [130/497], Loss: 1.2645, Accuracy: 46.88%\n",
      "Epoch [28/30], Step [140/497], Loss: 1.3280, Accuracy: 37.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Step [150/497], Loss: 1.3415, Accuracy: 46.88%\n",
      "Epoch [28/30], Step [160/497], Loss: 1.2024, Accuracy: 46.88%\n",
      "Epoch [28/30], Step [170/497], Loss: 1.2109, Accuracy: 53.12%\n",
      "Epoch [28/30], Step [180/497], Loss: 0.9683, Accuracy: 65.62%\n",
      "Epoch [28/30], Step [190/497], Loss: 1.2640, Accuracy: 46.88%\n",
      "Epoch [28/30], Step [200/497], Loss: 1.1446, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [210/497], Loss: 1.1864, Accuracy: 40.62%\n",
      "Epoch [28/30], Step [220/497], Loss: 1.2638, Accuracy: 37.50%\n",
      "Epoch [28/30], Step [230/497], Loss: 1.0246, Accuracy: 59.38%\n",
      "Epoch [28/30], Step [240/497], Loss: 1.2790, Accuracy: 50.00%\n",
      "Epoch [28/30], Step [250/497], Loss: 0.9672, Accuracy: 65.62%\n",
      "Epoch [28/30], Step [260/497], Loss: 1.2879, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [270/497], Loss: 1.2754, Accuracy: 40.62%\n",
      "Epoch [28/30], Step [280/497], Loss: 1.0688, Accuracy: 53.12%\n",
      "Epoch [28/30], Step [290/497], Loss: 1.2227, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [300/497], Loss: 1.2494, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [310/497], Loss: 1.2207, Accuracy: 59.38%\n",
      "Epoch [28/30], Step [320/497], Loss: 1.4096, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [330/497], Loss: 1.2055, Accuracy: 46.88%\n",
      "Epoch [28/30], Step [340/497], Loss: 1.0859, Accuracy: 53.12%\n",
      "Epoch [28/30], Step [350/497], Loss: 1.0871, Accuracy: 59.38%\n",
      "Epoch [28/30], Step [360/497], Loss: 1.4041, Accuracy: 28.12%\n",
      "Epoch [28/30], Step [370/497], Loss: 1.3180, Accuracy: 40.62%\n",
      "Epoch [28/30], Step [380/497], Loss: 1.2010, Accuracy: 46.88%\n",
      "Epoch [28/30], Step [390/497], Loss: 1.1982, Accuracy: 46.88%\n",
      "Epoch [28/30], Step [400/497], Loss: 1.2432, Accuracy: 43.75%\n",
      "Epoch [28/30], Step [410/497], Loss: 1.2143, Accuracy: 56.25%\n",
      "Epoch [28/30], Step [420/497], Loss: 1.2410, Accuracy: 40.62%\n",
      "Epoch [28/30], Step [430/497], Loss: 1.0511, Accuracy: 56.25%\n",
      "Epoch [28/30], Step [440/497], Loss: 0.9700, Accuracy: 59.38%\n",
      "Epoch [28/30], Step [450/497], Loss: 0.9540, Accuracy: 68.75%\n",
      "Epoch [28/30], Step [460/497], Loss: 1.2006, Accuracy: 53.12%\n",
      "Epoch [28/30], Step [470/497], Loss: 1.0112, Accuracy: 56.25%\n",
      "Epoch [28/30], Step [480/497], Loss: 1.1991, Accuracy: 50.00%\n",
      "Epoch [28/30], Step [490/497], Loss: 1.1831, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [10/497], Loss: 1.4029, Accuracy: 28.12%\n",
      "Epoch [29/30], Step [20/497], Loss: 1.0086, Accuracy: 68.75%\n",
      "Epoch [29/30], Step [30/497], Loss: 1.3156, Accuracy: 40.62%\n",
      "Epoch [29/30], Step [40/497], Loss: 1.1904, Accuracy: 59.38%\n",
      "Epoch [29/30], Step [50/497], Loss: 1.2635, Accuracy: 37.50%\n",
      "Epoch [29/30], Step [60/497], Loss: 1.1329, Accuracy: 59.38%\n",
      "Epoch [29/30], Step [70/497], Loss: 1.2356, Accuracy: 56.25%\n",
      "Epoch [29/30], Step [80/497], Loss: 1.2174, Accuracy: 50.00%\n",
      "Epoch [29/30], Step [90/497], Loss: 1.1514, Accuracy: 53.12%\n",
      "Epoch [29/30], Step [100/497], Loss: 1.3385, Accuracy: 40.62%\n",
      "Epoch [29/30], Step [110/497], Loss: 1.2238, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [120/497], Loss: 1.0265, Accuracy: 59.38%\n",
      "Epoch [29/30], Step [130/497], Loss: 1.1517, Accuracy: 50.00%\n",
      "Epoch [29/30], Step [140/497], Loss: 1.1997, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [150/497], Loss: 1.0662, Accuracy: 62.50%\n",
      "Epoch [29/30], Step [160/497], Loss: 1.1183, Accuracy: 43.75%\n",
      "Epoch [29/30], Step [170/497], Loss: 1.1551, Accuracy: 34.38%\n",
      "Epoch [29/30], Step [180/497], Loss: 0.9447, Accuracy: 71.88%\n",
      "Epoch [29/30], Step [190/497], Loss: 1.0336, Accuracy: 62.50%\n",
      "Epoch [29/30], Step [200/497], Loss: 1.1270, Accuracy: 53.12%\n",
      "Epoch [29/30], Step [210/497], Loss: 1.1273, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [220/497], Loss: 1.1761, Accuracy: 53.12%\n",
      "Epoch [29/30], Step [230/497], Loss: 1.0094, Accuracy: 59.38%\n",
      "Epoch [29/30], Step [240/497], Loss: 1.1655, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [250/497], Loss: 1.1935, Accuracy: 43.75%\n",
      "Epoch [29/30], Step [260/497], Loss: 1.1891, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [270/497], Loss: 1.0971, Accuracy: 56.25%\n",
      "Epoch [29/30], Step [280/497], Loss: 1.2894, Accuracy: 37.50%\n",
      "Epoch [29/30], Step [290/497], Loss: 1.1006, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [300/497], Loss: 1.2022, Accuracy: 43.75%\n",
      "Epoch [29/30], Step [310/497], Loss: 1.0531, Accuracy: 56.25%\n",
      "Epoch [29/30], Step [320/497], Loss: 1.2978, Accuracy: 50.00%\n",
      "Epoch [29/30], Step [330/497], Loss: 1.1935, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [340/497], Loss: 1.2167, Accuracy: 34.38%\n",
      "Epoch [29/30], Step [350/497], Loss: 1.1937, Accuracy: 46.88%\n",
      "Epoch [29/30], Step [360/497], Loss: 1.2148, Accuracy: 37.50%\n",
      "Epoch [29/30], Step [370/497], Loss: 1.0760, Accuracy: 50.00%\n",
      "Epoch [29/30], Step [380/497], Loss: 1.0728, Accuracy: 53.12%\n",
      "Epoch [29/30], Step [390/497], Loss: 1.2639, Accuracy: 34.38%\n",
      "Epoch [29/30], Step [400/497], Loss: 1.1683, Accuracy: 56.25%\n",
      "Epoch [29/30], Step [410/497], Loss: 1.1483, Accuracy: 62.50%\n",
      "Epoch [29/30], Step [420/497], Loss: 1.1127, Accuracy: 59.38%\n",
      "Epoch [29/30], Step [430/497], Loss: 1.1263, Accuracy: 59.38%\n",
      "Epoch [29/30], Step [440/497], Loss: 1.1134, Accuracy: 56.25%\n",
      "Epoch [29/30], Step [450/497], Loss: 1.0968, Accuracy: 53.12%\n",
      "Epoch [29/30], Step [460/497], Loss: 1.1099, Accuracy: 50.00%\n",
      "Epoch [29/30], Step [470/497], Loss: 1.1606, Accuracy: 53.12%\n",
      "Epoch [29/30], Step [480/497], Loss: 1.2275, Accuracy: 43.75%\n",
      "Epoch [29/30], Step [490/497], Loss: 1.1795, Accuracy: 53.12%\n",
      "Epoch [30/30], Step [10/497], Loss: 1.1208, Accuracy: 21.88%\n",
      "Epoch [30/30], Step [20/497], Loss: 1.0555, Accuracy: 62.50%\n",
      "Epoch [30/30], Step [30/497], Loss: 0.9180, Accuracy: 68.75%\n",
      "Epoch [30/30], Step [40/497], Loss: 1.1067, Accuracy: 46.88%\n",
      "Epoch [30/30], Step [50/497], Loss: 1.3638, Accuracy: 53.12%\n",
      "Epoch [30/30], Step [60/497], Loss: 1.1298, Accuracy: 43.75%\n",
      "Epoch [30/30], Step [70/497], Loss: 1.1482, Accuracy: 50.00%\n",
      "Epoch [30/30], Step [80/497], Loss: 1.0482, Accuracy: 59.38%\n",
      "Epoch [30/30], Step [90/497], Loss: 1.1959, Accuracy: 40.62%\n",
      "Epoch [30/30], Step [100/497], Loss: 1.1428, Accuracy: 50.00%\n",
      "Epoch [30/30], Step [110/497], Loss: 1.1191, Accuracy: 59.38%\n",
      "Epoch [30/30], Step [120/497], Loss: 1.1040, Accuracy: 56.25%\n",
      "Epoch [30/30], Step [130/497], Loss: 1.1891, Accuracy: 43.75%\n",
      "Epoch [30/30], Step [140/497], Loss: 0.9292, Accuracy: 71.88%\n",
      "Epoch [30/30], Step [150/497], Loss: 1.3986, Accuracy: 25.00%\n",
      "Epoch [30/30], Step [160/497], Loss: 1.3214, Accuracy: 34.38%\n",
      "Epoch [30/30], Step [170/497], Loss: 1.2322, Accuracy: 46.88%\n",
      "Epoch [30/30], Step [180/497], Loss: 1.1293, Accuracy: 50.00%\n",
      "Epoch [30/30], Step [190/497], Loss: 1.0950, Accuracy: 56.25%\n",
      "Epoch [30/30], Step [200/497], Loss: 1.2287, Accuracy: 40.62%\n",
      "Epoch [30/30], Step [210/497], Loss: 1.2826, Accuracy: 46.88%\n",
      "Epoch [30/30], Step [220/497], Loss: 1.1403, Accuracy: 50.00%\n",
      "Epoch [30/30], Step [230/497], Loss: 1.1123, Accuracy: 46.88%\n",
      "Epoch [30/30], Step [240/497], Loss: 1.2104, Accuracy: 53.12%\n",
      "Epoch [30/30], Step [250/497], Loss: 1.2146, Accuracy: 50.00%\n",
      "Epoch [30/30], Step [260/497], Loss: 1.1535, Accuracy: 50.00%\n",
      "Epoch [30/30], Step [270/497], Loss: 1.2921, Accuracy: 40.62%\n",
      "Epoch [30/30], Step [280/497], Loss: 1.1825, Accuracy: 56.25%\n",
      "Epoch [30/30], Step [290/497], Loss: 1.2247, Accuracy: 46.88%\n",
      "Epoch [30/30], Step [300/497], Loss: 1.1621, Accuracy: 46.88%\n",
      "Epoch [30/30], Step [310/497], Loss: 1.3423, Accuracy: 28.12%\n",
      "Epoch [30/30], Step [320/497], Loss: 1.0312, Accuracy: 71.88%\n",
      "Epoch [30/30], Step [330/497], Loss: 1.1424, Accuracy: 53.12%\n",
      "Epoch [30/30], Step [340/497], Loss: 1.1205, Accuracy: 53.12%\n",
      "Epoch [30/30], Step [350/497], Loss: 1.0530, Accuracy: 56.25%\n",
      "Epoch [30/30], Step [360/497], Loss: 1.1810, Accuracy: 43.75%\n",
      "Epoch [30/30], Step [370/497], Loss: 1.1581, Accuracy: 56.25%\n",
      "Epoch [30/30], Step [380/497], Loss: 1.2079, Accuracy: 59.38%\n",
      "Epoch [30/30], Step [390/497], Loss: 1.4066, Accuracy: 34.38%\n",
      "Epoch [30/30], Step [400/497], Loss: 1.2759, Accuracy: 46.88%\n",
      "Epoch [30/30], Step [410/497], Loss: 1.2428, Accuracy: 46.88%\n",
      "Epoch [30/30], Step [420/497], Loss: 1.1470, Accuracy: 37.50%\n",
      "Epoch [30/30], Step [430/497], Loss: 1.2881, Accuracy: 34.38%\n",
      "Epoch [30/30], Step [440/497], Loss: 1.0720, Accuracy: 56.25%\n",
      "Epoch [30/30], Step [450/497], Loss: 1.1506, Accuracy: 40.62%\n",
      "Epoch [30/30], Step [460/497], Loss: 1.2487, Accuracy: 31.25%\n",
      "Epoch [30/30], Step [470/497], Loss: 1.2384, Accuracy: 43.75%\n",
      "Epoch [30/30], Step [480/497], Loss: 1.1866, Accuracy: 43.75%\n",
      "Epoch [30/30], Step [490/497], Loss: 1.4217, Accuracy: 28.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Training Finished in 2404.0386641025543 seconds ###########\n"
     ]
    }
   ],
   "source": [
    "###### Define and run your training loop here #########\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "net.to(device)\n",
    "acc_array = []\n",
    "num_epochs = 30\n",
    "total_steps = len(data_loader_train)\n",
    "t1 = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(data_loader_train):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # Forward pass\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # print(\"kjnfjnrnkrn\",i)\n",
    "        # Backprop and optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(\"second time\",i)\n",
    "        # Train accuracy\n",
    "        total = labels.size(0)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
    "                    (correct / total) * 100))\n",
    "            accuracy = (correct / total) * 100\n",
    "            acc_array.append(float(accuracy))\n",
    "            \n",
    "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed2f139e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 5292 test images: 48.41269841269841 %\n"
     ]
    }
   ],
   "source": [
    "######## Write your code here #############\n",
    "net.eval() \n",
    "count=0\n",
    "with torch.no_grad(): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in data_loader_test:\n",
    "        # count+=1\n",
    "        # print(count)\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the {} test images: {} %'\n",
    "        .format(total, (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813085c",
   "metadata": {},
   "source": [
    "## Training with Model directly from Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4066fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Admin/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False).to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68fc1795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Epoch [1/5], Step [10/497], Loss: 6.7191, Accuracy: 50.00%\n",
      "Epoch [1/5], Step [20/497], Loss: 5.9979, Accuracy: 46.88%\n",
      "Epoch [1/5], Step [30/497], Loss: 1.5149, Accuracy: 43.75%\n",
      "Epoch [1/5], Step [40/497], Loss: 1.5791, Accuracy: 34.38%\n",
      "Epoch [1/5], Step [50/497], Loss: 1.3338, Accuracy: 40.62%\n",
      "Epoch [1/5], Step [60/497], Loss: 1.2137, Accuracy: 50.00%\n",
      "Epoch [1/5], Step [70/497], Loss: 1.2648, Accuracy: 43.75%\n",
      "Epoch [1/5], Step [80/497], Loss: 1.1942, Accuracy: 46.88%\n",
      "Epoch [1/5], Step [90/497], Loss: 1.3345, Accuracy: 43.75%\n",
      "Epoch [1/5], Step [100/497], Loss: 1.3920, Accuracy: 40.62%\n",
      "Epoch [1/5], Step [110/497], Loss: 1.1425, Accuracy: 53.12%\n",
      "Epoch [1/5], Step [120/497], Loss: 1.2261, Accuracy: 46.88%\n",
      "Epoch [1/5], Step [130/497], Loss: 1.2162, Accuracy: 37.50%\n",
      "Epoch [1/5], Step [140/497], Loss: 1.0173, Accuracy: 68.75%\n",
      "Epoch [1/5], Step [150/497], Loss: 0.9700, Accuracy: 62.50%\n",
      "Epoch [1/5], Step [160/497], Loss: 1.0369, Accuracy: 65.62%\n",
      "Epoch [1/5], Step [170/497], Loss: 1.2753, Accuracy: 37.50%\n",
      "Epoch [1/5], Step [180/497], Loss: 0.9659, Accuracy: 56.25%\n",
      "Epoch [1/5], Step [190/497], Loss: 1.2298, Accuracy: 40.62%\n",
      "Epoch [1/5], Step [200/497], Loss: 1.1470, Accuracy: 53.12%\n",
      "Epoch [1/5], Step [210/497], Loss: 0.8961, Accuracy: 71.88%\n",
      "Epoch [1/5], Step [220/497], Loss: 0.9674, Accuracy: 75.00%\n",
      "Epoch [1/5], Step [230/497], Loss: 1.1660, Accuracy: 50.00%\n",
      "Epoch [1/5], Step [240/497], Loss: 0.8090, Accuracy: 65.62%\n",
      "Epoch [1/5], Step [250/497], Loss: 0.9647, Accuracy: 56.25%\n",
      "Epoch [1/5], Step [260/497], Loss: 1.0258, Accuracy: 59.38%\n",
      "Epoch [1/5], Step [270/497], Loss: 1.0252, Accuracy: 50.00%\n",
      "Epoch [1/5], Step [280/497], Loss: 0.6775, Accuracy: 78.12%\n",
      "Epoch [1/5], Step [290/497], Loss: 0.8214, Accuracy: 71.88%\n",
      "Epoch [1/5], Step [300/497], Loss: 0.8869, Accuracy: 62.50%\n",
      "Epoch [1/5], Step [310/497], Loss: 0.9188, Accuracy: 62.50%\n",
      "Epoch [1/5], Step [320/497], Loss: 1.1127, Accuracy: 56.25%\n",
      "Epoch [1/5], Step [330/497], Loss: 0.9069, Accuracy: 65.62%\n",
      "Epoch [1/5], Step [340/497], Loss: 0.8597, Accuracy: 65.62%\n",
      "Epoch [1/5], Step [350/497], Loss: 0.8829, Accuracy: 65.62%\n",
      "Epoch [1/5], Step [360/497], Loss: 0.8570, Accuracy: 59.38%\n",
      "Epoch [1/5], Step [370/497], Loss: 0.8656, Accuracy: 65.62%\n",
      "Epoch [1/5], Step [380/497], Loss: 0.6837, Accuracy: 81.25%\n",
      "Epoch [1/5], Step [390/497], Loss: 0.5735, Accuracy: 75.00%\n",
      "Epoch [1/5], Step [400/497], Loss: 0.8751, Accuracy: 59.38%\n",
      "Epoch [1/5], Step [410/497], Loss: 1.0003, Accuracy: 53.12%\n",
      "Epoch [1/5], Step [420/497], Loss: 0.8191, Accuracy: 62.50%\n",
      "Epoch [1/5], Step [430/497], Loss: 0.6494, Accuracy: 71.88%\n",
      "Epoch [1/5], Step [440/497], Loss: 0.5628, Accuracy: 71.88%\n",
      "Epoch [1/5], Step [450/497], Loss: 0.9865, Accuracy: 53.12%\n",
      "Epoch [1/5], Step [460/497], Loss: 0.6937, Accuracy: 71.88%\n",
      "Epoch [1/5], Step [470/497], Loss: 0.7298, Accuracy: 65.62%\n",
      "Epoch [1/5], Step [480/497], Loss: 0.9339, Accuracy: 59.38%\n",
      "Epoch [1/5], Step [490/497], Loss: 1.2558, Accuracy: 53.12%\n",
      "Epoch [2/5], Step [10/497], Loss: 0.9566, Accuracy: 68.75%\n",
      "Epoch [2/5], Step [20/497], Loss: 0.6989, Accuracy: 68.75%\n",
      "Epoch [2/5], Step [30/497], Loss: 0.7720, Accuracy: 65.62%\n",
      "Epoch [2/5], Step [40/497], Loss: 0.5554, Accuracy: 81.25%\n",
      "Epoch [2/5], Step [50/497], Loss: 0.8396, Accuracy: 53.12%\n",
      "Epoch [2/5], Step [60/497], Loss: 0.8522, Accuracy: 65.62%\n",
      "Epoch [2/5], Step [70/497], Loss: 0.9142, Accuracy: 53.12%\n",
      "Epoch [2/5], Step [80/497], Loss: 0.6878, Accuracy: 68.75%\n",
      "Epoch [2/5], Step [90/497], Loss: 0.5515, Accuracy: 71.88%\n",
      "Epoch [2/5], Step [100/497], Loss: 0.7074, Accuracy: 75.00%\n",
      "Epoch [2/5], Step [110/497], Loss: 0.5698, Accuracy: 78.12%\n",
      "Epoch [2/5], Step [120/497], Loss: 0.4525, Accuracy: 81.25%\n",
      "Epoch [2/5], Step [130/497], Loss: 0.6024, Accuracy: 81.25%\n",
      "Epoch [2/5], Step [140/497], Loss: 1.0400, Accuracy: 56.25%\n",
      "Epoch [2/5], Step [150/497], Loss: 0.8822, Accuracy: 75.00%\n",
      "Epoch [2/5], Step [160/497], Loss: 0.9632, Accuracy: 68.75%\n",
      "Epoch [2/5], Step [170/497], Loss: 0.6942, Accuracy: 71.88%\n",
      "Epoch [2/5], Step [180/497], Loss: 0.6607, Accuracy: 75.00%\n",
      "Epoch [2/5], Step [190/497], Loss: 0.6388, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [200/497], Loss: 0.5241, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [210/497], Loss: 0.5593, Accuracy: 81.25%\n",
      "Epoch [2/5], Step [220/497], Loss: 0.7309, Accuracy: 68.75%\n",
      "Epoch [2/5], Step [230/497], Loss: 0.5936, Accuracy: 78.12%\n",
      "Epoch [2/5], Step [240/497], Loss: 0.5718, Accuracy: 78.12%\n",
      "Epoch [2/5], Step [250/497], Loss: 0.4843, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [260/497], Loss: 0.6512, Accuracy: 75.00%\n",
      "Epoch [2/5], Step [270/497], Loss: 0.7355, Accuracy: 65.62%\n",
      "Epoch [2/5], Step [280/497], Loss: 0.3599, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [290/497], Loss: 0.6171, Accuracy: 75.00%\n",
      "Epoch [2/5], Step [300/497], Loss: 0.4671, Accuracy: 81.25%\n",
      "Epoch [2/5], Step [310/497], Loss: 0.5775, Accuracy: 75.00%\n",
      "Epoch [2/5], Step [320/497], Loss: 0.7898, Accuracy: 68.75%\n",
      "Epoch [2/5], Step [330/497], Loss: 0.8217, Accuracy: 65.62%\n",
      "Epoch [2/5], Step [340/497], Loss: 0.7373, Accuracy: 71.88%\n",
      "Epoch [2/5], Step [350/497], Loss: 0.6151, Accuracy: 78.12%\n",
      "Epoch [2/5], Step [360/497], Loss: 0.7702, Accuracy: 62.50%\n",
      "Epoch [2/5], Step [370/497], Loss: 0.7677, Accuracy: 68.75%\n",
      "Epoch [2/5], Step [380/497], Loss: 0.6121, Accuracy: 75.00%\n",
      "Epoch [2/5], Step [390/497], Loss: 0.6012, Accuracy: 78.12%\n",
      "Epoch [2/5], Step [400/497], Loss: 0.4710, Accuracy: 78.12%\n",
      "Epoch [2/5], Step [410/497], Loss: 0.6966, Accuracy: 71.88%\n",
      "Epoch [2/5], Step [420/497], Loss: 0.4764, Accuracy: 84.38%\n",
      "Epoch [2/5], Step [430/497], Loss: 0.6049, Accuracy: 71.88%\n",
      "Epoch [2/5], Step [440/497], Loss: 1.1600, Accuracy: 65.62%\n",
      "Epoch [2/5], Step [450/497], Loss: 0.6272, Accuracy: 81.25%\n",
      "Epoch [2/5], Step [460/497], Loss: 0.6631, Accuracy: 65.62%\n",
      "Epoch [2/5], Step [470/497], Loss: 0.7232, Accuracy: 68.75%\n",
      "Epoch [2/5], Step [480/497], Loss: 0.5330, Accuracy: 71.88%\n",
      "Epoch [2/5], Step [490/497], Loss: 0.5529, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [10/497], Loss: 0.5463, Accuracy: 75.00%\n",
      "Epoch [3/5], Step [20/497], Loss: 0.8690, Accuracy: 62.50%\n",
      "Epoch [3/5], Step [30/497], Loss: 0.5696, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [40/497], Loss: 0.4132, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [50/497], Loss: 0.8550, Accuracy: 71.88%\n",
      "Epoch [3/5], Step [60/497], Loss: 0.7715, Accuracy: 68.75%\n",
      "Epoch [3/5], Step [70/497], Loss: 0.7555, Accuracy: 65.62%\n",
      "Epoch [3/5], Step [80/497], Loss: 0.5380, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [90/497], Loss: 0.6340, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [100/497], Loss: 0.4517, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [110/497], Loss: 0.4027, Accuracy: 84.38%\n",
      "Epoch [3/5], Step [120/497], Loss: 0.6521, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [130/497], Loss: 0.5921, Accuracy: 71.88%\n",
      "Epoch [3/5], Step [140/497], Loss: 0.3741, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [150/497], Loss: 0.7299, Accuracy: 75.00%\n",
      "Epoch [3/5], Step [160/497], Loss: 0.6151, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [170/497], Loss: 0.5547, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [180/497], Loss: 0.5183, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [190/497], Loss: 0.4200, Accuracy: 90.62%\n",
      "Epoch [3/5], Step [200/497], Loss: 0.4483, Accuracy: 90.62%\n",
      "Epoch [3/5], Step [210/497], Loss: 0.6244, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [220/497], Loss: 0.5923, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [230/497], Loss: 0.6665, Accuracy: 68.75%\n",
      "Epoch [3/5], Step [240/497], Loss: 0.6923, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [250/497], Loss: 0.3744, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [260/497], Loss: 0.4755, Accuracy: 90.62%\n",
      "Epoch [3/5], Step [270/497], Loss: 0.5644, Accuracy: 71.88%\n",
      "Epoch [3/5], Step [280/497], Loss: 0.5173, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [290/497], Loss: 0.5375, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [300/497], Loss: 0.7639, Accuracy: 65.62%\n",
      "Epoch [3/5], Step [310/497], Loss: 0.4459, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [320/497], Loss: 0.3493, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [330/497], Loss: 0.7059, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [340/497], Loss: 0.8369, Accuracy: 68.75%\n",
      "Epoch [3/5], Step [350/497], Loss: 0.5685, Accuracy: 75.00%\n",
      "Epoch [3/5], Step [360/497], Loss: 0.6994, Accuracy: 71.88%\n",
      "Epoch [3/5], Step [370/497], Loss: 0.5409, Accuracy: 84.38%\n",
      "Epoch [3/5], Step [380/497], Loss: 0.6714, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [390/497], Loss: 0.2828, Accuracy: 96.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [400/497], Loss: 0.2448, Accuracy: 90.62%\n",
      "Epoch [3/5], Step [410/497], Loss: 0.3384, Accuracy: 90.62%\n",
      "Epoch [3/5], Step [420/497], Loss: 0.7493, Accuracy: 68.75%\n",
      "Epoch [3/5], Step [430/497], Loss: 0.4505, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [440/497], Loss: 0.5082, Accuracy: 84.38%\n",
      "Epoch [3/5], Step [450/497], Loss: 0.8902, Accuracy: 59.38%\n",
      "Epoch [3/5], Step [460/497], Loss: 0.8193, Accuracy: 65.62%\n",
      "Epoch [3/5], Step [470/497], Loss: 0.3337, Accuracy: 90.62%\n",
      "Epoch [3/5], Step [480/497], Loss: 0.4018, Accuracy: 78.12%\n",
      "Epoch [3/5], Step [490/497], Loss: 0.4334, Accuracy: 81.25%\n",
      "Epoch [4/5], Step [10/497], Loss: 0.6456, Accuracy: 71.88%\n",
      "Epoch [4/5], Step [20/497], Loss: 0.4619, Accuracy: 81.25%\n",
      "Epoch [4/5], Step [30/497], Loss: 0.4107, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [40/497], Loss: 0.6175, Accuracy: 81.25%\n",
      "Epoch [4/5], Step [50/497], Loss: 0.8013, Accuracy: 65.62%\n",
      "Epoch [4/5], Step [60/497], Loss: 0.4664, Accuracy: 81.25%\n",
      "Epoch [4/5], Step [70/497], Loss: 0.5154, Accuracy: 75.00%\n",
      "Epoch [4/5], Step [80/497], Loss: 0.5650, Accuracy: 75.00%\n",
      "Epoch [4/5], Step [90/497], Loss: 0.2696, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [100/497], Loss: 0.3497, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [110/497], Loss: 0.2287, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [120/497], Loss: 0.3049, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [130/497], Loss: 0.2895, Accuracy: 93.75%\n",
      "Epoch [4/5], Step [140/497], Loss: 0.4251, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [150/497], Loss: 0.4085, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [160/497], Loss: 0.2655, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [170/497], Loss: 0.6461, Accuracy: 75.00%\n",
      "Epoch [4/5], Step [180/497], Loss: 0.2660, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [190/497], Loss: 0.7023, Accuracy: 71.88%\n",
      "Epoch [4/5], Step [200/497], Loss: 0.4391, Accuracy: 81.25%\n",
      "Epoch [4/5], Step [210/497], Loss: 0.4076, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [220/497], Loss: 0.7501, Accuracy: 65.62%\n",
      "Epoch [4/5], Step [230/497], Loss: 0.3709, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [240/497], Loss: 0.7210, Accuracy: 75.00%\n",
      "Epoch [4/5], Step [250/497], Loss: 0.2396, Accuracy: 93.75%\n",
      "Epoch [4/5], Step [260/497], Loss: 0.6336, Accuracy: 78.12%\n",
      "Epoch [4/5], Step [270/497], Loss: 0.4290, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [280/497], Loss: 0.7525, Accuracy: 78.12%\n",
      "Epoch [4/5], Step [290/497], Loss: 0.6014, Accuracy: 78.12%\n",
      "Epoch [4/5], Step [300/497], Loss: 0.4842, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [310/497], Loss: 0.3374, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [320/497], Loss: 0.1228, Accuracy: 100.00%\n",
      "Epoch [4/5], Step [330/497], Loss: 0.5378, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [340/497], Loss: 0.3930, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [350/497], Loss: 1.0645, Accuracy: 75.00%\n",
      "Epoch [4/5], Step [360/497], Loss: 0.2752, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [370/497], Loss: 0.3034, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [380/497], Loss: 0.4409, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [390/497], Loss: 0.4684, Accuracy: 78.12%\n",
      "Epoch [4/5], Step [400/497], Loss: 0.4184, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [410/497], Loss: 0.5085, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [420/497], Loss: 0.4168, Accuracy: 78.12%\n",
      "Epoch [4/5], Step [430/497], Loss: 0.4577, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [440/497], Loss: 0.5401, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [450/497], Loss: 0.4007, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [460/497], Loss: 0.2061, Accuracy: 96.88%\n",
      "Epoch [4/5], Step [470/497], Loss: 0.5096, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [480/497], Loss: 0.3418, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [490/497], Loss: 0.5330, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [10/497], Loss: 0.3974, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [20/497], Loss: 0.5930, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [30/497], Loss: 0.5938, Accuracy: 75.00%\n",
      "Epoch [5/5], Step [40/497], Loss: 0.3320, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [50/497], Loss: 0.4132, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [60/497], Loss: 0.3230, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [70/497], Loss: 0.3069, Accuracy: 93.75%\n",
      "Epoch [5/5], Step [80/497], Loss: 0.2658, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [90/497], Loss: 0.5333, Accuracy: 81.25%\n",
      "Epoch [5/5], Step [100/497], Loss: 0.5074, Accuracy: 78.12%\n",
      "Epoch [5/5], Step [110/497], Loss: 0.3263, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [120/497], Loss: 0.4026, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [130/497], Loss: 0.2385, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [140/497], Loss: 0.3417, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [150/497], Loss: 0.4773, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [160/497], Loss: 0.3693, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [170/497], Loss: 0.3171, Accuracy: 93.75%\n",
      "Epoch [5/5], Step [180/497], Loss: 0.3389, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [190/497], Loss: 0.4330, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [200/497], Loss: 0.7161, Accuracy: 71.88%\n",
      "Epoch [5/5], Step [210/497], Loss: 0.2082, Accuracy: 96.88%\n",
      "Epoch [5/5], Step [220/497], Loss: 0.5553, Accuracy: 78.12%\n",
      "Epoch [5/5], Step [230/497], Loss: 0.4711, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [240/497], Loss: 0.3604, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [250/497], Loss: 0.3703, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [260/497], Loss: 0.3486, Accuracy: 81.25%\n",
      "Epoch [5/5], Step [270/497], Loss: 0.5292, Accuracy: 78.12%\n",
      "Epoch [5/5], Step [280/497], Loss: 0.2590, Accuracy: 93.75%\n",
      "Epoch [5/5], Step [290/497], Loss: 0.4400, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [300/497], Loss: 0.4533, Accuracy: 75.00%\n",
      "Epoch [5/5], Step [310/497], Loss: 0.2219, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [320/497], Loss: 0.5429, Accuracy: 71.88%\n",
      "Epoch [5/5], Step [330/497], Loss: 0.3709, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [340/497], Loss: 0.6457, Accuracy: 75.00%\n",
      "Epoch [5/5], Step [350/497], Loss: 0.4523, Accuracy: 78.12%\n",
      "Epoch [5/5], Step [360/497], Loss: 0.4498, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [370/497], Loss: 0.3722, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [380/497], Loss: 0.5859, Accuracy: 81.25%\n",
      "Epoch [5/5], Step [390/497], Loss: 0.3760, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [400/497], Loss: 0.3000, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [410/497], Loss: 0.4986, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [420/497], Loss: 0.3049, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [430/497], Loss: 0.5142, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [440/497], Loss: 0.2914, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [450/497], Loss: 0.4466, Accuracy: 81.25%\n",
      "Epoch [5/5], Step [460/497], Loss: 0.4972, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [470/497], Loss: 0.2901, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [480/497], Loss: 0.3640, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [490/497], Loss: 0.4310, Accuracy: 90.62%\n",
      "######## Training Finished in 428.564551115036 seconds ###########\n"
     ]
    }
   ],
   "source": [
    "###### Define and run your training loop here #########\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "total_steps = len(data_loader_train)\n",
    "t1 = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(data_loader_train):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print(\"kjnfjnrnkrn\",i)\\\\\n",
    "        # Backprop and optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(\"second time\",i)\n",
    "        # Train accuracy\n",
    "        total = labels.size(0)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
    "                    (correct / total) * 100))\n",
    "            \n",
    "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09889cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 5292 test images: 77.5132275132275 %\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "perds = []\n",
    "target = []\n",
    "with torch.no_grad(): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in data_loader_test:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        perds.extend(predicted)\n",
    "        target.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the {} test images: {} %'\n",
    "        .format(total, (correct / total) * 100))\n",
    "    \n",
    "# plt.plot(Accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e46517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
      "     -------------------------------------- 529.7/529.7 kB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (4.3.0)\n",
      "Requirement already satisfied: torch>=1.3.1 in c:\\users\\admin\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\admin\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (1.23.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\envs\\pytorch\\lib\\site-packages (from packaging->torchmetrics) (3.0.9)\n",
      "Installing collected packages: torchmetrics\n",
      "Successfully installed torchmetrics-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "442e3365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7751, device='cuda:0')\n",
      "(tensor(0.8440, device='cuda:0'), tensor(0.7099, device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 272,  227,  397,    3],\n",
       "        [   6, 1179,  374,    0],\n",
       "        [  10,  101, 2392,   20],\n",
       "        [   1,   38,   13,  259]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.functional import precision_recall\n",
    "from torchmetrics import F1Score\n",
    "from torchmetrics import ConfusionMatrix\n",
    "perds1 = torch.stack(perds)\n",
    "target1 = torch.stack(target)\n",
    "f1 = F1Score(num_classes=4).to(device)\n",
    "print(f1(perds1, target1))\n",
    "print(precision_recall(perds1, target1, average='macro', num_classes=4))\n",
    "confmat = ConfusionMatrix(num_classes=4).to(device)\n",
    "confmat(perds1, target1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
