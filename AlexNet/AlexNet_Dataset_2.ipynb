{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a3e79247",
      "metadata": {
        "id": "a3e79247"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as td\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNa7s6OrU8A1",
        "outputId": "d4624c15-2123-46ca-e03a-88b67bfb1ebe"
      },
      "id": "FNa7s6OrU8A1",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "308235d6",
      "metadata": {
        "id": "308235d6"
      },
      "outputs": [],
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "def load_data(path,batch_size,input_size):\n",
        "    \n",
        "    normalize = transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ]) \n",
        "    transform_dict = {\"src\":  normalize}  \n",
        "    # train_path=path+\"/train\"\n",
        "    # test_path=path+\"/test\"\n",
        "    data = datasets.ImageFolder(root=path,transform=transform_dict[\"src\"])\n",
        "    # transform_dict1 = {\"test\":  normalize} \n",
        "    # test1 = datasets.ImageFolder(root=path,transform=transform_dict[\"test\"])\n",
        "    # transform_dict = {\"test\":  normalize}\n",
        "    # test= datasets.ImageFolder(root=path,transform=transform_dict[\"test\"])\n",
        "    # train_size = int((1- (test_split + val_split)) * len(data))\n",
        "    # test_size = int((1 - (val_split)) * len(data)) - train_size\n",
        "    # val_size = len(data) - train_size - test_size\n",
        "    train_size=int(0.75*len(data))\n",
        "    print(len(data))\n",
        "    test_size=int(len(data)-train_size)\n",
        "    train, test = td.random_split(data,[train_size,test_size])\n",
        "\n",
        "    data_loader_train = td.DataLoader(train,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    data_loader_test = td.DataLoader(test,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    # data_loader_val = td.DataLoader(val,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    return data_loader_train, data_loader_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cae6e61b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cae6e61b",
        "outputId": "7f5eb62c-7288-4c73-ad4d-913eb2103dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6922\n"
          ]
        }
      ],
      "source": [
        "data_loader_train,data_loader_test=load_data(r\"/content/drive/MyDrive/Project/datasets/Dataset2\",32,40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "16170f93",
      "metadata": {
        "id": "16170f93"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes: int = 4):\n",
        "        super().__init__()\n",
        "#         _log_api_usage_once(self)\n",
        "        self.features = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            torch.nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            torch.nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = torch.nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(256 * 6 * 6, 4096),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(4096, 4096),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x) :\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f2b7e6f6",
      "metadata": {
        "id": "f2b7e6f6"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "net = AlexNet(3).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8efa56f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8efa56f0",
        "outputId": "d5f31bda-3c17-4fbe-bc9a-462d69c5fc79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Epoch [1/20], Step [10/163], Loss: 1.0981, Accuracy: 40.62%\n",
            "Epoch [1/20], Step [20/163], Loss: 1.0981, Accuracy: 25.00%\n",
            "Epoch [1/20], Step [30/163], Loss: 1.0626, Accuracy: 50.00%\n",
            "Epoch [1/20], Step [40/163], Loss: 1.0912, Accuracy: 34.38%\n",
            "Epoch [1/20], Step [50/163], Loss: 1.0934, Accuracy: 37.50%\n",
            "Epoch [1/20], Step [60/163], Loss: 1.1392, Accuracy: 18.75%\n",
            "Epoch [1/20], Step [70/163], Loss: 1.0302, Accuracy: 31.25%\n",
            "Epoch [1/20], Step [80/163], Loss: 1.1423, Accuracy: 31.25%\n",
            "Epoch [1/20], Step [90/163], Loss: 1.0073, Accuracy: 50.00%\n",
            "Epoch [1/20], Step [100/163], Loss: 1.1445, Accuracy: 28.12%\n",
            "Epoch [1/20], Step [110/163], Loss: 1.0799, Accuracy: 40.62%\n",
            "Epoch [1/20], Step [120/163], Loss: 1.1202, Accuracy: 43.75%\n",
            "Epoch [1/20], Step [130/163], Loss: 1.0691, Accuracy: 40.62%\n",
            "Epoch [1/20], Step [140/163], Loss: 1.0952, Accuracy: 46.88%\n",
            "Epoch [1/20], Step [150/163], Loss: 1.0431, Accuracy: 62.50%\n",
            "Epoch [1/20], Step [160/163], Loss: 1.1520, Accuracy: 40.62%\n",
            "Epoch [2/20], Step [10/163], Loss: 0.8445, Accuracy: 62.50%\n",
            "Epoch [2/20], Step [20/163], Loss: 1.0541, Accuracy: 46.88%\n",
            "Epoch [2/20], Step [30/163], Loss: 1.4761, Accuracy: 18.75%\n",
            "Epoch [2/20], Step [40/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [2/20], Step [50/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [2/20], Step [60/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [2/20], Step [70/163], Loss: nan, Accuracy: 65.62%\n",
            "Epoch [2/20], Step [80/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [2/20], Step [90/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [2/20], Step [100/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [2/20], Step [110/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [2/20], Step [120/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [2/20], Step [130/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [2/20], Step [140/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [2/20], Step [150/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [2/20], Step [160/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [3/20], Step [10/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [3/20], Step [20/163], Loss: nan, Accuracy: 3.12%\n",
            "Epoch [3/20], Step [30/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [3/20], Step [40/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [3/20], Step [50/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [3/20], Step [60/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [3/20], Step [70/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [3/20], Step [80/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [3/20], Step [90/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [3/20], Step [100/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [3/20], Step [110/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [3/20], Step [120/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [3/20], Step [130/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [3/20], Step [140/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [3/20], Step [150/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [3/20], Step [160/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [4/20], Step [10/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [4/20], Step [20/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [4/20], Step [30/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [4/20], Step [40/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [4/20], Step [50/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [4/20], Step [60/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [4/20], Step [70/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [4/20], Step [80/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [4/20], Step [90/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [4/20], Step [100/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [4/20], Step [110/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [4/20], Step [120/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [4/20], Step [130/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [4/20], Step [140/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [4/20], Step [150/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [4/20], Step [160/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [5/20], Step [10/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [5/20], Step [20/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [5/20], Step [30/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [5/20], Step [40/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [5/20], Step [50/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [5/20], Step [60/163], Loss: nan, Accuracy: 18.75%\n",
            "Epoch [5/20], Step [70/163], Loss: nan, Accuracy: 46.88%\n",
            "Epoch [5/20], Step [80/163], Loss: nan, Accuracy: 46.88%\n",
            "Epoch [5/20], Step [90/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [5/20], Step [100/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [5/20], Step [110/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [5/20], Step [120/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [5/20], Step [130/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [5/20], Step [140/163], Loss: nan, Accuracy: 18.75%\n",
            "Epoch [5/20], Step [150/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [5/20], Step [160/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [6/20], Step [10/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [6/20], Step [20/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [6/20], Step [30/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [6/20], Step [40/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [6/20], Step [50/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [6/20], Step [60/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [6/20], Step [70/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [6/20], Step [80/163], Loss: nan, Accuracy: 50.00%\n",
            "Epoch [6/20], Step [90/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [6/20], Step [100/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [6/20], Step [110/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [6/20], Step [120/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [6/20], Step [130/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [6/20], Step [140/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [6/20], Step [150/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [6/20], Step [160/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [7/20], Step [10/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [7/20], Step [20/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [7/20], Step [30/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [7/20], Step [40/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [7/20], Step [50/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [7/20], Step [60/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [7/20], Step [70/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [7/20], Step [80/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [7/20], Step [90/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [7/20], Step [100/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [7/20], Step [110/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [7/20], Step [120/163], Loss: nan, Accuracy: 56.25%\n",
            "Epoch [7/20], Step [130/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [7/20], Step [140/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [7/20], Step [150/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [7/20], Step [160/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [8/20], Step [10/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [8/20], Step [20/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [8/20], Step [30/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [8/20], Step [40/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [8/20], Step [50/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [8/20], Step [60/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [8/20], Step [70/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [8/20], Step [80/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [8/20], Step [90/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [8/20], Step [100/163], Loss: nan, Accuracy: 53.12%\n",
            "Epoch [8/20], Step [110/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [8/20], Step [120/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [8/20], Step [130/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [8/20], Step [140/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [8/20], Step [150/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [8/20], Step [160/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [9/20], Step [10/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [9/20], Step [20/163], Loss: nan, Accuracy: 50.00%\n",
            "Epoch [9/20], Step [30/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [9/20], Step [40/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [9/20], Step [50/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [9/20], Step [60/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [9/20], Step [70/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [9/20], Step [80/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [9/20], Step [90/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [9/20], Step [100/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [9/20], Step [110/163], Loss: nan, Accuracy: 18.75%\n",
            "Epoch [9/20], Step [120/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [9/20], Step [130/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [9/20], Step [140/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [9/20], Step [150/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [9/20], Step [160/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [10/20], Step [10/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [10/20], Step [20/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [10/20], Step [30/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [10/20], Step [40/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [10/20], Step [50/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [10/20], Step [60/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [10/20], Step [70/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [10/20], Step [80/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [10/20], Step [90/163], Loss: nan, Accuracy: 56.25%\n",
            "Epoch [10/20], Step [100/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [10/20], Step [110/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [10/20], Step [120/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [10/20], Step [130/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [10/20], Step [140/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [10/20], Step [150/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [10/20], Step [160/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [11/20], Step [10/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [11/20], Step [20/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [11/20], Step [30/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [11/20], Step [40/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [11/20], Step [50/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [11/20], Step [60/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [11/20], Step [70/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [11/20], Step [80/163], Loss: nan, Accuracy: 18.75%\n",
            "Epoch [11/20], Step [90/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [11/20], Step [100/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [11/20], Step [110/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [11/20], Step [120/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [11/20], Step [130/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [11/20], Step [140/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [11/20], Step [150/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [11/20], Step [160/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [12/20], Step [10/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [12/20], Step [20/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [12/20], Step [30/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [12/20], Step [40/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [12/20], Step [50/163], Loss: nan, Accuracy: 56.25%\n",
            "Epoch [12/20], Step [60/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [12/20], Step [70/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [12/20], Step [80/163], Loss: nan, Accuracy: 46.88%\n",
            "Epoch [12/20], Step [90/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [12/20], Step [100/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [12/20], Step [110/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [12/20], Step [120/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [12/20], Step [130/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [12/20], Step [140/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [12/20], Step [150/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [12/20], Step [160/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [13/20], Step [10/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [13/20], Step [20/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [13/20], Step [30/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [13/20], Step [40/163], Loss: nan, Accuracy: 53.12%\n",
            "Epoch [13/20], Step [50/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [13/20], Step [60/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [13/20], Step [70/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [13/20], Step [80/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [13/20], Step [90/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [13/20], Step [100/163], Loss: nan, Accuracy: 15.62%\n",
            "Epoch [13/20], Step [110/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [13/20], Step [120/163], Loss: nan, Accuracy: 18.75%\n",
            "Epoch [13/20], Step [130/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [13/20], Step [140/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [13/20], Step [150/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [13/20], Step [160/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [14/20], Step [10/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [14/20], Step [20/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [14/20], Step [30/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [14/20], Step [40/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [14/20], Step [50/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [14/20], Step [60/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [14/20], Step [70/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [14/20], Step [80/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [14/20], Step [90/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [14/20], Step [100/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [14/20], Step [110/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [14/20], Step [120/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [14/20], Step [130/163], Loss: nan, Accuracy: 46.88%\n",
            "Epoch [14/20], Step [140/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [14/20], Step [150/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [14/20], Step [160/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [15/20], Step [10/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [15/20], Step [20/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [15/20], Step [30/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [15/20], Step [40/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [15/20], Step [50/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [15/20], Step [60/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [15/20], Step [70/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [15/20], Step [80/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [15/20], Step [90/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [15/20], Step [100/163], Loss: nan, Accuracy: 18.75%\n",
            "Epoch [15/20], Step [110/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [15/20], Step [120/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [15/20], Step [130/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [15/20], Step [140/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [15/20], Step [150/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [15/20], Step [160/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [16/20], Step [10/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [16/20], Step [20/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [16/20], Step [30/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [16/20], Step [40/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [16/20], Step [50/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [16/20], Step [60/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [16/20], Step [70/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [16/20], Step [80/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [16/20], Step [90/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [16/20], Step [100/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [16/20], Step [110/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [16/20], Step [120/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [16/20], Step [130/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [16/20], Step [140/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [16/20], Step [150/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [16/20], Step [160/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [17/20], Step [10/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [17/20], Step [20/163], Loss: nan, Accuracy: 18.75%\n",
            "Epoch [17/20], Step [30/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [17/20], Step [40/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [17/20], Step [50/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [17/20], Step [60/163], Loss: nan, Accuracy: 15.62%\n",
            "Epoch [17/20], Step [70/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [17/20], Step [80/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [17/20], Step [90/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [17/20], Step [100/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [17/20], Step [110/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [17/20], Step [120/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [17/20], Step [130/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [17/20], Step [140/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [17/20], Step [150/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [17/20], Step [160/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [18/20], Step [10/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [18/20], Step [20/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [18/20], Step [30/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [18/20], Step [40/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [18/20], Step [50/163], Loss: nan, Accuracy: 46.88%\n",
            "Epoch [18/20], Step [60/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [18/20], Step [70/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [18/20], Step [80/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [18/20], Step [90/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [18/20], Step [100/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [18/20], Step [110/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [18/20], Step [120/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [18/20], Step [130/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [18/20], Step [140/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [18/20], Step [150/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [18/20], Step [160/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [19/20], Step [10/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [19/20], Step [20/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [19/20], Step [30/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [19/20], Step [40/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [19/20], Step [50/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [19/20], Step [60/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [19/20], Step [70/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [19/20], Step [80/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [19/20], Step [90/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [19/20], Step [100/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [19/20], Step [110/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [19/20], Step [120/163], Loss: nan, Accuracy: 56.25%\n",
            "Epoch [19/20], Step [130/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [19/20], Step [140/163], Loss: nan, Accuracy: 15.62%\n",
            "Epoch [19/20], Step [150/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [19/20], Step [160/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [20/20], Step [10/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [20/20], Step [20/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [20/20], Step [30/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [20/20], Step [40/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [20/20], Step [50/163], Loss: nan, Accuracy: 46.88%\n",
            "Epoch [20/20], Step [60/163], Loss: nan, Accuracy: 21.88%\n",
            "Epoch [20/20], Step [70/163], Loss: nan, Accuracy: 40.62%\n",
            "Epoch [20/20], Step [80/163], Loss: nan, Accuracy: 37.50%\n",
            "Epoch [20/20], Step [90/163], Loss: nan, Accuracy: 18.75%\n",
            "Epoch [20/20], Step [100/163], Loss: nan, Accuracy: 31.25%\n",
            "Epoch [20/20], Step [110/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [20/20], Step [120/163], Loss: nan, Accuracy: 25.00%\n",
            "Epoch [20/20], Step [130/163], Loss: nan, Accuracy: 34.38%\n",
            "Epoch [20/20], Step [140/163], Loss: nan, Accuracy: 28.12%\n",
            "Epoch [20/20], Step [150/163], Loss: nan, Accuracy: 43.75%\n",
            "Epoch [20/20], Step [160/163], Loss: nan, Accuracy: 34.38%\n",
            "######## Training Finished in 2696.7633385658264 seconds ###########\n"
          ]
        }
      ],
      "source": [
        "###### Define and run your training loop here #########\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "net.to(device)\n",
        "\n",
        "num_epochs = 20\n",
        "total_steps = len(data_loader_train)\n",
        "t1 = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(data_loader_train):\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # Forward pass\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "#         print(\"kjnfjnrnkrn\",i)\\\\\n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "#         print(\"second time\",i)\n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            \n",
        "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ed2f139e",
      "metadata": {
        "id": "ed2f139e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530912f3-e0a7-41fd-b363-bab850c76395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 1731 test images: 33.10225303292894 %\n"
          ]
        }
      ],
      "source": [
        "######## Write your code here #############\n",
        "net.eval() \n",
        "count=0\n",
        "with torch.no_grad(): \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in data_loader_test:\n",
        "        # count+=1\n",
        "        # print(count)\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Test Accuracy of the model on the {} test images: {} %'\n",
        "        .format(total, (correct / total) * 100))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}