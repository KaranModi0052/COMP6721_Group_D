{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM4roBshk-OR",
        "outputId": "c7542acc-67dc-4ae2-cd1b-8669af52c68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as td\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import time"
      ],
      "metadata": {
        "id": "qmhN_C-9stH0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "def load_data(path,batch_size,input_size):\n",
        "    \n",
        "    normalize = transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ]) \n",
        "    transform_dict = {\"src\":  normalize} \n",
        "    data = datasets.ImageFolder(root=path,transform=transform_dict[\"src\"])\n",
        "    # transform_dict1 = {\"test\":  normalize\n",
        "    train_size=int(0.75*len(data))\n",
        "    print(len(data))\n",
        "    test_size=int(len(data)-train_size)\n",
        "    train, test = td.random_split(data,[train_size,test_size])\n",
        "\n",
        "    data_loader_train = td.DataLoader(train,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    data_loader_test = td.DataLoader(test,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    # data_loader_val = td.DataLoader(val,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=0)\n",
        "    return data_loader_train, data_loader_test"
      ],
      "metadata": {
        "id": "nUncT4fzdZNr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader_train,data_loader_test=load_data(r\"/content/gdrive/MyDrive/Colab Notebooks/Dataset2\",32,64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIIN6QPydZLH",
        "outputId": "bcfb5f27-1830-4492-9729-c257ef6a0e0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50\n",
        "net=resnet50(weights=None)\n",
        "resnet50(pretrained=False) \n",
        "# net = resNet50(22).to('cuda')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFpDWRWJBtan",
        "outputId": "d8a81a6d-cb0d-48b8-cc98-b1306ce721bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### Define and run your training loop here #########\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "net.to(device)\n",
        "\n",
        "num_epochs = 50\n",
        "total_steps = len(data_loader_train)\n",
        "t1 = time.time()\n",
        "Accuracies=[]\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(data_loader_train):\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # Forward pass\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # print(\"kjnfjnrnkrn\",i)\n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(\"second time\",i)\n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            Accuracies.append((correct / total) * 100)\n",
        "            \n",
        "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmK_9RNadrkg",
        "outputId": "f7087552-f426-40b4-cc39-7112e97be366"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Epoch [1/50], Step [10/162], Loss: 4.5969, Accuracy: 25.00%\n",
            "Epoch [1/50], Step [20/162], Loss: 1.7297, Accuracy: 40.62%\n",
            "Epoch [1/50], Step [30/162], Loss: 1.0737, Accuracy: 40.62%\n",
            "Epoch [1/50], Step [40/162], Loss: 1.0661, Accuracy: 43.75%\n",
            "Epoch [1/50], Step [50/162], Loss: 1.2407, Accuracy: 31.25%\n",
            "Epoch [1/50], Step [60/162], Loss: 1.1463, Accuracy: 40.62%\n",
            "Epoch [1/50], Step [70/162], Loss: 1.1575, Accuracy: 34.38%\n",
            "Epoch [1/50], Step [80/162], Loss: 0.9613, Accuracy: 65.62%\n",
            "Epoch [1/50], Step [90/162], Loss: 0.9853, Accuracy: 50.00%\n",
            "Epoch [1/50], Step [100/162], Loss: 1.0655, Accuracy: 46.88%\n",
            "Epoch [1/50], Step [110/162], Loss: 0.9200, Accuracy: 56.25%\n",
            "Epoch [1/50], Step [120/162], Loss: 1.1668, Accuracy: 31.25%\n",
            "Epoch [1/50], Step [130/162], Loss: 1.0907, Accuracy: 46.88%\n",
            "Epoch [1/50], Step [140/162], Loss: 1.0521, Accuracy: 50.00%\n",
            "Epoch [1/50], Step [150/162], Loss: 1.0851, Accuracy: 50.00%\n",
            "Epoch [1/50], Step [160/162], Loss: 1.0077, Accuracy: 68.75%\n",
            "Epoch [2/50], Step [10/162], Loss: 1.0754, Accuracy: 46.88%\n",
            "Epoch [2/50], Step [20/162], Loss: 0.9744, Accuracy: 62.50%\n",
            "Epoch [2/50], Step [30/162], Loss: 1.0476, Accuracy: 53.12%\n",
            "Epoch [2/50], Step [40/162], Loss: 1.0356, Accuracy: 53.12%\n",
            "Epoch [2/50], Step [50/162], Loss: 0.9127, Accuracy: 59.38%\n",
            "Epoch [2/50], Step [60/162], Loss: 0.9578, Accuracy: 59.38%\n",
            "Epoch [2/50], Step [70/162], Loss: 0.9578, Accuracy: 59.38%\n",
            "Epoch [2/50], Step [80/162], Loss: 0.8823, Accuracy: 71.88%\n",
            "Epoch [2/50], Step [90/162], Loss: 0.9715, Accuracy: 56.25%\n",
            "Epoch [2/50], Step [100/162], Loss: 0.9878, Accuracy: 59.38%\n",
            "Epoch [2/50], Step [110/162], Loss: 1.0155, Accuracy: 53.12%\n",
            "Epoch [2/50], Step [120/162], Loss: 0.9565, Accuracy: 59.38%\n",
            "Epoch [2/50], Step [130/162], Loss: 0.9703, Accuracy: 56.25%\n",
            "Epoch [2/50], Step [140/162], Loss: 1.0996, Accuracy: 53.12%\n",
            "Epoch [2/50], Step [150/162], Loss: 0.8914, Accuracy: 65.62%\n",
            "Epoch [2/50], Step [160/162], Loss: 0.9874, Accuracy: 56.25%\n",
            "Epoch [3/50], Step [10/162], Loss: 0.9643, Accuracy: 53.12%\n",
            "Epoch [3/50], Step [20/162], Loss: 0.9822, Accuracy: 50.00%\n",
            "Epoch [3/50], Step [30/162], Loss: 0.9784, Accuracy: 50.00%\n",
            "Epoch [3/50], Step [40/162], Loss: 0.8603, Accuracy: 68.75%\n",
            "Epoch [3/50], Step [50/162], Loss: 0.8438, Accuracy: 78.12%\n",
            "Epoch [3/50], Step [60/162], Loss: 0.9911, Accuracy: 56.25%\n",
            "Epoch [3/50], Step [70/162], Loss: 0.8583, Accuracy: 68.75%\n",
            "Epoch [3/50], Step [80/162], Loss: 0.9086, Accuracy: 65.62%\n",
            "Epoch [3/50], Step [90/162], Loss: 0.8475, Accuracy: 71.88%\n",
            "Epoch [3/50], Step [100/162], Loss: 1.0018, Accuracy: 46.88%\n",
            "Epoch [3/50], Step [110/162], Loss: 0.8832, Accuracy: 62.50%\n",
            "Epoch [3/50], Step [120/162], Loss: 0.9532, Accuracy: 65.62%\n",
            "Epoch [3/50], Step [130/162], Loss: 0.8748, Accuracy: 71.88%\n",
            "Epoch [3/50], Step [140/162], Loss: 0.8951, Accuracy: 62.50%\n",
            "Epoch [3/50], Step [150/162], Loss: 0.8253, Accuracy: 75.00%\n",
            "Epoch [3/50], Step [160/162], Loss: 0.8536, Accuracy: 65.62%\n",
            "Epoch [4/50], Step [10/162], Loss: 0.8859, Accuracy: 68.75%\n",
            "Epoch [4/50], Step [20/162], Loss: 0.8681, Accuracy: 71.88%\n",
            "Epoch [4/50], Step [30/162], Loss: 0.9217, Accuracy: 59.38%\n",
            "Epoch [4/50], Step [40/162], Loss: 0.9188, Accuracy: 62.50%\n",
            "Epoch [4/50], Step [50/162], Loss: 0.9461, Accuracy: 59.38%\n",
            "Epoch [4/50], Step [60/162], Loss: 0.9487, Accuracy: 62.50%\n",
            "Epoch [4/50], Step [70/162], Loss: 0.7784, Accuracy: 78.12%\n",
            "Epoch [4/50], Step [80/162], Loss: 0.9596, Accuracy: 59.38%\n",
            "Epoch [4/50], Step [90/162], Loss: 0.7529, Accuracy: 81.25%\n",
            "Epoch [4/50], Step [100/162], Loss: 0.6887, Accuracy: 84.38%\n",
            "Epoch [4/50], Step [110/162], Loss: 0.9137, Accuracy: 50.00%\n",
            "Epoch [4/50], Step [120/162], Loss: 1.1270, Accuracy: 40.62%\n",
            "Epoch [4/50], Step [130/162], Loss: 0.9424, Accuracy: 50.00%\n",
            "Epoch [4/50], Step [140/162], Loss: 0.8583, Accuracy: 71.88%\n",
            "Epoch [4/50], Step [150/162], Loss: 0.8656, Accuracy: 68.75%\n",
            "Epoch [4/50], Step [160/162], Loss: 0.8991, Accuracy: 62.50%\n",
            "Epoch [5/50], Step [10/162], Loss: 0.7463, Accuracy: 65.62%\n",
            "Epoch [5/50], Step [20/162], Loss: 0.8045, Accuracy: 68.75%\n",
            "Epoch [5/50], Step [30/162], Loss: 0.7163, Accuracy: 75.00%\n",
            "Epoch [5/50], Step [40/162], Loss: 0.7965, Accuracy: 78.12%\n",
            "Epoch [5/50], Step [50/162], Loss: 0.7713, Accuracy: 71.88%\n",
            "Epoch [5/50], Step [60/162], Loss: 0.6491, Accuracy: 84.38%\n",
            "Epoch [5/50], Step [70/162], Loss: 0.8009, Accuracy: 68.75%\n",
            "Epoch [5/50], Step [80/162], Loss: 0.8031, Accuracy: 62.50%\n",
            "Epoch [5/50], Step [90/162], Loss: 0.6638, Accuracy: 87.50%\n",
            "Epoch [5/50], Step [100/162], Loss: 0.9286, Accuracy: 65.62%\n",
            "Epoch [5/50], Step [110/162], Loss: 0.8164, Accuracy: 65.62%\n",
            "Epoch [5/50], Step [120/162], Loss: 0.8593, Accuracy: 78.12%\n",
            "Epoch [5/50], Step [130/162], Loss: 0.7479, Accuracy: 84.38%\n",
            "Epoch [5/50], Step [140/162], Loss: 0.6166, Accuracy: 87.50%\n",
            "Epoch [5/50], Step [150/162], Loss: 0.8315, Accuracy: 75.00%\n",
            "Epoch [5/50], Step [160/162], Loss: 0.6691, Accuracy: 78.12%\n",
            "Epoch [6/50], Step [10/162], Loss: 0.7000, Accuracy: 68.75%\n",
            "Epoch [6/50], Step [20/162], Loss: 0.7667, Accuracy: 78.12%\n",
            "Epoch [6/50], Step [30/162], Loss: 0.9117, Accuracy: 68.75%\n",
            "Epoch [6/50], Step [40/162], Loss: 0.7210, Accuracy: 71.88%\n",
            "Epoch [6/50], Step [50/162], Loss: 0.6913, Accuracy: 71.88%\n",
            "Epoch [6/50], Step [60/162], Loss: 0.7202, Accuracy: 75.00%\n",
            "Epoch [6/50], Step [70/162], Loss: 0.8720, Accuracy: 56.25%\n",
            "Epoch [6/50], Step [80/162], Loss: 0.5662, Accuracy: 84.38%\n",
            "Epoch [6/50], Step [90/162], Loss: 0.9349, Accuracy: 59.38%\n",
            "Epoch [6/50], Step [100/162], Loss: 0.6411, Accuracy: 87.50%\n",
            "Epoch [6/50], Step [110/162], Loss: 0.8720, Accuracy: 56.25%\n",
            "Epoch [6/50], Step [120/162], Loss: 0.7676, Accuracy: 71.88%\n",
            "Epoch [6/50], Step [130/162], Loss: 0.5444, Accuracy: 87.50%\n",
            "Epoch [6/50], Step [140/162], Loss: 0.6734, Accuracy: 78.12%\n",
            "Epoch [6/50], Step [150/162], Loss: 0.7529, Accuracy: 68.75%\n",
            "Epoch [6/50], Step [160/162], Loss: 0.7546, Accuracy: 71.88%\n",
            "Epoch [7/50], Step [10/162], Loss: 0.8057, Accuracy: 62.50%\n",
            "Epoch [7/50], Step [20/162], Loss: 0.5931, Accuracy: 90.62%\n",
            "Epoch [7/50], Step [30/162], Loss: 0.7879, Accuracy: 68.75%\n",
            "Epoch [7/50], Step [40/162], Loss: 0.6209, Accuracy: 75.00%\n",
            "Epoch [7/50], Step [50/162], Loss: 0.5653, Accuracy: 81.25%\n",
            "Epoch [7/50], Step [60/162], Loss: 0.7019, Accuracy: 68.75%\n",
            "Epoch [7/50], Step [70/162], Loss: 0.6485, Accuracy: 71.88%\n",
            "Epoch [7/50], Step [80/162], Loss: 0.6027, Accuracy: 84.38%\n",
            "Epoch [7/50], Step [90/162], Loss: 1.0085, Accuracy: 50.00%\n",
            "Epoch [7/50], Step [100/162], Loss: 0.6669, Accuracy: 75.00%\n",
            "Epoch [7/50], Step [110/162], Loss: 0.6931, Accuracy: 65.62%\n",
            "Epoch [7/50], Step [120/162], Loss: 0.6239, Accuracy: 84.38%\n",
            "Epoch [7/50], Step [130/162], Loss: 0.6148, Accuracy: 81.25%\n",
            "Epoch [7/50], Step [140/162], Loss: 0.7690, Accuracy: 75.00%\n",
            "Epoch [7/50], Step [150/162], Loss: 0.6285, Accuracy: 81.25%\n",
            "Epoch [7/50], Step [160/162], Loss: 0.6060, Accuracy: 78.12%\n",
            "Epoch [8/50], Step [10/162], Loss: 0.6849, Accuracy: 75.00%\n",
            "Epoch [8/50], Step [20/162], Loss: 0.6361, Accuracy: 75.00%\n",
            "Epoch [8/50], Step [30/162], Loss: 0.7984, Accuracy: 75.00%\n",
            "Epoch [8/50], Step [40/162], Loss: 0.5833, Accuracy: 78.12%\n",
            "Epoch [8/50], Step [50/162], Loss: 0.6368, Accuracy: 84.38%\n",
            "Epoch [8/50], Step [60/162], Loss: 0.6924, Accuracy: 71.88%\n",
            "Epoch [8/50], Step [70/162], Loss: 0.8066, Accuracy: 68.75%\n",
            "Epoch [8/50], Step [80/162], Loss: 0.5467, Accuracy: 81.25%\n",
            "Epoch [8/50], Step [90/162], Loss: 0.7294, Accuracy: 75.00%\n",
            "Epoch [8/50], Step [100/162], Loss: 0.7268, Accuracy: 71.88%\n",
            "Epoch [8/50], Step [110/162], Loss: 0.7729, Accuracy: 65.62%\n",
            "Epoch [8/50], Step [120/162], Loss: 0.7275, Accuracy: 81.25%\n",
            "Epoch [8/50], Step [130/162], Loss: 0.6586, Accuracy: 71.88%\n",
            "Epoch [8/50], Step [140/162], Loss: 0.6337, Accuracy: 78.12%\n",
            "Epoch [8/50], Step [150/162], Loss: 0.6523, Accuracy: 78.12%\n",
            "Epoch [8/50], Step [160/162], Loss: 0.7799, Accuracy: 65.62%\n",
            "Epoch [9/50], Step [10/162], Loss: 0.4905, Accuracy: 81.25%\n",
            "Epoch [9/50], Step [20/162], Loss: 0.5419, Accuracy: 78.12%\n",
            "Epoch [9/50], Step [30/162], Loss: 0.7095, Accuracy: 78.12%\n",
            "Epoch [9/50], Step [40/162], Loss: 0.6861, Accuracy: 75.00%\n",
            "Epoch [9/50], Step [50/162], Loss: 0.7567, Accuracy: 75.00%\n",
            "Epoch [9/50], Step [60/162], Loss: 0.9948, Accuracy: 65.62%\n",
            "Epoch [9/50], Step [70/162], Loss: 0.4345, Accuracy: 93.75%\n",
            "Epoch [9/50], Step [80/162], Loss: 0.5983, Accuracy: 78.12%\n",
            "Epoch [9/50], Step [90/162], Loss: 0.6501, Accuracy: 81.25%\n",
            "Epoch [9/50], Step [100/162], Loss: 0.6152, Accuracy: 78.12%\n",
            "Epoch [9/50], Step [110/162], Loss: 0.5315, Accuracy: 78.12%\n",
            "Epoch [9/50], Step [120/162], Loss: 0.7181, Accuracy: 68.75%\n",
            "Epoch [9/50], Step [130/162], Loss: 0.4284, Accuracy: 87.50%\n",
            "Epoch [9/50], Step [140/162], Loss: 0.4258, Accuracy: 90.62%\n",
            "Epoch [9/50], Step [150/162], Loss: 0.7652, Accuracy: 75.00%\n",
            "Epoch [9/50], Step [160/162], Loss: 0.5650, Accuracy: 78.12%\n",
            "Epoch [10/50], Step [10/162], Loss: 0.6416, Accuracy: 65.62%\n",
            "Epoch [10/50], Step [20/162], Loss: 0.6562, Accuracy: 78.12%\n",
            "Epoch [10/50], Step [30/162], Loss: 0.5875, Accuracy: 78.12%\n",
            "Epoch [10/50], Step [40/162], Loss: 0.7155, Accuracy: 75.00%\n",
            "Epoch [10/50], Step [50/162], Loss: 0.6530, Accuracy: 75.00%\n",
            "Epoch [10/50], Step [60/162], Loss: 0.4699, Accuracy: 87.50%\n",
            "Epoch [10/50], Step [70/162], Loss: 0.7052, Accuracy: 75.00%\n",
            "Epoch [10/50], Step [80/162], Loss: 0.7088, Accuracy: 68.75%\n",
            "Epoch [10/50], Step [90/162], Loss: 0.6106, Accuracy: 75.00%\n",
            "Epoch [10/50], Step [100/162], Loss: 0.5474, Accuracy: 71.88%\n",
            "Epoch [10/50], Step [110/162], Loss: 0.5667, Accuracy: 81.25%\n",
            "Epoch [10/50], Step [120/162], Loss: 0.5092, Accuracy: 81.25%\n",
            "Epoch [10/50], Step [130/162], Loss: 0.5910, Accuracy: 87.50%\n",
            "Epoch [10/50], Step [140/162], Loss: 0.3277, Accuracy: 90.62%\n",
            "Epoch [10/50], Step [150/162], Loss: 0.6657, Accuracy: 75.00%\n",
            "Epoch [10/50], Step [160/162], Loss: 0.7552, Accuracy: 65.62%\n",
            "Epoch [11/50], Step [10/162], Loss: 0.7725, Accuracy: 78.12%\n",
            "Epoch [11/50], Step [20/162], Loss: 0.5381, Accuracy: 78.12%\n",
            "Epoch [11/50], Step [30/162], Loss: 0.5869, Accuracy: 84.38%\n",
            "Epoch [11/50], Step [40/162], Loss: 0.8332, Accuracy: 65.62%\n",
            "Epoch [11/50], Step [50/162], Loss: 0.5246, Accuracy: 84.38%\n",
            "Epoch [11/50], Step [60/162], Loss: 0.5175, Accuracy: 81.25%\n",
            "Epoch [11/50], Step [70/162], Loss: 0.6385, Accuracy: 75.00%\n",
            "Epoch [11/50], Step [80/162], Loss: 0.5754, Accuracy: 81.25%\n",
            "Epoch [11/50], Step [90/162], Loss: 0.5765, Accuracy: 78.12%\n",
            "Epoch [11/50], Step [100/162], Loss: 0.5156, Accuracy: 87.50%\n",
            "Epoch [11/50], Step [110/162], Loss: 0.5842, Accuracy: 75.00%\n",
            "Epoch [11/50], Step [120/162], Loss: 0.5314, Accuracy: 87.50%\n",
            "Epoch [11/50], Step [130/162], Loss: 0.6630, Accuracy: 78.12%\n",
            "Epoch [11/50], Step [140/162], Loss: 0.3221, Accuracy: 90.62%\n",
            "Epoch [11/50], Step [150/162], Loss: 0.5842, Accuracy: 87.50%\n",
            "Epoch [11/50], Step [160/162], Loss: 0.5588, Accuracy: 84.38%\n",
            "Epoch [12/50], Step [10/162], Loss: 0.6201, Accuracy: 78.12%\n",
            "Epoch [12/50], Step [20/162], Loss: 0.5825, Accuracy: 78.12%\n",
            "Epoch [12/50], Step [30/162], Loss: 0.5200, Accuracy: 93.75%\n",
            "Epoch [12/50], Step [40/162], Loss: 0.6433, Accuracy: 81.25%\n",
            "Epoch [12/50], Step [50/162], Loss: 0.4697, Accuracy: 84.38%\n",
            "Epoch [12/50], Step [60/162], Loss: 0.4922, Accuracy: 84.38%\n",
            "Epoch [12/50], Step [70/162], Loss: 0.5361, Accuracy: 84.38%\n",
            "Epoch [12/50], Step [80/162], Loss: 0.5324, Accuracy: 78.12%\n",
            "Epoch [12/50], Step [90/162], Loss: 0.6047, Accuracy: 75.00%\n",
            "Epoch [12/50], Step [100/162], Loss: 0.3605, Accuracy: 90.62%\n",
            "Epoch [12/50], Step [110/162], Loss: 0.4991, Accuracy: 84.38%\n",
            "Epoch [12/50], Step [120/162], Loss: 0.5164, Accuracy: 81.25%\n",
            "Epoch [12/50], Step [130/162], Loss: 0.5353, Accuracy: 84.38%\n",
            "Epoch [12/50], Step [140/162], Loss: 0.4095, Accuracy: 90.62%\n",
            "Epoch [12/50], Step [150/162], Loss: 0.5811, Accuracy: 75.00%\n",
            "Epoch [12/50], Step [160/162], Loss: 0.5801, Accuracy: 81.25%\n",
            "Epoch [13/50], Step [10/162], Loss: 0.6438, Accuracy: 71.88%\n",
            "Epoch [13/50], Step [20/162], Loss: 0.3120, Accuracy: 87.50%\n",
            "Epoch [13/50], Step [30/162], Loss: 0.7231, Accuracy: 65.62%\n",
            "Epoch [13/50], Step [40/162], Loss: 0.5796, Accuracy: 81.25%\n",
            "Epoch [13/50], Step [50/162], Loss: 0.4657, Accuracy: 84.38%\n",
            "Epoch [13/50], Step [60/162], Loss: 0.5554, Accuracy: 75.00%\n",
            "Epoch [13/50], Step [70/162], Loss: 0.6126, Accuracy: 81.25%\n",
            "Epoch [13/50], Step [80/162], Loss: 0.5029, Accuracy: 84.38%\n",
            "Epoch [13/50], Step [90/162], Loss: 0.5256, Accuracy: 81.25%\n",
            "Epoch [13/50], Step [100/162], Loss: 0.5632, Accuracy: 81.25%\n",
            "Epoch [13/50], Step [110/162], Loss: 0.4804, Accuracy: 87.50%\n",
            "Epoch [13/50], Step [120/162], Loss: 0.4830, Accuracy: 90.62%\n",
            "Epoch [13/50], Step [130/162], Loss: 0.5792, Accuracy: 84.38%\n",
            "Epoch [13/50], Step [140/162], Loss: 0.4968, Accuracy: 84.38%\n",
            "Epoch [13/50], Step [150/162], Loss: 0.6091, Accuracy: 81.25%\n",
            "Epoch [13/50], Step [160/162], Loss: 0.4981, Accuracy: 87.50%\n",
            "Epoch [14/50], Step [10/162], Loss: 0.3403, Accuracy: 93.75%\n",
            "Epoch [14/50], Step [20/162], Loss: 0.2891, Accuracy: 96.88%\n",
            "Epoch [14/50], Step [30/162], Loss: 0.4796, Accuracy: 87.50%\n",
            "Epoch [14/50], Step [40/162], Loss: 0.4665, Accuracy: 90.62%\n",
            "Epoch [14/50], Step [50/162], Loss: 0.5461, Accuracy: 75.00%\n",
            "Epoch [14/50], Step [60/162], Loss: 0.5495, Accuracy: 81.25%\n",
            "Epoch [14/50], Step [70/162], Loss: 0.2395, Accuracy: 93.75%\n",
            "Epoch [14/50], Step [80/162], Loss: 0.6143, Accuracy: 75.00%\n",
            "Epoch [14/50], Step [90/162], Loss: 0.4992, Accuracy: 81.25%\n",
            "Epoch [14/50], Step [100/162], Loss: 0.4508, Accuracy: 84.38%\n",
            "Epoch [14/50], Step [110/162], Loss: 0.4629, Accuracy: 81.25%\n",
            "Epoch [14/50], Step [120/162], Loss: 0.2637, Accuracy: 93.75%\n",
            "Epoch [14/50], Step [130/162], Loss: 0.5915, Accuracy: 81.25%\n",
            "Epoch [14/50], Step [140/162], Loss: 0.5785, Accuracy: 81.25%\n",
            "Epoch [14/50], Step [150/162], Loss: 0.3682, Accuracy: 93.75%\n",
            "Epoch [14/50], Step [160/162], Loss: 0.5826, Accuracy: 81.25%\n",
            "Epoch [15/50], Step [10/162], Loss: 0.6296, Accuracy: 84.38%\n",
            "Epoch [15/50], Step [20/162], Loss: 0.4511, Accuracy: 87.50%\n",
            "Epoch [15/50], Step [30/162], Loss: 0.5047, Accuracy: 84.38%\n",
            "Epoch [15/50], Step [40/162], Loss: 0.3262, Accuracy: 93.75%\n",
            "Epoch [15/50], Step [50/162], Loss: 0.4518, Accuracy: 81.25%\n",
            "Epoch [15/50], Step [60/162], Loss: 0.4465, Accuracy: 87.50%\n",
            "Epoch [15/50], Step [70/162], Loss: 0.4985, Accuracy: 84.38%\n",
            "Epoch [15/50], Step [80/162], Loss: 0.3559, Accuracy: 96.88%\n",
            "Epoch [15/50], Step [90/162], Loss: 0.5548, Accuracy: 78.12%\n",
            "Epoch [15/50], Step [100/162], Loss: 0.4462, Accuracy: 84.38%\n",
            "Epoch [15/50], Step [110/162], Loss: 0.7490, Accuracy: 78.12%\n",
            "Epoch [15/50], Step [120/162], Loss: 0.5087, Accuracy: 90.62%\n",
            "Epoch [15/50], Step [130/162], Loss: 0.5051, Accuracy: 87.50%\n",
            "Epoch [15/50], Step [140/162], Loss: 0.3560, Accuracy: 93.75%\n",
            "Epoch [15/50], Step [150/162], Loss: 0.6988, Accuracy: 71.88%\n",
            "Epoch [15/50], Step [160/162], Loss: 0.4278, Accuracy: 81.25%\n",
            "Epoch [16/50], Step [10/162], Loss: 0.4930, Accuracy: 81.25%\n",
            "Epoch [16/50], Step [20/162], Loss: 0.3276, Accuracy: 96.88%\n",
            "Epoch [16/50], Step [30/162], Loss: 0.5630, Accuracy: 78.12%\n",
            "Epoch [16/50], Step [40/162], Loss: 0.2367, Accuracy: 93.75%\n",
            "Epoch [16/50], Step [50/162], Loss: 0.3715, Accuracy: 87.50%\n",
            "Epoch [16/50], Step [60/162], Loss: 0.5186, Accuracy: 81.25%\n",
            "Epoch [16/50], Step [70/162], Loss: 0.3570, Accuracy: 87.50%\n",
            "Epoch [16/50], Step [80/162], Loss: 0.4303, Accuracy: 87.50%\n",
            "Epoch [16/50], Step [90/162], Loss: 0.4083, Accuracy: 90.62%\n",
            "Epoch [16/50], Step [100/162], Loss: 0.3470, Accuracy: 96.88%\n",
            "Epoch [16/50], Step [110/162], Loss: 0.4105, Accuracy: 87.50%\n",
            "Epoch [16/50], Step [120/162], Loss: 0.3055, Accuracy: 96.88%\n",
            "Epoch [16/50], Step [130/162], Loss: 0.2773, Accuracy: 93.75%\n",
            "Epoch [16/50], Step [140/162], Loss: 0.3316, Accuracy: 93.75%\n",
            "Epoch [16/50], Step [150/162], Loss: 0.3209, Accuracy: 93.75%\n",
            "Epoch [16/50], Step [160/162], Loss: 0.3257, Accuracy: 90.62%\n",
            "Epoch [17/50], Step [10/162], Loss: 0.2749, Accuracy: 100.00%\n",
            "Epoch [17/50], Step [20/162], Loss: 0.3313, Accuracy: 87.50%\n",
            "Epoch [17/50], Step [30/162], Loss: 0.3441, Accuracy: 93.75%\n",
            "Epoch [17/50], Step [40/162], Loss: 0.1563, Accuracy: 100.00%\n",
            "Epoch [17/50], Step [50/162], Loss: 0.6016, Accuracy: 81.25%\n",
            "Epoch [17/50], Step [60/162], Loss: 0.2475, Accuracy: 93.75%\n",
            "Epoch [17/50], Step [70/162], Loss: 0.2924, Accuracy: 93.75%\n",
            "Epoch [17/50], Step [80/162], Loss: 0.3000, Accuracy: 87.50%\n",
            "Epoch [17/50], Step [90/162], Loss: 0.3423, Accuracy: 90.62%\n",
            "Epoch [17/50], Step [100/162], Loss: 0.3142, Accuracy: 96.88%\n",
            "Epoch [17/50], Step [110/162], Loss: 0.2984, Accuracy: 90.62%\n",
            "Epoch [17/50], Step [120/162], Loss: 0.3770, Accuracy: 90.62%\n",
            "Epoch [17/50], Step [130/162], Loss: 0.3450, Accuracy: 90.62%\n",
            "Epoch [17/50], Step [140/162], Loss: 0.3326, Accuracy: 93.75%\n",
            "Epoch [17/50], Step [150/162], Loss: 0.2792, Accuracy: 96.88%\n",
            "Epoch [17/50], Step [160/162], Loss: 0.2981, Accuracy: 90.62%\n",
            "Epoch [18/50], Step [10/162], Loss: 0.2410, Accuracy: 96.88%\n",
            "Epoch [18/50], Step [20/162], Loss: 0.3543, Accuracy: 90.62%\n",
            "Epoch [18/50], Step [30/162], Loss: 0.3554, Accuracy: 96.88%\n",
            "Epoch [18/50], Step [40/162], Loss: 0.4501, Accuracy: 87.50%\n",
            "Epoch [18/50], Step [50/162], Loss: 0.2031, Accuracy: 96.88%\n",
            "Epoch [18/50], Step [60/162], Loss: 0.3780, Accuracy: 90.62%\n",
            "Epoch [18/50], Step [70/162], Loss: 0.5005, Accuracy: 84.38%\n",
            "Epoch [18/50], Step [80/162], Loss: 0.2183, Accuracy: 96.88%\n",
            "Epoch [18/50], Step [90/162], Loss: 0.2235, Accuracy: 93.75%\n",
            "Epoch [18/50], Step [100/162], Loss: 0.2346, Accuracy: 96.88%\n",
            "Epoch [18/50], Step [110/162], Loss: 0.4522, Accuracy: 87.50%\n",
            "Epoch [18/50], Step [120/162], Loss: 0.2031, Accuracy: 96.88%\n",
            "Epoch [18/50], Step [130/162], Loss: 0.6201, Accuracy: 84.38%\n",
            "Epoch [18/50], Step [140/162], Loss: 0.3098, Accuracy: 96.88%\n",
            "Epoch [18/50], Step [150/162], Loss: 0.4410, Accuracy: 87.50%\n",
            "Epoch [18/50], Step [160/162], Loss: 0.2815, Accuracy: 93.75%\n",
            "Epoch [19/50], Step [10/162], Loss: 0.2134, Accuracy: 96.88%\n",
            "Epoch [19/50], Step [20/162], Loss: 0.1439, Accuracy: 100.00%\n",
            "Epoch [19/50], Step [30/162], Loss: 0.3536, Accuracy: 90.62%\n",
            "Epoch [19/50], Step [40/162], Loss: 0.5382, Accuracy: 84.38%\n",
            "Epoch [19/50], Step [50/162], Loss: 0.4080, Accuracy: 90.62%\n",
            "Epoch [19/50], Step [60/162], Loss: 0.3950, Accuracy: 90.62%\n",
            "Epoch [19/50], Step [70/162], Loss: 0.4721, Accuracy: 87.50%\n",
            "Epoch [19/50], Step [80/162], Loss: 0.6790, Accuracy: 84.38%\n",
            "Epoch [19/50], Step [90/162], Loss: 0.3879, Accuracy: 87.50%\n",
            "Epoch [19/50], Step [100/162], Loss: 0.2031, Accuracy: 93.75%\n",
            "Epoch [19/50], Step [110/162], Loss: 0.3936, Accuracy: 93.75%\n",
            "Epoch [19/50], Step [120/162], Loss: 0.3526, Accuracy: 87.50%\n",
            "Epoch [19/50], Step [130/162], Loss: 0.2462, Accuracy: 96.88%\n",
            "Epoch [19/50], Step [140/162], Loss: 0.2950, Accuracy: 96.88%\n",
            "Epoch [19/50], Step [150/162], Loss: 0.2033, Accuracy: 96.88%\n",
            "Epoch [19/50], Step [160/162], Loss: 0.4252, Accuracy: 84.38%\n",
            "Epoch [20/50], Step [10/162], Loss: 0.1781, Accuracy: 96.88%\n",
            "Epoch [20/50], Step [20/162], Loss: 0.2908, Accuracy: 90.62%\n",
            "Epoch [20/50], Step [30/162], Loss: 0.3287, Accuracy: 93.75%\n",
            "Epoch [20/50], Step [40/162], Loss: 0.2469, Accuracy: 93.75%\n",
            "Epoch [20/50], Step [50/162], Loss: 0.3643, Accuracy: 93.75%\n",
            "Epoch [20/50], Step [60/162], Loss: 0.2684, Accuracy: 93.75%\n",
            "Epoch [20/50], Step [70/162], Loss: 0.4905, Accuracy: 93.75%\n",
            "Epoch [20/50], Step [80/162], Loss: 0.2604, Accuracy: 96.88%\n",
            "Epoch [20/50], Step [90/162], Loss: 0.3402, Accuracy: 90.62%\n",
            "Epoch [20/50], Step [100/162], Loss: 0.3407, Accuracy: 90.62%\n",
            "Epoch [20/50], Step [110/162], Loss: 0.2196, Accuracy: 96.88%\n",
            "Epoch [20/50], Step [120/162], Loss: 0.5079, Accuracy: 90.62%\n",
            "Epoch [20/50], Step [130/162], Loss: 0.5727, Accuracy: 87.50%\n",
            "Epoch [20/50], Step [140/162], Loss: 0.1862, Accuracy: 100.00%\n",
            "Epoch [20/50], Step [150/162], Loss: 0.4020, Accuracy: 90.62%\n",
            "Epoch [20/50], Step [160/162], Loss: 0.4615, Accuracy: 84.38%\n",
            "Epoch [21/50], Step [10/162], Loss: 0.2652, Accuracy: 90.62%\n",
            "Epoch [21/50], Step [20/162], Loss: 0.4422, Accuracy: 90.62%\n",
            "Epoch [21/50], Step [30/162], Loss: 0.4682, Accuracy: 90.62%\n",
            "Epoch [21/50], Step [40/162], Loss: 0.3075, Accuracy: 93.75%\n",
            "Epoch [21/50], Step [50/162], Loss: 0.1561, Accuracy: 100.00%\n",
            "Epoch [21/50], Step [60/162], Loss: 0.2951, Accuracy: 93.75%\n",
            "Epoch [21/50], Step [70/162], Loss: 0.2383, Accuracy: 93.75%\n",
            "Epoch [21/50], Step [80/162], Loss: 0.2116, Accuracy: 96.88%\n",
            "Epoch [21/50], Step [90/162], Loss: 0.4153, Accuracy: 87.50%\n",
            "Epoch [21/50], Step [100/162], Loss: 0.4759, Accuracy: 87.50%\n",
            "Epoch [21/50], Step [110/162], Loss: 0.4378, Accuracy: 90.62%\n",
            "Epoch [21/50], Step [120/162], Loss: 0.2962, Accuracy: 93.75%\n",
            "Epoch [21/50], Step [130/162], Loss: 0.1653, Accuracy: 100.00%\n",
            "Epoch [21/50], Step [140/162], Loss: 0.5208, Accuracy: 90.62%\n",
            "Epoch [21/50], Step [150/162], Loss: 0.3032, Accuracy: 93.75%\n",
            "Epoch [21/50], Step [160/162], Loss: 0.3187, Accuracy: 93.75%\n",
            "Epoch [22/50], Step [10/162], Loss: 0.3368, Accuracy: 93.75%\n",
            "Epoch [22/50], Step [20/162], Loss: 0.3021, Accuracy: 93.75%\n",
            "Epoch [22/50], Step [30/162], Loss: 0.2777, Accuracy: 96.88%\n",
            "Epoch [22/50], Step [40/162], Loss: 0.3495, Accuracy: 90.62%\n",
            "Epoch [22/50], Step [50/162], Loss: 0.2149, Accuracy: 93.75%\n",
            "Epoch [22/50], Step [60/162], Loss: 0.3993, Accuracy: 93.75%\n",
            "Epoch [22/50], Step [70/162], Loss: 0.3050, Accuracy: 96.88%\n",
            "Epoch [22/50], Step [80/162], Loss: 0.3230, Accuracy: 96.88%\n",
            "Epoch [22/50], Step [90/162], Loss: 0.4153, Accuracy: 87.50%\n",
            "Epoch [22/50], Step [100/162], Loss: 0.2672, Accuracy: 96.88%\n",
            "Epoch [22/50], Step [110/162], Loss: 0.2003, Accuracy: 96.88%\n",
            "Epoch [22/50], Step [120/162], Loss: 0.2037, Accuracy: 96.88%\n",
            "Epoch [22/50], Step [130/162], Loss: 0.2047, Accuracy: 96.88%\n",
            "Epoch [22/50], Step [140/162], Loss: 0.5640, Accuracy: 81.25%\n",
            "Epoch [22/50], Step [150/162], Loss: 0.4409, Accuracy: 90.62%\n",
            "Epoch [22/50], Step [160/162], Loss: 0.3180, Accuracy: 93.75%\n",
            "Epoch [23/50], Step [10/162], Loss: 0.6610, Accuracy: 84.38%\n",
            "Epoch [23/50], Step [20/162], Loss: 0.3795, Accuracy: 90.62%\n",
            "Epoch [23/50], Step [30/162], Loss: 0.3383, Accuracy: 93.75%\n",
            "Epoch [23/50], Step [40/162], Loss: 0.3385, Accuracy: 93.75%\n",
            "Epoch [23/50], Step [50/162], Loss: 0.1581, Accuracy: 100.00%\n",
            "Epoch [23/50], Step [60/162], Loss: 0.3058, Accuracy: 96.88%\n",
            "Epoch [23/50], Step [70/162], Loss: 0.1563, Accuracy: 100.00%\n",
            "Epoch [23/50], Step [80/162], Loss: 0.3961, Accuracy: 96.88%\n",
            "Epoch [23/50], Step [90/162], Loss: 0.3631, Accuracy: 93.75%\n",
            "Epoch [23/50], Step [100/162], Loss: 0.3964, Accuracy: 90.62%\n",
            "Epoch [23/50], Step [110/162], Loss: 0.2898, Accuracy: 93.75%\n",
            "Epoch [23/50], Step [120/162], Loss: 0.2215, Accuracy: 96.88%\n",
            "Epoch [23/50], Step [130/162], Loss: 0.1927, Accuracy: 100.00%\n",
            "Epoch [23/50], Step [140/162], Loss: 0.5394, Accuracy: 87.50%\n",
            "Epoch [23/50], Step [150/162], Loss: 0.3007, Accuracy: 96.88%\n",
            "Epoch [23/50], Step [160/162], Loss: 0.4300, Accuracy: 93.75%\n",
            "Epoch [24/50], Step [10/162], Loss: 0.3375, Accuracy: 90.62%\n",
            "Epoch [24/50], Step [20/162], Loss: 0.4198, Accuracy: 90.62%\n",
            "Epoch [24/50], Step [30/162], Loss: 0.2531, Accuracy: 96.88%\n",
            "Epoch [24/50], Step [40/162], Loss: 0.3050, Accuracy: 93.75%\n",
            "Epoch [24/50], Step [50/162], Loss: 0.2534, Accuracy: 96.88%\n",
            "Epoch [24/50], Step [60/162], Loss: 0.3811, Accuracy: 90.62%\n",
            "Epoch [24/50], Step [70/162], Loss: 0.1688, Accuracy: 100.00%\n",
            "Epoch [24/50], Step [80/162], Loss: 0.4670, Accuracy: 87.50%\n",
            "Epoch [24/50], Step [90/162], Loss: 0.2395, Accuracy: 96.88%\n",
            "Epoch [24/50], Step [100/162], Loss: 0.3326, Accuracy: 93.75%\n",
            "Epoch [24/50], Step [110/162], Loss: 0.6325, Accuracy: 87.50%\n",
            "Epoch [24/50], Step [120/162], Loss: 0.2428, Accuracy: 96.88%\n",
            "Epoch [24/50], Step [130/162], Loss: 0.3897, Accuracy: 90.62%\n",
            "Epoch [24/50], Step [140/162], Loss: 0.2028, Accuracy: 96.88%\n",
            "Epoch [24/50], Step [150/162], Loss: 0.2304, Accuracy: 93.75%\n",
            "Epoch [24/50], Step [160/162], Loss: 0.4660, Accuracy: 93.75%\n",
            "Epoch [25/50], Step [10/162], Loss: 0.2941, Accuracy: 93.75%\n",
            "Epoch [25/50], Step [20/162], Loss: 0.3530, Accuracy: 93.75%\n",
            "Epoch [25/50], Step [30/162], Loss: 0.2487, Accuracy: 96.88%\n",
            "Epoch [25/50], Step [40/162], Loss: 0.3561, Accuracy: 96.88%\n",
            "Epoch [25/50], Step [50/162], Loss: 0.3349, Accuracy: 96.88%\n",
            "Epoch [25/50], Step [60/162], Loss: 0.3207, Accuracy: 90.62%\n",
            "Epoch [25/50], Step [70/162], Loss: 0.5532, Accuracy: 90.62%\n",
            "Epoch [25/50], Step [80/162], Loss: 0.3597, Accuracy: 93.75%\n",
            "Epoch [25/50], Step [90/162], Loss: 0.3877, Accuracy: 90.62%\n",
            "Epoch [25/50], Step [100/162], Loss: 0.2981, Accuracy: 93.75%\n",
            "Epoch [25/50], Step [110/162], Loss: 0.7154, Accuracy: 84.38%\n",
            "Epoch [25/50], Step [120/162], Loss: 0.2402, Accuracy: 96.88%\n",
            "Epoch [25/50], Step [130/162], Loss: 0.2817, Accuracy: 96.88%\n",
            "Epoch [25/50], Step [140/162], Loss: 0.3871, Accuracy: 96.88%\n",
            "Epoch [25/50], Step [150/162], Loss: 0.4036, Accuracy: 90.62%\n",
            "Epoch [25/50], Step [160/162], Loss: 0.3491, Accuracy: 93.75%\n",
            "Epoch [26/50], Step [10/162], Loss: 0.4738, Accuracy: 87.50%\n",
            "Epoch [26/50], Step [20/162], Loss: 0.1405, Accuracy: 100.00%\n",
            "Epoch [26/50], Step [30/162], Loss: 0.4915, Accuracy: 90.62%\n",
            "Epoch [26/50], Step [40/162], Loss: 0.2717, Accuracy: 100.00%\n",
            "Epoch [26/50], Step [50/162], Loss: 0.4064, Accuracy: 93.75%\n",
            "Epoch [26/50], Step [60/162], Loss: 0.5289, Accuracy: 90.62%\n",
            "Epoch [26/50], Step [70/162], Loss: 0.3248, Accuracy: 96.88%\n",
            "Epoch [26/50], Step [80/162], Loss: 0.3711, Accuracy: 93.75%\n",
            "Epoch [26/50], Step [90/162], Loss: 0.3521, Accuracy: 93.75%\n",
            "Epoch [26/50], Step [100/162], Loss: 0.2932, Accuracy: 96.88%\n",
            "Epoch [26/50], Step [110/162], Loss: 0.1450, Accuracy: 100.00%\n",
            "Epoch [26/50], Step [120/162], Loss: 0.5768, Accuracy: 84.38%\n",
            "Epoch [26/50], Step [130/162], Loss: 0.3949, Accuracy: 90.62%\n",
            "Epoch [26/50], Step [140/162], Loss: 0.6105, Accuracy: 87.50%\n",
            "Epoch [26/50], Step [150/162], Loss: 0.2980, Accuracy: 93.75%\n",
            "Epoch [26/50], Step [160/162], Loss: 0.7227, Accuracy: 87.50%\n",
            "Epoch [27/50], Step [10/162], Loss: 0.4490, Accuracy: 93.75%\n",
            "Epoch [27/50], Step [20/162], Loss: 0.2764, Accuracy: 96.88%\n",
            "Epoch [27/50], Step [30/162], Loss: 0.4833, Accuracy: 93.75%\n",
            "Epoch [27/50], Step [40/162], Loss: 0.2517, Accuracy: 96.88%\n",
            "Epoch [27/50], Step [50/162], Loss: 0.2923, Accuracy: 96.88%\n",
            "Epoch [27/50], Step [60/162], Loss: 0.3416, Accuracy: 96.88%\n",
            "Epoch [27/50], Step [70/162], Loss: 0.3237, Accuracy: 96.88%\n",
            "Epoch [27/50], Step [80/162], Loss: 0.4804, Accuracy: 90.62%\n",
            "Epoch [27/50], Step [90/162], Loss: 0.3418, Accuracy: 96.88%\n",
            "Epoch [27/50], Step [100/162], Loss: 0.3210, Accuracy: 96.88%\n",
            "Epoch [27/50], Step [110/162], Loss: 0.2772, Accuracy: 96.88%\n",
            "Epoch [27/50], Step [120/162], Loss: 0.3471, Accuracy: 93.75%\n",
            "Epoch [27/50], Step [130/162], Loss: 0.5079, Accuracy: 90.62%\n",
            "Epoch [27/50], Step [140/162], Loss: 0.2458, Accuracy: 100.00%\n",
            "Epoch [27/50], Step [150/162], Loss: 0.3200, Accuracy: 93.75%\n",
            "Epoch [27/50], Step [160/162], Loss: 0.3631, Accuracy: 90.62%\n",
            "Epoch [28/50], Step [10/162], Loss: 0.2641, Accuracy: 100.00%\n",
            "Epoch [28/50], Step [20/162], Loss: 0.4571, Accuracy: 93.75%\n",
            "Epoch [28/50], Step [30/162], Loss: 0.1885, Accuracy: 100.00%\n",
            "Epoch [28/50], Step [40/162], Loss: 0.5590, Accuracy: 87.50%\n",
            "Epoch [28/50], Step [50/162], Loss: 0.8131, Accuracy: 93.75%\n",
            "Epoch [28/50], Step [60/162], Loss: 0.3594, Accuracy: 93.75%\n",
            "Epoch [28/50], Step [70/162], Loss: 0.4420, Accuracy: 90.62%\n",
            "Epoch [28/50], Step [80/162], Loss: 0.5472, Accuracy: 90.62%\n",
            "Epoch [28/50], Step [90/162], Loss: 0.8608, Accuracy: 84.38%\n",
            "Epoch [28/50], Step [100/162], Loss: 0.5244, Accuracy: 90.62%\n",
            "Epoch [28/50], Step [110/162], Loss: 0.3632, Accuracy: 96.88%\n",
            "Epoch [28/50], Step [120/162], Loss: 0.4231, Accuracy: 90.62%\n",
            "Epoch [28/50], Step [130/162], Loss: 0.3945, Accuracy: 93.75%\n",
            "Epoch [28/50], Step [140/162], Loss: 0.4284, Accuracy: 90.62%\n",
            "Epoch [28/50], Step [150/162], Loss: 0.6204, Accuracy: 87.50%\n",
            "Epoch [28/50], Step [160/162], Loss: 0.2061, Accuracy: 100.00%\n",
            "Epoch [29/50], Step [10/162], Loss: 0.4580, Accuracy: 90.62%\n",
            "Epoch [29/50], Step [20/162], Loss: 0.4643, Accuracy: 93.75%\n",
            "Epoch [29/50], Step [30/162], Loss: 0.5912, Accuracy: 90.62%\n",
            "Epoch [29/50], Step [40/162], Loss: 0.7654, Accuracy: 87.50%\n",
            "Epoch [29/50], Step [50/162], Loss: 0.1992, Accuracy: 100.00%\n",
            "Epoch [29/50], Step [60/162], Loss: 0.5983, Accuracy: 87.50%\n",
            "Epoch [29/50], Step [70/162], Loss: 0.5110, Accuracy: 90.62%\n",
            "Epoch [29/50], Step [80/162], Loss: 0.4001, Accuracy: 96.88%\n",
            "Epoch [29/50], Step [90/162], Loss: 0.8253, Accuracy: 84.38%\n",
            "Epoch [29/50], Step [100/162], Loss: 0.3557, Accuracy: 93.75%\n",
            "Epoch [29/50], Step [110/162], Loss: 0.3758, Accuracy: 96.88%\n",
            "Epoch [29/50], Step [120/162], Loss: 0.5500, Accuracy: 90.62%\n",
            "Epoch [29/50], Step [130/162], Loss: 0.7534, Accuracy: 90.62%\n",
            "Epoch [29/50], Step [140/162], Loss: 0.3725, Accuracy: 93.75%\n",
            "Epoch [29/50], Step [150/162], Loss: 0.6499, Accuracy: 93.75%\n",
            "Epoch [29/50], Step [160/162], Loss: 0.7387, Accuracy: 87.50%\n",
            "Epoch [30/50], Step [10/162], Loss: 0.2457, Accuracy: 100.00%\n",
            "Epoch [30/50], Step [20/162], Loss: 0.7169, Accuracy: 84.38%\n",
            "Epoch [30/50], Step [30/162], Loss: 0.4057, Accuracy: 93.75%\n",
            "Epoch [30/50], Step [40/162], Loss: 0.5585, Accuracy: 84.38%\n",
            "Epoch [30/50], Step [50/162], Loss: 0.4875, Accuracy: 96.88%\n",
            "Epoch [30/50], Step [60/162], Loss: 0.4770, Accuracy: 96.88%\n",
            "Epoch [30/50], Step [70/162], Loss: 0.3379, Accuracy: 96.88%\n",
            "Epoch [30/50], Step [80/162], Loss: 0.5640, Accuracy: 90.62%\n",
            "Epoch [30/50], Step [90/162], Loss: 0.8255, Accuracy: 84.38%\n",
            "Epoch [30/50], Step [100/162], Loss: 0.7251, Accuracy: 87.50%\n",
            "Epoch [30/50], Step [110/162], Loss: 0.9709, Accuracy: 87.50%\n",
            "Epoch [30/50], Step [120/162], Loss: 0.3402, Accuracy: 96.88%\n",
            "Epoch [30/50], Step [130/162], Loss: 0.6416, Accuracy: 90.62%\n",
            "Epoch [30/50], Step [140/162], Loss: 0.7009, Accuracy: 84.38%\n",
            "Epoch [30/50], Step [150/162], Loss: 0.9857, Accuracy: 84.38%\n",
            "Epoch [30/50], Step [160/162], Loss: 0.3532, Accuracy: 96.88%\n",
            "Epoch [31/50], Step [10/162], Loss: 0.5115, Accuracy: 93.75%\n",
            "Epoch [31/50], Step [20/162], Loss: 0.3334, Accuracy: 100.00%\n",
            "Epoch [31/50], Step [30/162], Loss: 0.6597, Accuracy: 93.75%\n",
            "Epoch [31/50], Step [40/162], Loss: 0.5712, Accuracy: 90.62%\n",
            "Epoch [31/50], Step [50/162], Loss: 0.5903, Accuracy: 90.62%\n",
            "Epoch [31/50], Step [60/162], Loss: 0.2993, Accuracy: 96.88%\n",
            "Epoch [31/50], Step [70/162], Loss: 0.7960, Accuracy: 96.88%\n",
            "Epoch [31/50], Step [80/162], Loss: 0.3354, Accuracy: 100.00%\n",
            "Epoch [31/50], Step [90/162], Loss: 0.5522, Accuracy: 90.62%\n",
            "Epoch [31/50], Step [100/162], Loss: 0.4604, Accuracy: 93.75%\n",
            "Epoch [31/50], Step [110/162], Loss: 0.7672, Accuracy: 90.62%\n",
            "Epoch [31/50], Step [120/162], Loss: 0.2633, Accuracy: 100.00%\n",
            "Epoch [31/50], Step [130/162], Loss: 0.5527, Accuracy: 93.75%\n",
            "Epoch [31/50], Step [140/162], Loss: 0.4069, Accuracy: 96.88%\n",
            "Epoch [31/50], Step [150/162], Loss: 0.5248, Accuracy: 93.75%\n",
            "Epoch [31/50], Step [160/162], Loss: 0.4614, Accuracy: 96.88%\n",
            "Epoch [32/50], Step [10/162], Loss: 0.6662, Accuracy: 90.62%\n",
            "Epoch [32/50], Step [20/162], Loss: 1.0512, Accuracy: 90.62%\n",
            "Epoch [32/50], Step [30/162], Loss: 0.7536, Accuracy: 84.38%\n",
            "Epoch [32/50], Step [40/162], Loss: 0.6538, Accuracy: 90.62%\n",
            "Epoch [32/50], Step [50/162], Loss: 0.5357, Accuracy: 96.88%\n",
            "Epoch [32/50], Step [60/162], Loss: 0.4581, Accuracy: 93.75%\n",
            "Epoch [32/50], Step [70/162], Loss: 0.3109, Accuracy: 100.00%\n",
            "Epoch [32/50], Step [80/162], Loss: 0.5386, Accuracy: 96.88%\n",
            "Epoch [32/50], Step [90/162], Loss: 0.2971, Accuracy: 100.00%\n",
            "Epoch [32/50], Step [100/162], Loss: 0.8854, Accuracy: 90.62%\n",
            "Epoch [32/50], Step [110/162], Loss: 0.4003, Accuracy: 96.88%\n",
            "Epoch [32/50], Step [120/162], Loss: 0.7698, Accuracy: 87.50%\n",
            "Epoch [32/50], Step [130/162], Loss: 0.9667, Accuracy: 84.38%\n",
            "Epoch [32/50], Step [140/162], Loss: 0.7580, Accuracy: 87.50%\n",
            "Epoch [32/50], Step [150/162], Loss: 0.6587, Accuracy: 90.62%\n",
            "Epoch [32/50], Step [160/162], Loss: 1.0995, Accuracy: 84.38%\n",
            "Epoch [33/50], Step [10/162], Loss: 0.3640, Accuracy: 100.00%\n",
            "Epoch [33/50], Step [20/162], Loss: 0.6886, Accuracy: 93.75%\n",
            "Epoch [33/50], Step [30/162], Loss: 0.7784, Accuracy: 87.50%\n",
            "Epoch [33/50], Step [40/162], Loss: 1.2379, Accuracy: 84.38%\n",
            "Epoch [33/50], Step [50/162], Loss: 0.4623, Accuracy: 93.75%\n",
            "Epoch [33/50], Step [60/162], Loss: 0.4960, Accuracy: 96.88%\n",
            "Epoch [33/50], Step [70/162], Loss: 0.7411, Accuracy: 90.62%\n",
            "Epoch [33/50], Step [80/162], Loss: 0.3471, Accuracy: 100.00%\n",
            "Epoch [33/50], Step [90/162], Loss: 0.9406, Accuracy: 84.38%\n",
            "Epoch [33/50], Step [100/162], Loss: 0.6153, Accuracy: 90.62%\n",
            "Epoch [33/50], Step [110/162], Loss: 0.8555, Accuracy: 96.88%\n",
            "Epoch [33/50], Step [120/162], Loss: 0.6988, Accuracy: 90.62%\n",
            "Epoch [33/50], Step [130/162], Loss: 0.5514, Accuracy: 96.88%\n",
            "Epoch [33/50], Step [140/162], Loss: 0.6615, Accuracy: 93.75%\n",
            "Epoch [33/50], Step [150/162], Loss: 0.9159, Accuracy: 87.50%\n",
            "Epoch [33/50], Step [160/162], Loss: 0.4796, Accuracy: 96.88%\n",
            "Epoch [34/50], Step [10/162], Loss: 0.8684, Accuracy: 90.62%\n",
            "Epoch [34/50], Step [20/162], Loss: 0.5691, Accuracy: 93.75%\n",
            "Epoch [34/50], Step [30/162], Loss: 0.6768, Accuracy: 90.62%\n",
            "Epoch [34/50], Step [40/162], Loss: 0.5582, Accuracy: 96.88%\n",
            "Epoch [34/50], Step [50/162], Loss: 0.4714, Accuracy: 96.88%\n",
            "Epoch [34/50], Step [60/162], Loss: 0.4327, Accuracy: 100.00%\n",
            "Epoch [34/50], Step [70/162], Loss: 0.6610, Accuracy: 93.75%\n",
            "Epoch [34/50], Step [80/162], Loss: 0.9994, Accuracy: 87.50%\n",
            "Epoch [34/50], Step [90/162], Loss: 0.8064, Accuracy: 87.50%\n",
            "Epoch [34/50], Step [100/162], Loss: 0.3878, Accuracy: 100.00%\n",
            "Epoch [34/50], Step [110/162], Loss: 0.6458, Accuracy: 90.62%\n",
            "Epoch [34/50], Step [120/162], Loss: 0.7577, Accuracy: 93.75%\n",
            "Epoch [34/50], Step [130/162], Loss: 0.7198, Accuracy: 87.50%\n",
            "Epoch [34/50], Step [140/162], Loss: 0.8742, Accuracy: 87.50%\n",
            "Epoch [34/50], Step [150/162], Loss: 0.6672, Accuracy: 96.88%\n",
            "Epoch [34/50], Step [160/162], Loss: 0.7635, Accuracy: 93.75%\n",
            "Epoch [35/50], Step [10/162], Loss: 0.6162, Accuracy: 96.88%\n",
            "Epoch [35/50], Step [20/162], Loss: 0.9010, Accuracy: 87.50%\n",
            "Epoch [35/50], Step [30/162], Loss: 0.5921, Accuracy: 93.75%\n",
            "Epoch [35/50], Step [40/162], Loss: 0.5033, Accuracy: 96.88%\n",
            "Epoch [35/50], Step [50/162], Loss: 0.6069, Accuracy: 96.88%\n",
            "Epoch [35/50], Step [60/162], Loss: 0.7457, Accuracy: 93.75%\n",
            "Epoch [35/50], Step [70/162], Loss: 0.7881, Accuracy: 96.88%\n",
            "Epoch [35/50], Step [80/162], Loss: 0.8793, Accuracy: 87.50%\n",
            "Epoch [35/50], Step [90/162], Loss: 1.0798, Accuracy: 87.50%\n",
            "Epoch [35/50], Step [100/162], Loss: 0.8496, Accuracy: 87.50%\n",
            "Epoch [35/50], Step [110/162], Loss: 0.9330, Accuracy: 90.62%\n",
            "Epoch [35/50], Step [120/162], Loss: 0.6601, Accuracy: 93.75%\n",
            "Epoch [35/50], Step [130/162], Loss: 0.7322, Accuracy: 93.75%\n",
            "Epoch [35/50], Step [140/162], Loss: 1.0316, Accuracy: 90.62%\n",
            "Epoch [35/50], Step [150/162], Loss: 0.6195, Accuracy: 96.88%\n",
            "Epoch [35/50], Step [160/162], Loss: 0.7575, Accuracy: 93.75%\n",
            "Epoch [36/50], Step [10/162], Loss: 1.2135, Accuracy: 90.62%\n",
            "Epoch [36/50], Step [20/162], Loss: 1.0015, Accuracy: 87.50%\n",
            "Epoch [36/50], Step [30/162], Loss: 1.2541, Accuracy: 90.62%\n",
            "Epoch [36/50], Step [40/162], Loss: 0.6523, Accuracy: 96.88%\n",
            "Epoch [36/50], Step [50/162], Loss: 0.4635, Accuracy: 100.00%\n",
            "Epoch [36/50], Step [60/162], Loss: 0.9042, Accuracy: 90.62%\n",
            "Epoch [36/50], Step [70/162], Loss: 0.6119, Accuracy: 96.88%\n",
            "Epoch [36/50], Step [80/162], Loss: 0.8647, Accuracy: 90.62%\n",
            "Epoch [36/50], Step [90/162], Loss: 0.6085, Accuracy: 93.75%\n",
            "Epoch [36/50], Step [100/162], Loss: 1.1630, Accuracy: 81.25%\n",
            "Epoch [36/50], Step [110/162], Loss: 0.9773, Accuracy: 87.50%\n",
            "Epoch [36/50], Step [120/162], Loss: 0.8906, Accuracy: 90.62%\n",
            "Epoch [36/50], Step [130/162], Loss: 1.4350, Accuracy: 81.25%\n",
            "Epoch [36/50], Step [140/162], Loss: 0.6432, Accuracy: 96.88%\n",
            "Epoch [36/50], Step [150/162], Loss: 0.5018, Accuracy: 100.00%\n",
            "Epoch [36/50], Step [160/162], Loss: 1.5295, Accuracy: 81.25%\n",
            "Epoch [37/50], Step [10/162], Loss: 0.9203, Accuracy: 90.62%\n",
            "Epoch [37/50], Step [20/162], Loss: 1.3568, Accuracy: 87.50%\n",
            "Epoch [37/50], Step [30/162], Loss: 1.0213, Accuracy: 90.62%\n",
            "Epoch [37/50], Step [40/162], Loss: 0.7235, Accuracy: 93.75%\n",
            "Epoch [37/50], Step [50/162], Loss: 1.1884, Accuracy: 84.38%\n",
            "Epoch [37/50], Step [60/162], Loss: 0.6630, Accuracy: 96.88%\n",
            "Epoch [37/50], Step [70/162], Loss: 0.5797, Accuracy: 96.88%\n",
            "Epoch [37/50], Step [80/162], Loss: 0.8312, Accuracy: 93.75%\n",
            "Epoch [37/50], Step [90/162], Loss: 0.8684, Accuracy: 96.88%\n",
            "Epoch [37/50], Step [100/162], Loss: 0.8577, Accuracy: 90.62%\n",
            "Epoch [37/50], Step [110/162], Loss: 0.8024, Accuracy: 93.75%\n",
            "Epoch [37/50], Step [120/162], Loss: 0.7295, Accuracy: 93.75%\n",
            "Epoch [37/50], Step [130/162], Loss: 1.0743, Accuracy: 93.75%\n",
            "Epoch [37/50], Step [140/162], Loss: 1.5075, Accuracy: 90.62%\n",
            "Epoch [37/50], Step [150/162], Loss: 1.4955, Accuracy: 84.38%\n",
            "Epoch [37/50], Step [160/162], Loss: 1.0721, Accuracy: 87.50%\n",
            "Epoch [38/50], Step [10/162], Loss: 0.9043, Accuracy: 90.62%\n",
            "Epoch [38/50], Step [20/162], Loss: 0.9480, Accuracy: 93.75%\n",
            "Epoch [38/50], Step [30/162], Loss: 0.6007, Accuracy: 96.88%\n",
            "Epoch [38/50], Step [40/162], Loss: 1.7406, Accuracy: 75.00%\n",
            "Epoch [38/50], Step [50/162], Loss: 1.0498, Accuracy: 87.50%\n",
            "Epoch [38/50], Step [60/162], Loss: 1.0717, Accuracy: 87.50%\n",
            "Epoch [38/50], Step [70/162], Loss: 1.3601, Accuracy: 87.50%\n",
            "Epoch [38/50], Step [80/162], Loss: 0.9680, Accuracy: 87.50%\n",
            "Epoch [38/50], Step [90/162], Loss: 0.6222, Accuracy: 96.88%\n",
            "Epoch [38/50], Step [100/162], Loss: 0.9570, Accuracy: 90.62%\n",
            "Epoch [38/50], Step [110/162], Loss: 1.6808, Accuracy: 81.25%\n",
            "Epoch [38/50], Step [120/162], Loss: 0.4808, Accuracy: 100.00%\n",
            "Epoch [38/50], Step [130/162], Loss: 0.8130, Accuracy: 96.88%\n",
            "Epoch [38/50], Step [140/162], Loss: 0.9428, Accuracy: 93.75%\n",
            "Epoch [38/50], Step [150/162], Loss: 0.6909, Accuracy: 93.75%\n",
            "Epoch [38/50], Step [160/162], Loss: 1.0792, Accuracy: 90.62%\n",
            "Epoch [39/50], Step [10/162], Loss: 1.2016, Accuracy: 84.38%\n",
            "Epoch [39/50], Step [20/162], Loss: 1.0847, Accuracy: 90.62%\n",
            "Epoch [39/50], Step [30/162], Loss: 1.0209, Accuracy: 90.62%\n",
            "Epoch [39/50], Step [40/162], Loss: 0.9914, Accuracy: 90.62%\n",
            "Epoch [39/50], Step [50/162], Loss: 1.1551, Accuracy: 90.62%\n",
            "Epoch [39/50], Step [60/162], Loss: 1.2360, Accuracy: 84.38%\n",
            "Epoch [39/50], Step [70/162], Loss: 0.8982, Accuracy: 93.75%\n",
            "Epoch [39/50], Step [80/162], Loss: 1.0264, Accuracy: 90.62%\n",
            "Epoch [39/50], Step [90/162], Loss: 0.7791, Accuracy: 96.88%\n",
            "Epoch [39/50], Step [100/162], Loss: 1.0525, Accuracy: 87.50%\n",
            "Epoch [39/50], Step [110/162], Loss: 0.5791, Accuracy: 100.00%\n",
            "Epoch [39/50], Step [120/162], Loss: 0.8395, Accuracy: 93.75%\n",
            "Epoch [39/50], Step [130/162], Loss: 0.8733, Accuracy: 96.88%\n",
            "Epoch [39/50], Step [140/162], Loss: 0.8412, Accuracy: 93.75%\n",
            "Epoch [39/50], Step [150/162], Loss: 1.4848, Accuracy: 84.38%\n",
            "Epoch [39/50], Step [160/162], Loss: 1.0316, Accuracy: 90.62%\n",
            "Epoch [40/50], Step [10/162], Loss: 1.5223, Accuracy: 84.38%\n",
            "Epoch [40/50], Step [20/162], Loss: 1.0435, Accuracy: 93.75%\n",
            "Epoch [40/50], Step [30/162], Loss: 1.4795, Accuracy: 81.25%\n",
            "Epoch [40/50], Step [40/162], Loss: 1.3563, Accuracy: 84.38%\n",
            "Epoch [40/50], Step [50/162], Loss: 1.0653, Accuracy: 90.62%\n",
            "Epoch [40/50], Step [60/162], Loss: 0.5958, Accuracy: 100.00%\n",
            "Epoch [40/50], Step [70/162], Loss: 0.9625, Accuracy: 90.62%\n",
            "Epoch [40/50], Step [80/162], Loss: 0.9457, Accuracy: 93.75%\n",
            "Epoch [40/50], Step [90/162], Loss: 0.8087, Accuracy: 96.88%\n",
            "Epoch [40/50], Step [100/162], Loss: 0.6036, Accuracy: 100.00%\n",
            "Epoch [40/50], Step [110/162], Loss: 0.8022, Accuracy: 93.75%\n",
            "Epoch [40/50], Step [120/162], Loss: 0.6833, Accuracy: 96.88%\n",
            "Epoch [40/50], Step [130/162], Loss: 1.1278, Accuracy: 87.50%\n",
            "Epoch [40/50], Step [140/162], Loss: 0.8774, Accuracy: 93.75%\n",
            "Epoch [40/50], Step [150/162], Loss: 1.5397, Accuracy: 84.38%\n",
            "Epoch [40/50], Step [160/162], Loss: 0.8460, Accuracy: 93.75%\n",
            "Epoch [41/50], Step [10/162], Loss: 0.8397, Accuracy: 96.88%\n",
            "Epoch [41/50], Step [20/162], Loss: 0.5962, Accuracy: 100.00%\n",
            "Epoch [41/50], Step [30/162], Loss: 0.7745, Accuracy: 96.88%\n",
            "Epoch [41/50], Step [40/162], Loss: 1.2879, Accuracy: 87.50%\n",
            "Epoch [41/50], Step [50/162], Loss: 1.3585, Accuracy: 87.50%\n",
            "Epoch [41/50], Step [60/162], Loss: 1.2832, Accuracy: 87.50%\n",
            "Epoch [41/50], Step [70/162], Loss: 1.0068, Accuracy: 93.75%\n",
            "Epoch [41/50], Step [80/162], Loss: 1.0741, Accuracy: 90.62%\n",
            "Epoch [41/50], Step [90/162], Loss: 1.8505, Accuracy: 87.50%\n",
            "Epoch [41/50], Step [100/162], Loss: 1.1891, Accuracy: 93.75%\n",
            "Epoch [41/50], Step [110/162], Loss: 1.0009, Accuracy: 93.75%\n",
            "Epoch [41/50], Step [120/162], Loss: 0.5890, Accuracy: 100.00%\n",
            "Epoch [41/50], Step [130/162], Loss: 0.9412, Accuracy: 96.88%\n",
            "Epoch [41/50], Step [140/162], Loss: 1.0379, Accuracy: 93.75%\n",
            "Epoch [41/50], Step [150/162], Loss: 0.6943, Accuracy: 100.00%\n",
            "Epoch [41/50], Step [160/162], Loss: 0.8550, Accuracy: 96.88%\n",
            "Epoch [42/50], Step [10/162], Loss: 1.0179, Accuracy: 93.75%\n",
            "Epoch [42/50], Step [20/162], Loss: 1.1144, Accuracy: 90.62%\n",
            "Epoch [42/50], Step [30/162], Loss: 0.8977, Accuracy: 96.88%\n",
            "Epoch [42/50], Step [40/162], Loss: 1.3138, Accuracy: 93.75%\n",
            "Epoch [42/50], Step [50/162], Loss: 1.3370, Accuracy: 84.38%\n",
            "Epoch [42/50], Step [60/162], Loss: 1.3829, Accuracy: 81.25%\n",
            "Epoch [42/50], Step [70/162], Loss: 1.2861, Accuracy: 84.38%\n",
            "Epoch [42/50], Step [80/162], Loss: 0.7520, Accuracy: 96.88%\n",
            "Epoch [42/50], Step [90/162], Loss: 1.1390, Accuracy: 96.88%\n",
            "Epoch [42/50], Step [100/162], Loss: 1.6935, Accuracy: 81.25%\n",
            "Epoch [42/50], Step [110/162], Loss: 0.8605, Accuracy: 96.88%\n",
            "Epoch [42/50], Step [120/162], Loss: 0.9751, Accuracy: 93.75%\n",
            "Epoch [42/50], Step [130/162], Loss: 1.3216, Accuracy: 87.50%\n",
            "Epoch [42/50], Step [140/162], Loss: 1.0001, Accuracy: 90.62%\n",
            "Epoch [42/50], Step [150/162], Loss: 1.4373, Accuracy: 84.38%\n",
            "Epoch [42/50], Step [160/162], Loss: 0.8827, Accuracy: 96.88%\n",
            "Epoch [43/50], Step [10/162], Loss: 1.2764, Accuracy: 90.62%\n",
            "Epoch [43/50], Step [20/162], Loss: 1.1807, Accuracy: 90.62%\n",
            "Epoch [43/50], Step [30/162], Loss: 0.9363, Accuracy: 96.88%\n",
            "Epoch [43/50], Step [40/162], Loss: 1.3705, Accuracy: 90.62%\n",
            "Epoch [43/50], Step [50/162], Loss: 1.2491, Accuracy: 90.62%\n",
            "Epoch [43/50], Step [60/162], Loss: 0.9175, Accuracy: 100.00%\n",
            "Epoch [43/50], Step [70/162], Loss: 1.1655, Accuracy: 93.75%\n",
            "Epoch [43/50], Step [80/162], Loss: 1.8269, Accuracy: 78.12%\n",
            "Epoch [43/50], Step [90/162], Loss: 0.7952, Accuracy: 100.00%\n",
            "Epoch [43/50], Step [100/162], Loss: 1.2483, Accuracy: 90.62%\n",
            "Epoch [43/50], Step [110/162], Loss: 1.0702, Accuracy: 93.75%\n",
            "Epoch [43/50], Step [120/162], Loss: 0.8890, Accuracy: 96.88%\n",
            "Epoch [43/50], Step [130/162], Loss: 0.7942, Accuracy: 100.00%\n",
            "Epoch [43/50], Step [140/162], Loss: 1.2335, Accuracy: 90.62%\n",
            "Epoch [43/50], Step [150/162], Loss: 1.1576, Accuracy: 93.75%\n",
            "Epoch [43/50], Step [160/162], Loss: 1.4109, Accuracy: 90.62%\n",
            "Epoch [44/50], Step [10/162], Loss: 0.8425, Accuracy: 96.88%\n",
            "Epoch [44/50], Step [20/162], Loss: 1.1991, Accuracy: 90.62%\n",
            "Epoch [44/50], Step [30/162], Loss: 1.0319, Accuracy: 93.75%\n",
            "Epoch [44/50], Step [40/162], Loss: 1.3083, Accuracy: 90.62%\n",
            "Epoch [44/50], Step [50/162], Loss: 0.8887, Accuracy: 93.75%\n",
            "Epoch [44/50], Step [60/162], Loss: 0.9791, Accuracy: 93.75%\n",
            "Epoch [44/50], Step [70/162], Loss: 1.1439, Accuracy: 93.75%\n",
            "Epoch [44/50], Step [80/162], Loss: 1.6751, Accuracy: 81.25%\n",
            "Epoch [44/50], Step [90/162], Loss: 0.9632, Accuracy: 96.88%\n",
            "Epoch [44/50], Step [100/162], Loss: 1.0650, Accuracy: 90.62%\n",
            "Epoch [44/50], Step [110/162], Loss: 0.9655, Accuracy: 93.75%\n",
            "Epoch [44/50], Step [120/162], Loss: 0.8895, Accuracy: 100.00%\n",
            "Epoch [44/50], Step [130/162], Loss: 1.2196, Accuracy: 90.62%\n",
            "Epoch [44/50], Step [140/162], Loss: 1.0112, Accuracy: 93.75%\n",
            "Epoch [44/50], Step [150/162], Loss: 1.2624, Accuracy: 87.50%\n",
            "Epoch [44/50], Step [160/162], Loss: 1.4611, Accuracy: 87.50%\n",
            "Epoch [45/50], Step [10/162], Loss: 0.9118, Accuracy: 96.88%\n",
            "Epoch [45/50], Step [20/162], Loss: 0.9782, Accuracy: 96.88%\n",
            "Epoch [45/50], Step [30/162], Loss: 0.7697, Accuracy: 100.00%\n",
            "Epoch [45/50], Step [40/162], Loss: 1.4821, Accuracy: 90.62%\n",
            "Epoch [45/50], Step [50/162], Loss: 1.1452, Accuracy: 90.62%\n",
            "Epoch [45/50], Step [60/162], Loss: 1.0394, Accuracy: 93.75%\n",
            "Epoch [45/50], Step [70/162], Loss: 1.1786, Accuracy: 93.75%\n",
            "Epoch [45/50], Step [80/162], Loss: 1.0124, Accuracy: 93.75%\n",
            "Epoch [45/50], Step [90/162], Loss: 1.1683, Accuracy: 93.75%\n",
            "Epoch [45/50], Step [100/162], Loss: 1.1479, Accuracy: 90.62%\n",
            "Epoch [45/50], Step [110/162], Loss: 1.3067, Accuracy: 87.50%\n",
            "Epoch [45/50], Step [120/162], Loss: 1.6961, Accuracy: 81.25%\n",
            "Epoch [45/50], Step [130/162], Loss: 1.3608, Accuracy: 87.50%\n",
            "Epoch [45/50], Step [140/162], Loss: 1.2159, Accuracy: 93.75%\n",
            "Epoch [45/50], Step [150/162], Loss: 1.6068, Accuracy: 90.62%\n",
            "Epoch [45/50], Step [160/162], Loss: 0.8832, Accuracy: 96.88%\n",
            "Epoch [46/50], Step [10/162], Loss: 1.5116, Accuracy: 84.38%\n",
            "Epoch [46/50], Step [20/162], Loss: 0.9569, Accuracy: 96.88%\n",
            "Epoch [46/50], Step [30/162], Loss: 1.1002, Accuracy: 93.75%\n",
            "Epoch [46/50], Step [40/162], Loss: 1.2042, Accuracy: 87.50%\n",
            "Epoch [46/50], Step [50/162], Loss: 1.2897, Accuracy: 87.50%\n",
            "Epoch [46/50], Step [60/162], Loss: 1.3524, Accuracy: 90.62%\n",
            "Epoch [46/50], Step [70/162], Loss: 1.8255, Accuracy: 81.25%\n",
            "Epoch [46/50], Step [80/162], Loss: 1.0837, Accuracy: 96.88%\n",
            "Epoch [46/50], Step [90/162], Loss: 0.9076, Accuracy: 96.88%\n",
            "Epoch [46/50], Step [100/162], Loss: 0.8363, Accuracy: 100.00%\n",
            "Epoch [46/50], Step [110/162], Loss: 1.5272, Accuracy: 87.50%\n",
            "Epoch [46/50], Step [120/162], Loss: 1.0118, Accuracy: 93.75%\n",
            "Epoch [46/50], Step [130/162], Loss: 1.3048, Accuracy: 87.50%\n",
            "Epoch [46/50], Step [140/162], Loss: 1.2329, Accuracy: 87.50%\n",
            "Epoch [46/50], Step [150/162], Loss: 1.2004, Accuracy: 90.62%\n",
            "Epoch [46/50], Step [160/162], Loss: 1.7910, Accuracy: 81.25%\n",
            "Epoch [47/50], Step [10/162], Loss: 1.2992, Accuracy: 87.50%\n",
            "Epoch [47/50], Step [20/162], Loss: 1.2868, Accuracy: 90.62%\n",
            "Epoch [47/50], Step [30/162], Loss: 1.1032, Accuracy: 96.88%\n",
            "Epoch [47/50], Step [40/162], Loss: 1.1126, Accuracy: 93.75%\n",
            "Epoch [47/50], Step [50/162], Loss: 1.3910, Accuracy: 87.50%\n",
            "Epoch [47/50], Step [60/162], Loss: 1.1098, Accuracy: 93.75%\n",
            "Epoch [47/50], Step [70/162], Loss: 1.5970, Accuracy: 84.38%\n",
            "Epoch [47/50], Step [80/162], Loss: 1.2846, Accuracy: 90.62%\n",
            "Epoch [47/50], Step [90/162], Loss: 1.0771, Accuracy: 90.62%\n",
            "Epoch [47/50], Step [100/162], Loss: 1.1971, Accuracy: 93.75%\n",
            "Epoch [47/50], Step [110/162], Loss: 1.2805, Accuracy: 90.62%\n",
            "Epoch [47/50], Step [120/162], Loss: 1.4712, Accuracy: 90.62%\n",
            "Epoch [47/50], Step [130/162], Loss: 0.9747, Accuracy: 100.00%\n",
            "Epoch [47/50], Step [140/162], Loss: 1.0695, Accuracy: 93.75%\n",
            "Epoch [47/50], Step [150/162], Loss: 1.6640, Accuracy: 81.25%\n",
            "Epoch [47/50], Step [160/162], Loss: 1.0881, Accuracy: 96.88%\n",
            "Epoch [48/50], Step [10/162], Loss: 1.1332, Accuracy: 90.62%\n",
            "Epoch [48/50], Step [20/162], Loss: 1.3395, Accuracy: 87.50%\n",
            "Epoch [48/50], Step [30/162], Loss: 1.1188, Accuracy: 96.88%\n",
            "Epoch [48/50], Step [40/162], Loss: 1.5034, Accuracy: 81.25%\n",
            "Epoch [48/50], Step [50/162], Loss: 1.0702, Accuracy: 93.75%\n",
            "Epoch [48/50], Step [60/162], Loss: 1.5037, Accuracy: 84.38%\n",
            "Epoch [48/50], Step [70/162], Loss: 1.2610, Accuracy: 93.75%\n",
            "Epoch [48/50], Step [80/162], Loss: 1.4323, Accuracy: 87.50%\n",
            "Epoch [48/50], Step [90/162], Loss: 1.2985, Accuracy: 96.88%\n",
            "Epoch [48/50], Step [100/162], Loss: 1.4718, Accuracy: 84.38%\n",
            "Epoch [48/50], Step [110/162], Loss: 1.5947, Accuracy: 84.38%\n",
            "Epoch [48/50], Step [120/162], Loss: 0.9625, Accuracy: 96.88%\n",
            "Epoch [48/50], Step [130/162], Loss: 1.7513, Accuracy: 75.00%\n",
            "Epoch [48/50], Step [140/162], Loss: 1.3229, Accuracy: 90.62%\n",
            "Epoch [48/50], Step [150/162], Loss: 1.3800, Accuracy: 90.62%\n",
            "Epoch [48/50], Step [160/162], Loss: 1.0032, Accuracy: 93.75%\n",
            "Epoch [49/50], Step [10/162], Loss: 1.0456, Accuracy: 96.88%\n",
            "Epoch [49/50], Step [20/162], Loss: 1.1489, Accuracy: 93.75%\n",
            "Epoch [49/50], Step [30/162], Loss: 1.4284, Accuracy: 84.38%\n",
            "Epoch [49/50], Step [40/162], Loss: 1.6184, Accuracy: 81.25%\n",
            "Epoch [49/50], Step [50/162], Loss: 1.5078, Accuracy: 93.75%\n",
            "Epoch [49/50], Step [60/162], Loss: 1.1722, Accuracy: 93.75%\n",
            "Epoch [49/50], Step [70/162], Loss: 1.2473, Accuracy: 87.50%\n",
            "Epoch [49/50], Step [80/162], Loss: 1.5613, Accuracy: 87.50%\n",
            "Epoch [49/50], Step [90/162], Loss: 1.2170, Accuracy: 90.62%\n",
            "Epoch [49/50], Step [100/162], Loss: 1.1450, Accuracy: 93.75%\n",
            "Epoch [49/50], Step [110/162], Loss: 1.9516, Accuracy: 75.00%\n",
            "Epoch [49/50], Step [120/162], Loss: 1.1978, Accuracy: 90.62%\n",
            "Epoch [49/50], Step [130/162], Loss: 1.0139, Accuracy: 96.88%\n",
            "Epoch [49/50], Step [140/162], Loss: 1.4358, Accuracy: 90.62%\n",
            "Epoch [49/50], Step [150/162], Loss: 1.2070, Accuracy: 90.62%\n",
            "Epoch [49/50], Step [160/162], Loss: 1.2244, Accuracy: 87.50%\n",
            "Epoch [50/50], Step [10/162], Loss: 1.1338, Accuracy: 93.75%\n",
            "Epoch [50/50], Step [20/162], Loss: 0.8616, Accuracy: 100.00%\n",
            "Epoch [50/50], Step [30/162], Loss: 0.9718, Accuracy: 96.88%\n",
            "Epoch [50/50], Step [40/162], Loss: 1.4206, Accuracy: 90.62%\n",
            "Epoch [50/50], Step [50/162], Loss: 1.8687, Accuracy: 84.38%\n",
            "Epoch [50/50], Step [60/162], Loss: 0.9904, Accuracy: 96.88%\n",
            "Epoch [50/50], Step [70/162], Loss: 1.4680, Accuracy: 84.38%\n",
            "Epoch [50/50], Step [80/162], Loss: 1.2058, Accuracy: 87.50%\n",
            "Epoch [50/50], Step [90/162], Loss: 0.8220, Accuracy: 100.00%\n",
            "Epoch [50/50], Step [100/162], Loss: 0.9333, Accuracy: 96.88%\n",
            "Epoch [50/50], Step [110/162], Loss: 1.2191, Accuracy: 90.62%\n",
            "Epoch [50/50], Step [120/162], Loss: 1.0012, Accuracy: 96.88%\n",
            "Epoch [50/50], Step [130/162], Loss: 1.1643, Accuracy: 90.62%\n",
            "Epoch [50/50], Step [140/162], Loss: 1.3354, Accuracy: 87.50%\n",
            "Epoch [50/50], Step [150/162], Loss: 1.1607, Accuracy: 96.88%\n",
            "Epoch [50/50], Step [160/162], Loss: 1.0552, Accuracy: 96.88%\n",
            "######## Training Finished in 7473.2746431827545 seconds ###########\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval() \n",
        "perds = []\n",
        "target = []\n",
        "with torch.no_grad(): \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in data_loader_test:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        perds.extend(predicted)\n",
        "        target.extend(labels)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Test Accuracy of the model on the {} test images: {} %'\n",
        "        .format(total, (correct / total) * 100))\n",
        "\n",
        "plt.plot(Accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HGLZz7-NTB31",
        "outputId": "d30bcd26-4e9f-47c1-8a10-efbf7e5ef72b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 1726 test images: 93.04750869061414 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3cb24da890>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZgcVbn/P6e7pyeZyTLJZM8kTDYTCEkghIRFAmENiywKiHAVEcUFveLC5tUfqBcuV1GuitcLihq9sgYwCAiGsAlcIwkJSQiQAEnIvk+WmczWfX5/dFV3dXVVdXVX9/R0z/t5nnmma39r+5633vOec5TWGkEQBKGyCJXaAEEQBKHwiLgLgiBUICLugiAIFYiIuyAIQgUi4i4IglCBREptAMCgQYN0Y2Njqc0QBEEoK5YuXbpLaz3YaVm3EPfGxkaWLFlSajMEQRDKCqXUBrdlEpYRBEGoQETcBUEQKhARd0EQhApExF0QBKECEXEXBEGoQLKKu1Lqt0qpHUqpVZZ5A5VSC5VSa43/A4z5Sin1c6XUe0qpFUqp6cU0XhAEQXDGj+f+e2Cubd5NwCKt9QRgkTENcDYwwfi7BvhVYcwUBEEQciGruGutXwb22GZfAMwzfs8DLrTM/4NO8A+gTik1vFDGCt2TF9/dwYLlm1m9Zb+v9ZvbOnl82SZf667esp+lG/YC8Myqrew62AbAc6u3s21fq+e2iz/YzU8XrmFfSwdLN+xNs8/P9ubxf7pwDRv3tNARi/Pw6xuJx527yX5m1VYWLN/MXQvX0NzWmZyvteaRJRtpbuvk4SXp26/esp83Ptybsa9YXPPw6xvpjMV58d0drNq8j7+8uSVt+X+/+B5PrdgKQFNLO0+uSCx/c2MTKzftS9tfU0s7f3lzC6++t4t1u5qznvcHOw/y2nu7ktNLN+zh7a3+7u+bG5tYsakpY/5fV25lt3H/IHF/Vm3exyNLNqK1zri+Ow+0sWD5ZuYv3YRX1+Qb97SwYPlmnlyxhVfW7mK97fzM69/WGWPrvkMsent7Vvvt18/Ez/ZOZLs/xSDfRkxDtdZbjd/bgKHG75HARst6m4x5W7GhlLqGhHfP6NGj8zRD6A589nevJ3+vv+PcrOv/2+Mr+fPyLYwd1Idpo+o81z3n538HYMWtZ/Kl/32DqQ39WXDtiXz+D0sYWdebV2861XXbT977DwBWbd7H8+/sSNqntfa1vfX497z0Pl87dTx3/m0NkbDi49Mb0tbbd6iDL/3vG8npzU2HuPOSaQAsensH189fwfXzVwAQUoqLj2lI27/9uj2yZCM3PbaSpkPt3P70O8n5R42qY9TAGh59YxM/euZdAOZMOot/fXA5L6/ZybSGOi745asZ+/zq/ct4xSLW2e7TqT95KW29T/zq/3xtBzgef19LB1/+0xtMG1XHgmtPBFL3B2BIv16s2ryPHz/7LuGQ4hPHNPC537/Oys0JERxYW8Wpk4bixGk/eYn2WDw5ffms0dx+0ZTk9LNvbeP6+Sv4YFczjyzZxK6DbZ7n4WS/yUW/fI1t+1t9XQcr2e5PMQhcoaoTRWrOI35ore/VWs/QWs8YPNix9axQoazf3QJAZzyeZc0UnbHEI/bhnhY6Dc9uc9MhX9tu2tuSNm06zn63B2jrjCfXP9QRy1hu9+Z3HEh5qPtbO9KWNbW0Zz3e3pbENjst+wFoNY59oDX1ZRDXsNWwraU90zbAl7deTGKG571ht7MdrR2x5Lk2HUqcu/X+7GnucNwOSBN2gPbO9Okm41ruPtiW/PLLd5CibfsTX3sxl6831+32Jc6lub0zy5qFI19x326GW4z/O4z5m4FRlvUajHmCkKTNePmqI2Hf21hfpo6Y/0LBiVwKFSutHYnteldltzusUr+Vcl8vG/aCxLwMUcsBYjFNOJSYdhMduwB2Naa1bvZFw5lSVGU5x1zuub2gNSdDlhuRozZnkOszWGWcX0dn1418l6+4PwFcafy+Elhgmf8ZI2vmOGCfJXwjCAC0dSYEK5SD6llfJvMFyVc089R2DhlesZO4d9rUwhRbAEX+6t7SZhf3xHGqLGIY05pI2FvcO0ss7qbn7lZfEQlnXiPrOeZiv/1emNcsZLkn+RbwJvmKe3vM+cuqGGSNuSulHgBOAQYppTYBtwB3AA8rpa4GNgCXGqs/DZwDvAe0AFcVwWahG+H2snphfjbHc/g0tr5Mphfqt3Cwm5i3524USr0cxN0uqlbbgnju9s94J3HvjMcJGwdxO7eOWP4eYz732G0fsRzuufUc23Ow334vzBCM8lgnV3K9nuaXiVvYrBhkFXet9adcFp3msK4Grg1qlFA+5PKymphhGbuH5UWa554Ud3/bttpCG/m+2OZ+Qg4HtouqkyeaD3YxMG23fhnE4qmwjFuBaY9D54JTHYMftNYoZdqVmOd27Z3ub75hGfu9cArLuD17fp+NnD33SOLYzZYvMev1KQbSQlUIRD5C2WaIRSwHD7q9M+V9mS+W14thrTCzC2QuhYqVQ0bM3akyzttzz/0FNjexplRCymO0iktnTBMJhZK/nQgSc8+3ErDNUqCYToBrnUCnThZMLcY5RyMpeerIoXCyHyMZlrHchpjLdfJbkOUblmmxXMti14N0i/7chdKw40ArvarC9OtV5bi8vTPO9v2tjBpYAySyPto64gzuW83Btk427G5mYG00bZvWjhi7m9vp37sqmRlRbbykrR1xlIL9RqaHVYhWbGqirTNOY30tg/tWs7npUJqImt7Y3paOZPZDSCVS7DrjiUyW1o447Z1xpo3qnxYXP2gRyAOtHWk52B/ubqE9FuOw+lqWrN/LYfU1jKjrzfs7D2ZktWw38uLjWnOwrZO12w9wsK2T6kiYdbsOpq1retIf7m7JCGts2N3Cxj0tDO5bnXb+0UiIxvpa9jS3s8XIFNm0Nz2jZ/nGJiYO68uG3akMoB0H2jC0Pa0ge2vLPvr1qqImmhlG2tx0iP1GVkp7Z5wJQ/tQE42wfX8rtdUpWdjf2pER91+1eR9xrfnI0L7JENW6Xc001tekZQm1tMeSy81MGLdydeOelqTtzcZ/a1hm6/5W9rV0sL+1gx0HWhk7qA+dcZ2sv7HS1hlnw+5mDquvRWvtmClkLeBb2jtZt6uZhrqajMwmrTXrd7cwZlAtkHjm4hrW7jhIR0wzZlAtW/cdojOm6de7itaOGLXVEfoY19Dc3ix8rTn4a7Yd5EBrB42DahlR19v5wgRAxL0HM/O2RdTXRln6vTMcl9/46AoeX7aZ1T84i5pohNk/eoGmlg7W33EuH/vFK44vzZf+dykvvruTxvqaZMqjG6aHtWF3M+ff/Wpy/rr/OIcT73g+bV2rp2TmCSsU037wt4z9XnViIzecNSk5bQ1JTLk1ff3ZP34BgE/NHM0D//yQCUP6sPCbJ3OakedtxUyDi8fh/F+8wgce6YVhpdi+v5XZP36Bof2q05b98R8b+OM/NnD64am8bfP8jzlsQLLRFqSnVAL88MnVPPDPD3lvR6ow+cSvXuPE8fUAXD0v1ebg3J+/4mqf/foe2ziAR750ArNuX8RYQ8gAZv/oBe7//HEpe/a3ct4vEvs9/fCh/ObKGWzY3cycO1/k/i/M4vJfL06u29zWmSz8L/xl6v7+fe1OTpqQnv5829Nvc86UYUDKu7WK+/2LP+Sh1xNNaLJ9Lf597S5O/vGLvPDtU3jx3R384f8S41m88WGqULfu45P3/IOVm/ehFHz55HFp+5r32npu/ctqFlx7ItNG1RFSirjWXGW07bj78qP56v3LAIiEFJ1xzUeG9uFv3zgZgPteWce/P/U2owYmxPvnz7+X3PfH7k5cxx9cMJnPHN/oeU75IGGZHs7uZveca7PhjymOpscM7nnTL767EyCrsEPKe7LmbEMq5dBKu0MKmVvMvbmtM+dP3sXrdgOwt6U9aw50XGtPYYdEKGaPcW23729zXGfRO5ktHa3C7oZV2E3ChmeYbz3h6+tTx7WeW1NLR1oc/4DlK8i03yyAzC8BE7fKwzXbDzpeY3N984vOnh4Zi+ucwoDb9rWyzCLo1i84a1zebCilder6NdYnvlaXb0xs/4HxZWavxLe2ejaf5zXbU/fHvJ8b97i3qTjziGE+zyg3RNwFV+LJLIPiVPqYL6o9Bu4U43WKcbply8TiucdE9xkFVziksgqInywfh7TtDKr8rOSTAtXfOmI9X2uIybTfrBewX7YWj1i90yU2wz/m9XequM4Va8Wz9Tzc7rG5jrnUnp9uf+RySed1w/5lVyhE3HsovlromasUSThMUbdXrNpjvOAs1m7vldlPCUCvKn+PuNkqsjOms2YA+XEewz6EyanhTr6YnnsxsAqh9dpU29L77IWeV9qfU8qmWainKl+DVTgq5S7ubpXqyZRN439VxMxPd06/zabt2ZZHQqpoGTMi7j2UNh/ZBzrjR2ExX157hodvz91FQONaJz2tut5Rx3UybUms3x6LZ23k5Cc0EFKKbOVnodIlwd+Xgvf2yrXAt56u9dxN4TM9d/vm9kwfE62dwyvJsIyxrBCtOSNWcbfcV3fP3VzXEHdje7f021zaajjhxwnIFxH3HoqfxhTmyx70AXYj6bn78PicCiPXsIyGDuNNrqtxzgRyoyMW9+G5+wnLqKyNpQoZlokE9NzDyj0clR6WSc0389DN9EG/nnssrh09Z7PuxUxTDJoqqHW6A5DmubukQprrmM9AMizjkn4btH2XiLtQcNy8Kivmc1sscY/ZPoFNnGK1bQ6VrG6vRdwSlunXOzdx74xlr7TzczlCSmWN+xc2LBNMJDrjcddWl3GXsIyJ2TAnw3N3ibm3tMcc88zNNMSk5x5Q3ONap3nu1vPLVpCZhzZz7c1t7f5Esd6NQiDi3kPx01jDfG4L0PrcEfMFs2fH7HHI4HGy197y1ESnhWVyFHcfGRl+MzacMnysFDYsE2xfce3+TLiFZQ61x4jFdbIwtl+Xg63O4n6oI+ZYSJhZWWa4zu3++qWtM5ZmkzUn/lBHzLHVrr1rjIjZJ0ync8zdTdv9FkzFLBwkz72b8PCSjdwwfwUrbj3TtVFRNr7yp6X8c91elnz39KzrWj33xpue4jPHH5bMB77kmAYeWZoaTOPDPc0ce9tzyelvP/JmXvbZ6Yxr3tzYxBf+sCRt/tcfXJ6xrpPwNLt89j+9chtPr9wGQH0ffzF3K9N/uNBz+bd8nP/vX1vP1n3eXQpv8JEu6peg4l4dCbme9yNLU0M0fOJXryV/72/tZOZtz3He1MR4PHZBu+u5NXzx5HH84C+r0+Y/vGQj9778gastL7y7k8abnsr5HOx87vfpz5U15fbSe/6PaCTEjXMnpa9jvBd7mtv5+aK1ya+Wny1ay+9fW88+W7qn23lM+Le/+mrrUSzHCcRz7zb89pV1AGxtyj46kBtPr9yW7K86G3avxRR2IE3YAf7xQfpAXPOX+htFKRuxuObDPZkP/6RhfTPmuXmB2Tj5I0N8rXfj3El8fPrInPY9fkgfzp3iPtDYK2t3uS4rBB8dPyj5OxJQ3CeP6Oe67LE33Hvt3t3cnsxzt4u7GXb67avr0uZb20tk47MnNHL82Hrf6+dCe2ecuxauSZvXZnEifrpwTdo52YU9G37aeuTbr7wfRNy7GV0Vw8ulV7sgnU550RnXjp+vR4+uY/yQPmnzzHjscWMHps0/4wjn0XkAjhjejwE+K1S/fMo4po7s77nOp2amjxj28ekjPXOx3b4sgmC24gT46ISUuAdJp5va0D+jIVkumF0L2HtubPX53HiJ98emjeCo0d6jdQXBXmlrDxEWu/+XYnruEpbpoeRSWRW0YsuNWCxOR8y7H2+T/Yc6qImGM5ZVecSta6vDaf2kZKMq4u3r2PuIKWSFqF+s55/er3z+KhEOqYw+VXLB/Fq097ne3hn39ez06+1+j6LhUEGziuzY7bP3VVOsZ9+kmM6ceO7dBLOipqsq33PxSIr1gHfGtWM/3Y7i3tpJTTSSEX7wevFrohF6O3Sa5UY2EbGn7xVTdNxwE/cg7X0iIcX+Q+6ee7Z4/k6XsAz4S7n1qmOqiqhkx3PFwP6+2VNuiz1yUjHfdxH3boL5Vd11YZlcutstkuce145duXp57vaWmF7ec000TG3Uv+eezRO3t5gstbhbu8TNp199k3BIeWZPZbsuZvjJWlCnBqfIHu7xSletCoc8v84KjT1Dp9ieezERce8mFLHPfkdyEvcAo/h44RZzjzq8zPtbTXFPn++VTlgTjVBTXTjP3X4Zii06Tl0nWK+NfcCOfMnWAMrveVrDMn16JQrVZoeuJOx4eu6h4oVlog5fBHbPvdRjzwYh0FVTSn1dKbVKKfWWUuo6Y95ApdRCpdRa4/+Awpha2RSrcy43cvncLFrM3UXcnT33TmqrIxlC5CVqtdVhanwMZp06rvc9sHvuTuJQSJyG87NeG2uIKogIZQu7+D1P6700+zO3e+5Oh/KKuVdFVNHEvdYhZGdvLNcjPXel1JHAF4CZwDTgPKXUeOAmYJHWegKwyJjuMbz2/i6uzyMP3BqW+d2r65j32vqMdR5ftomfPbc2Y/6L7+7glgWr0ubd/NgKfrFoLdc9uCytIrC1I8aX/riUd7cf8G1boVIf7fx04RoeWrIxY36vqnDGINTb9rcanrut4yaPQrF3NEwkHPIds81WoWrPSCl2yMAppGS1MWIRvadW5D8OfbY0yl0H3buFtmLNwDLF3dpPvxt9LZ67/Qu2KhxyLOQKQY3D9TX77Dd59q3MbpnLhSBF4uHAYq11i9a6E3gJ+DhwATDPWGcecGEwE8uLy3+9OCNP3A/mM601fP8vq7nlibcy1vnGQ29y13NrMuZ/9nevM8+Spw7wwD838pOFa/jz8i1paW7/XLeHZ97axn2vrLPvJi8+frRzbvh5U4czc8xAx2VWnPq5/pfjDuOGuRMz5n/y2FFJIYqGQ3z//MncePYkPntCY3IwBCtmAfHNMz6SnNdYX8Odl0xLW++rc8YDMK2hLi3V0BprvmLWaG4+O73BS1U4xL+dczifPaGR5755MlfMGs2njzss6zmbZEvTvGRGA+dOGc6dl0xj0rC+/PozM5hiSdc8YkQ/34WL0/U0sRaY1rTEcYNrnVYHEgNMXHf6hLR5Vi/XafQnyEz9mzlmYLIgADIK4qpwiI9NG85hRv/qTtRbRgP7r08exaRhfWmsr2HGYamggbXtxMXHNPDTS6e52uhF/xxbPJeSIOK+CjhJKVWvlKoBzgFGAUO11qYbsQ1wT0SuYHJunGBmyxTh2NZIRqE/M+3D7AFcduwo7r58Og9/8fic91dXU0XvaJiTJgzmtouOTFt23tQRSSE6ddIQrjyhkYG1UW49f7JjpZ/5Of/Fk8clX+5fXjGdi49pSFvvkhkNyXP57yuOSTbo+czxCaGeNWYgt100hUF90vvdrgor6vtUc+v5kxk/pA+3XTSFH16YbrMXv7xiuufyI0f0T9r7zHWzOeOIoRxjEaxoOMR3zjk8YztTq0+ZmBjtaProOr5yynjX41jrLaw2/fnaE123OWHcIK7+6Ji0edZny28o5YazJmJ96qsj6YIbDYeojoT54QXO1/V75x3BX79+UnL6wqNH8sx1s3nx+jnM//IJyfk/unhq8vedl0zj49MbqMkhTdbk5evneC4/fLh7YzArlx07Kudj50reee5a67eVUv8J/A1oBpYDMds6WinlqFdKqWuAawBGjx7ttEpZo3VulaQpzz24vNu9I+t0V8QQC9VnSq9Ipmdl7ttPRamTV+sUxskI9RiTZggkNcCy/zRMP4SzPCBOsfC0bJlwyDOkYnqm2epazQyk3lXhNC/aKWxhtc1+/tawjN9noCocSrMv03NP7MftPMPKXwMup3oDp5h7NqqzjA/glAzgRN9exW9iFOjp1Frfp7U+Rms9G9gLrAG2K6WGAxj/d7hse6/WeobWesbgwYOdVilrck1pNJ/PQnju9mNbCww//bgHpVAVYE4vkil4flIcrXaYl8BJB+yVtGYBYG6fHBnItm3QIixbRaZT61drgVUVUY6DdJhiZ9qfzWEwhbO2Opwmgl72hZWTuKeeLb993STE3eK52+65uR+3/YVDynW4RStOGUFehZcb2dJC/VY+982z/6hcCJotM8T4P5pEvP1+4AngSmOVK4EFQY5RruQq0taYe67YU+bsGSTW6Vy6HciXIC03refv6LkbL6mfeGmauOPcZSt4eO7GfPOSFWJINSvZhpFz8uyt51SVxXOP2MZV9RJIIKcGX6FQ5v7SxN3ntYpGlM1zT7fBLKjcvgRCIZX3qFe1OaTJWo/nhV/Hpis896BHeFQpVQ90ANdqrZuUUncADyulrgY2AJcGNbIcyd1zN4Qkj3zlXlXhtD4x7Pvo6rBMoTx3rywJP15X1Mlzd/C37QJpTiXDMgUc09OKXQCrwiqt8HVKP7enQnoJm+nlm89iWCliDm5HJIevoaTtDse12p6L5279snDLbHIrWBPhz+zHqopkrpNPhWrW4/h89u3ZYMUgkLhrrU9ymLcbOC3IfiuBnOtTjf9uAxx40bsqTBOpvkHso8xYX55DRejMyk7hxD1zP2Y+tx+vy/pCm1fASQcyRNv0FkP5F7h+sAtgr0iYjljq/jt5v9ZtlFKesW3zPpjmu2mguc9cxM7JNqvjkFvM3dKy1UXc3RpaxbX2FZZxeibzCcvkcxwnCu0oOB6j6EeoIB5duolt+1r54z82pHX/+cHOg/zvPzbwwD8/TM7LM1kmY3Do5RubePW9Xa4C8/tX17F1X3puboetsc1TK7fywc6Dif3nUXjkipOXlA9OnrvZyMTPi5keczfCMj6Oa64TtVWoFppso/r48X69Pff0mLtbCCcVc/cvdk7i9HdLF8d+B+yuCofS+sVx89zdzjMW176uk5Po5lOhmo2oz2ffb9gqCCLuPjnQ2sG3HnmT4/5jEd/78yq+9+dUo6FTf/IS3/3zKm5+bGVyXs5hGUNS7H18XPjLV7niN4szeqsD2LC7mVttAyFAZujl+39Zzak/eclx/0G5ZMYovntuejreeVNGJH9fPstfJpSTlz7WIc/65ImDqa+Ncvjw9D7fbzr7cPpWR9LEwSpm5vKGAYl86a+flsjRrq+NZrzk5ns3dlAf+lRH+PaZzjnik126CL7gqBHMnZzKl//OOZOYNKwvn7elDo4ZlH5+9i6C/Xh3Xp7iuCG19KmOcP1ZCfu/Mmc8Q/tVc+6U4YweWMNRo+r44uyxHDmyP72qQsk0y4uOHpm1b/ts4lTlYHtfh8IjGg5xkqXr4mmj6pIhC2vap9uXQCyufdWF1EbDTBrWl4ss7TJ6+RT3Ro8ceztOsf3qSIhoOJSWqx8JK2aNGciXTxnne9+5Il3++sTe697BLGOQ5uztGc+nvYm7iVNFqFvmi9vgv/ZlowfWOA6W4YcTxtVz/xeOA2DisL48tXIryz5s4k+fn8Voy0N8+0VTuH9x4ovmsyc08vvX1vOdcyZx+9PvJNcZP6QP8z43kxPveD7tGDXRCIu/cxqzbl+UnHf+tBGcP20Eds44Yigrv38WU299NnldrC+9udzkG2d8hG9YGjdZMbfqVRVilWUbK+vvONdxPsDPLjuaWFwz7jtPA3DN7HFcMzvxEn/3vCOSowzVRCN8csYox1a64M+7c4qTm1v1qY6k2X/tnPFcO8c53/2SGam867s+eVTW47oVPOa9dfKmV37/LMbe/FRaHVBVRNG/phdjB9Xywa5mLpg2kpvPzszdd/POE2GZ7NcpEg7xzHWz0+bZhfjYxgG8vn4vkLi/Z/z0JdbuOMi1c8Zz/fwVWY8B6YXtLz51NF97YBnD+vfipevn8LUHliVH3+pTHeGhPNqB5IJ47nni5GlayTVMaz6eTqPCg3NFaD7jN7anNTQp3KehaYvXi+a1zE3Ich1hyHpJ8s1uMSvoggRj/FYoejkBfvbhle8fdOg9L9z2bcbG3S69/fG2x9LdPHS35yAWd+6vxg/2rx77OZn3Jpc+hKzdQ9ifP+upFSPeb0fEPU+c0vTSyDPm7uZ1O4q7y0G80h3zaUXoB/OIXoLi9RK6hWiz9feSYYfl1H2GfTMIkpaaK16H8BducBeJoEPveeFWGKcydPztx+5guJ1zUM/d+di2gsX2wJj3P5f3xPo1YJqsktMpO/NJw8wVEXe/2J6fbC3V8o25u3ruDr045uO5W/dT0N72zHQ7H7t0Skc0H3z7e5przrz1uuc79FyyQVkXqLvXc+KncHLKcDGfIb+VmvngdmkjyQwdf9fOfo9c9+uWLRPXeWee2AsW+1eDeQ45ibvFGbGfm9XOYqRh2hFx94vtWbU3trCTbwtV+1BlJk5duuYl7sUKyxj/8/GilMd2uRZAaZ57vuJO8LCMX7weEz8xdy+RKOZYIu5hGePaFfjiuWbLBDiQPdxi/9KJJz13/8+Ro+du3Efr/ZSwTDfCHgLJ1g1pzi1UTXHPJebuchS3fYA95p7/7bfrjp+Yuxsa9xTFXOPG1kI176hE0nPPc/sc8Po68OOReqUvFtNzdw/LFCd91C3EZB/XNhf8xtxzeU+qwu4xd+v9zKXBWL6IuDuwfX8r2239Oq/cvC9t2qxQdXu44lqzctM+dh5oY0tToltbbcxzwvQW3fLZreK+fX8rr723i4MuI9Y/u2qb4/w12w+wbldzcjrIYBP2d9ereX9XUpAK1eS+uiIs477Mj+fu1Vd9MXOp3Qqe1LgEhT1e2C0VMkAhkk3c84m5W9t42MtW625y6eohX0TcHZh1+6K09LulG/bw6fv+mbaOecPd+kVfuHo7H7v7FY697TlOMFL8Hlm6iY/d/Qp/eytTfLOFZaziPuv2RVz+m8X8y32LHdf9jYtNZ971Mm9t2Z+c9jsIgx+8mvefNmkIAMcZfYVPG1XHsY2pHOaPTR2RfNgvPMo5v/r0w/31HG31hEcP9J+fbOUsI0d91ADn7a39hGdj4tC+GfOqwqlBn0/+yOCMdaePrgPcxxaNRkLJXHCneoXzpg4H8OwDPV/sOd9D+6V3g2wWqKbXa3a1fMYRift34TPqAv8AACAASURBVFGZaayQsnlgTWYX0pAYbs+KGf6Y0Zh9zAA37OGWUz4yJG065bkn1hvWr1fWfVrDtea9MY/y0fGpe13sUbxA8tx9sWlv5oASpois3ro/YxnAezsOZsx7Z2ti9COv3HK3kEq7Q4Vq0E7AmrPk6ueCV6+L93z6GNo649RWR3jzljPp37uK+79wHB2xOB0xTd/qCKGQYuWtZzrGIt/6/lm+Xwbz8j33zdmMylPcrzqxkU8c0+A4MMPqH5zl25N7+wdznfO9b03lnn/imAbmTBpCdSQxVqj55bbvUIdjX/kAK245M23azGWvCita2+P06x3h9o9P8RybNF9+culRaQNfvHzDHLSGSd97BkiJu9Y6ef4dsXiyMLvzkml89dTxnP7Tl9P2e93pH+Hzs8e62mz/Qpk1diB3Xz490OAZZgExaVhfHvri8dRGw9zwaCqf3RqWeeeHc12/StfedjbH3vYcTS0d9LFkwdi/HOceOYxl3zsj5wywfBFxz5Ns/W85hVfc+gWH7B2HFaPDr0Lu06uYiYRDySwK82VMDFGX/pC7dYOaS7N4s9Ad4OIB+kEp5SoauVSEuX162+trnETc67Pdvn36SEaJZcUQdkgIYq3D8UzMsiweT51D1DY0oH3QE0iEebxsdgoDBR0VySqy/XtXZdR/mK9iNOI91F9VOMSoATU0teyjT3XKJqfI1QCXArsYSFjGB05hvWyxPicPPJZMUXMQd+O/mzdeSCE2P+kLKu5m3y0ljrmbl90tdU4IRrb7q2xhGSe6otMsP9idC3uIS+dRoVrr5LmX6HTlDfCBU8WaWZHqdt9iDj0zxpKee+b65nPg3v1AAcU9aop74SsMvQas7krcKuCEYGSrpE567gEriruCbI28ckmFNDXC6lSU+jRF3G34bbiSzXO3L2/rjCf37eS5JD13t5h7AYXYfFgL67kn/pf6gTYpZuvMnky2DyJrzN2NYnaLkAvZCqpk9wM+PPdkKrBl1ZCtQrWrEXG34bexULb8Wvvy5rbOVFjGK+buFpYp4PB45mdmYWPu3SMsY9JdBKTSyOq5G4riGZbpLg9JFsx3OJewjPXcSn2eIu427P2pg0vMPYu422PuLe2xZCWsk+duznLLlilkV70pcc//ayAjz90jFbIUdJdP/0ojW5mZirm7r9NdCt5s7RhS3riPsIxDI75Sn6aIu40WnyKaLSzzxJtb0qZP+tELSW/mhvkraLzpKRpveooL7n6FKbc8i/nx9ugbmxz3d8/L7/uyyw9mrvIRw/u5rpMt9XD8kD5p0xON9Liu6BDJi8ONc+oulXaVRrbMpXojG8TeV70V89Yc7vH8ZWPc4D7ZV8qCmZ0zcVh6WwSzS4fJIxP2+QrLGP+tqybz3EvkaARKhVRKfQP4PIlzWwlcBQwHHgTqgaXAp7XWhWstU2ScwiJOMp5Ps2cnb/9NlxardhIpVpn59nYmDevLO9sS+fTTGvpn7P+I4f3494umsG1fK2MH1XL0Dxcml51xxFBOHFfPkSP7M2pgDUvW7+Xa+9/IOMZJEwbx3fPS+9z+0cVTuWLWYcnBMErF/Z+fxQeWVrhCMF6+fg5b9pktrGF4/96e609tqOOPV89k5hj3xkVKKR798vE5C/QrN87hYFsnOw+0ee7fykvXn+Iafhw1sIb7vzCLo0elGqU9+bWPMqRvIlXznk/PYM32Axlpqc9/62SUUrR2xDLSMZVSLPrWyYSUoqmltLKXt7grpUYC/wocobU+pJR6GLgMOAe4S2v9oFLqf4CrgV8VxNouwClW6FQ5FEvFIXzT4jF+qZOjaT2u3/j4nElDkuJ++uFDM8T90hkNjKzrzci6zJf0ilmjOWViqpXeFJeRhk4cPygjv7kmGuH4cfW+bCwmA2qjHNOFucSVzuj6mrTBV/xw0oTBWdc55rDcW5aajsOkYVlWtHBYvfsXBMAJ4walTR9peeb7967iWIcWsGMdCiVtacNiFlpvbuzIWK8rCRqWiQC9lVIRoAbYCpwKzDeWzwMuDHiMLsWvP55PXeTBNveb7fTlZi1T2n1WqFpjzRGHz0mv1nH2z08JWwtCboQdKlTLLltGa70ZuBP4kISo7yMRhmnSWpvt2jcBjp2FKKWuUUotUUot2blzZ75mFBxHz91pvTzCMgdcOvpywxrX9yvu1i8Ap/xcr5p/u/C7dg7lyxJB6Dk4pQKX2jnKW9yVUgOAC4AxwAigFpjrd3ut9b1a6xla6xmDB2f/jOsqHPNz82ih6oSXuDuNwGQtaJxSNLPhlOvtVTlU0ME7BKEHYs0EchuApqsI8jafDqzTWu/UWncAjwEnAnVGmAagAdgc0MYuxa9Dno/n7jWotlOqoz0s4yeFzFrohJ3CMp7ibuvP2uUcS+2RCEJ3w6mdR6l7wAhy+A+B45RSNSqR63MasBp4AbjYWOdKYEEwE7sWZ8fdo0I1Bw60usfcnSpbrdk17Z1xX82grQ5+lUNh4LUPu1fvNeiHIAgpuls7DwiQLaO1XqyUmg+8AXQCy4B7gaeAB5VS/27Mu68QhhaSn/ztXeJac/1ZkzKWff3BZRnzbnx0Zca8Bcu30NoRS+sFLhtejYaWb2zKmDf5lmeTv9tjcfpVRWjt8A7PWAuiXCtU7V69WxNyCd8IgjNOX7WlEvxAee5a61uAW2yzPwBmBtlvsfnF8+8BOIq7mUboh2ff2s4npjcUzK5seInq//zLdF54ZyeXHNPAPS99YKyfY8zdJvxjBtXyxZPHsutAe7Jx1VdOGcfls0bnY74gFI1fXTHddXCTrsB0g6xvXFcM0+iF9OeeBbeRkYrBqIG92bjHvaGSl7jPPXI4c49MjGYTDilice3Y7W0uMXelFDefnWisZIr7DXMzC0RBKDVnTxle0uM7dXld6s705Ps6C367IygE2T7f/I5GZPbX7lQBG8kh5i4IQvkib3MWnDoSs1LIUjlbMoyfClVIDd7ttL5XV7gSSxeE/EhFYJRlXmnjMvI2Z6G5vXDjjGYjWwdD0Yi/Trl6eXjuXt2QirgLQp54hGBK1XGYvM1ZyOa5F5Jsj0DUp+duhmWcOirzes78fhkIgtD9EXHPQkuXeu7ey/161qbn3uyQO+/luZfKwxCEcscpAFPqbBkRd+DRpZt4Z9t+x2VePTkCzF/q3P96Puw75N2LXK4Vqs0OLWJLPTqMIFQiyWwZh2Vl13FYJfGtR95k7n/93XFZoUZA6t+7yrGbXSu7Dnr3/+wk7udNHc4nZ4xKm3fzOZMYM6iWuZMz+0Y9zNZ961fnjEcpOKEbdNcrlC+Xzmjgq3PGl9qMkvHDC49k/JA+jByQesfHD+nD2EG1GWMfdBWS554Fp37UT/7IYF5a478ny9MPH8pvrpwBQONNT2Us71sd4YBLvzPfOWcStz/9DkBG3vo9nz6GsxwE/OjRA3jh26cAcOYRQ/nb6u0APPfN2cmQjcm3z5rIt8+a6PtcBMGJH108rdQmlJSTJgzmuW+enDavV1WY5433sBSI554Fp652C51V4jUknHVQDHt3xH5CLN1pwF5BELoOEfcsOPUHE43kKpLeNStevT2aOeuQ2ZGXn2FCrc6+iLsg9BxE3C04dZTVGc/03AvdktNb3C2ee4a4Zxdra6tXEXdB6Dn0eHG3CrpTXrhTWMZv1krqGN7LvVqNWsMy9vi/H63uTv1LC4LQdfT4192q507dlzuHZXIU9yzLvTxqa1jGXvj4yUuXmLsg9EwqXty3NB1i3a5mx2Wvvb+LjXtaktMb97ZkLHf03MP+ugEwcesX3cSrMy9rWMYec/cj1Wmeu4i7IPQYKj4V8oQ7ngdg/R3nAulCe/mvF6ete9pPXkqbvvzXi+nbK/MS5eq5ZxvQKOzpuafE/czJQ9MG9fCj1XMnD2PB8i1AsLBMNByiYYB3nr4gCN2Hihd3O05xdS8OtHYSDYfSBqjOXdwLky3zsakj+NEz7+Z0bGs/10E897d/OLcbDSAmCEI28vbllFITlVLLLX/7lVLXKaUGKqUWKqXWGv8HFNLgoOQzLqhdzKsLXKHqJe7WClU/A2R7HieAuIdDyjMfXxCE7kXe4q61fldrfZTW+ijgGKAFeBy4CViktZ4ALDKmuw25eu6Q2VtirqmQ2Tx3vxWqXlk1fpCYuyD0HApVoXoa8L7WegNwATDPmD8PuLBAxygI+Xju9haphQ7LeNGrgJ67qvjqc0EQTAr1ul8GPGD8Hqq13mr83gYMddpAKXWNUmqJUmrJzp3++2kJSn6ee1Bx917utdhaoeo0JmouBAnLCIJQXgQWd6VUFDgfeMS+TCdSUxy1S2t9r9Z6htZ6xuDBg4Oa4RunFqfZsIt5rmGZbKmQXsutIaFwwME0JCwjCD2HQnjuZwNvaK23G9PblVLDAYz/OwpwjJzoiMUde3OEAsXcC+y5e2EV5KAxd9F2Qeg5FELcP0UqJAPwBHCl8ftKYEEBjpETx972HEf/YKHjsk6HFqfZsIdDco19Wz3zo0fXea473bbczFAZM6g2eLaMZLsIQo8hkLgrpWqBM4DHLLPvAM5QSq0FTjemu5Smlg4OuvSPnk/dZm11eovUkFI8c91J/O6qY123eeia45K/rZ77Hz43k7svP9rVpnmfm8lfv35S2vKF35jN4185IXDMXMIygtBzCNSISWvdDNTb5u0mkT3TLcknc6Ummn6ZwiHFpGH9mDSsX9r8QX2iydGUpjT0T863eu59e1UxdaS79963VxWHD69KmzdhaN+cbXZCHHdB6Dn0uOS4fMTd7rm71adas2qsXe3aY+5Vtv7gddauxQqDDIAtCD2HHijuuW/Tuyrdc3cLb1g7ALOuYi9Q7KmVpR4lXRCEyqPHiXu2tEQnMj13F3F3yUPP8NwLPNiHIAiCnR6nMvl47hkxdzfPPeTsudsLFHuevDjugiAUmh4o7nl47lFbtoyb5+4ac9e29Wwxd4nLCIJQYCpG3L/x0HK+/5e3XJfH4ppTfvwCT67YkvO+a6ojaQ2Z3BoTVbnE3Pv3Ts9+sW9fVxPN2abE8Srm9gmCUGAqpj/3x5dtBuCWj012XN7c3sn63S388oX3c953bTRMOKToiGnOmTKMI0f2d1wvPVsmxS+vmJ62nlKKH188lWMbB/LSmp2cPWUYq7fsp7Y6dTue+tePsn5X+shQAP99xXTqaqpYvWU/s8YM9GX/c9+czarN+32tKwhCZVAx4p6NbEmAdTVVNLV0OC6rqY5QFQrRSpybzz48rTMvK9ZYvDXtcEjfXhnrXjJjFACNg2oT60xMX2fyiP5MHpFZiJxjDL5xwrhBXqeTxvghfRk/pDC58oIglAc95rs+W0WqV+vN2mg42WmX31RxySgXBKGU9Bxxz6LuXq03a6KRZJqjV0Mg6yJpLyQIQinpMeIey5KR4iXaNdGwrx4Z08Vd1F0QhNLRc8Q9i+fu1SlXbXU4mb4Y8+hVUjrmEgShu9BjxL2903uQDi/HvFdVOJkJ4zXYh2i7IAjdhYoW97e3ptL/so2d6hVGiUZCyS4H8hmDVRAEoaupaHE/+2d/T/52G5kJYPKIfhw/rt5x2RHD+1FfW82dl0zjpAmDaKyvdd1PSCkunzWaOy+Zlr/RgiAIBaCixd2Kl7g/9pUTqHYZOu+3nz2WcEhx1Kg6/nj1rKxD7N1+0RQuPqYhkK2CIAhB6THi7jW8XkgpWjucxT+XOLpkyAiC0F3oMeLu5bmHlKK1M+a4LCdxz9UoQRCEIhF0DNU6pdR8pdQ7Sqm3lVLHK6UGKqUWKqXWGv8HFMrYIHR4eu7Q5uK555LeKI67IAjdhaCe+8+AZ7TWk4BpwNvATcAirfUEYJExXXK8UxgVbS6eey7iLnnugiB0F/IWd6VUf2A2cB+A1rpda90EXADMM1abB1wY1MhC4BWWAWjtcAnL5HAMkXZBELoLQTz3McBO4HdKqWVKqd8opWqBoVrrrcY624ChThsrpa5RSi1RSi3ZuXNnADP88cf/2+C53K1CVcIygiCUI0HEPQJMB36ltT4aaMYWgtGJIYYcg91a63u11jO01jMGDx4cwAx/vPCudwFy+azRjvNVTldI1F0QhO5BEHHfBGzSWi82pueTEPvtSqnhAMb/HcFM7Bo+NXM06+84l/V3nMuNcycl5+cUlhFtFwShm5C3uGuttwEblVITjVmnAauBJ4ArjXlXAgsCWVgCrCKdU1imCLYIgiDkQ9CRmL4G/EkpFQU+AK4iUWA8rJS6GtgAXBrwGF2OVaQlW0YQhHIkkLhrrZcDMxwWnRZkv6Um30E3RNsFQegu9JgWqrmgLL67iLsgCOWIiLsD+cfcRd0FQegeVJy4H2zrLOj+coqji7YLgtBNqDhxP/KWZ9Omh/fvlfM+rL075qLX0xr653wsQRCEYhA0W6bbc9WJjdz+9DsZ839/1bF89nevO25jFfRsjvsb3zuDjlicvS3tTBzaN4ClgiAIhaPixT0adv44mTSsn+s26dky3uo+sDYKwNB+uX8hCIIgFIuKC8vYqXIZOclrQGzJVxcEodypfHF38dy9PHLRdkEQyp2KF3e3sIyX5y7aLghCuVPx4u7muXuGXsR1FwShzOkB4u4s1F7iLtIuCEK5U/HiHo2EiDpUqnr10y6OuyAI5U5Fp0JOHtGPmWMGsvAbs1m8bg9L1u/h4SWbgGyeu6i7IAjlTUWL+7+eNoGaaITD6iMcVl/LEcP7WcTdfTvx3AVBKHcqOixj1+ja6lRZJjF3QRAqmcoWd5uA10TDlmVe2xXLIkEQhK6hosXdjlXcJeYuCEIlEyjmrpRaDxwAYkCn1nqGUmog8BDQCKwHLtVa7w1mZp722aZrov7CMqLtgiCUO4Xw3OdorY/SWpvD7d0ELNJaTwAWGdMlwa7fYUstqpd+i7YLglDuFCMscwEwz/g9D7iwCMcIjHfMXeRdEITyJmgqpAb+ppTSwD1a63uBoVrrrcbybcBQpw2VUtcA1wCMHj06oBnOOGn0l08Zx56D7Z4C7tJjQc7cOHcSDQN6F2ZngiAIORBU3D+qtd6slBoCLFRKpY2KobXWhvBnYBQE9wLMmDHDcZ2gOFWM3jh3UtbtwqHCqPuXTxlXkP0IgiDkSiAV01pvNv7vAB4HZgLblVLDAYz/O4IamTd5RlciXi2cBEEQyoC8xV0pVauU6mv+Bs4EVgFPAFcaq10JLAhqZFcTFnEXBKHMCRKWGQo8bsSuI8D9WutnlFKvAw8rpa4GNgCXBjfTG62dozr5SrR47oIglDt5i7vW+gNgmsP83cBpQYzK3Rbn+flmvYjnLghCuVMRLVTjbuqeJ5ECVagKgiCUiopQMTdpz9f/Fs9dEIRypyK6/LU77vW1UXY3t3P48H6e2x1WX8PUhrqM+RGX0ZsEQRDKhcoQd8N3rworOmKaMycP5T8+PjXrdi9dP8dxvnjugiCUO5URljE891RnYMHEWbJlBEEodypK3E2PO2jXMOK5C4JQ7lSGuBthmbCh6kGlWbJlBEEodypCxUzP3fTYxXMXBKGnUxnibvwvlChLzF0QhHKn7MVda82Hu1sAS8w9YGBGPHdBEMqdshf3Py3+kHN+/ncglS0TNCwjee6CIJQ7ZS/ur72/K/k7VKAKVfHcBUEod8pe3Fs74snfqVTIoHnuZX9ZBEHo4ZS9irV2xJK/CzX0qXjugiCUO2Uv7m2dKc89VCB1l2wZQRDKnbIXdyfPXfLcBUHo6VSWuCf/S98ygiD0bAKLu1IqrJRappR60pgeo5RarJR6Tyn1kFIqGtxMd6wVqimbgu1TPHdBEMqdQnjuXwfetkz/J3CX1no8sBe4ugDHcKS1I8bmpkMZ84NKs5ltM7Kud8A9CYIglIZA4q6UagDOBX5jTCvgVGC+sco84MIgx/DiYFuni13B9/37q47lsa+cEHxHgiAIJSDoYB3/BdwA9DWm64EmrbWpupuAkU4bKqWuAa4BGD16dF4Ht4+dqlRh8twBTpk4JPA+BEEQSkXenrtS6jxgh9Z6aT7ba63v1VrP0FrPGDx4cF422IfXi8UTMyRiLghCTyeI534icL5S6hygF9AP+BlQp5SKGN57A7A5uJnOmGJu0hnLrFwVBEHoieTtuWutb9ZaN2itG4HLgOe11lcALwAXG6tdCSwIbKUL9rBMe8zs2L1YRxQEQSgPipHnfiPwTaXUeyRi8PcV4RhAZlimw/Dcg+a5C4IglDtBK1QB0Fq/CLxo/P4AmFmI/WbDHpZJxtxF2wVB6OGUdQvVzLCM6bkLgiD0bCpK3JNhGVF3QRB6OGUu7unT9hi8IAhCT6XMxd1ZzaVCVRCEnk5Zi7u9QtVEwjKCIPR0ylrc3cIwheh+QBAEoZwpa3F39dy72A5BEITuRlmLu1vMXRAEoadT5uLuPF+iMoIg9HTKXNzT1f3E8fWAZMsIgiCUt7jbXPfpowcA4rkLgiCUt7i7NGISbRcEoadT5uKeru4a6ThMEAQBKk3cJXlGEAQBKHNxt+e5m1PSiEkQhJ5OWYu73VMXz10QBCFBWYu7a8dh4rgLgtDDKWtxt4ZlTpowiGMbE6mQRzXUlcokQRCEbkHew+wppXoBLwPVxn7ma61vUUqNAR4kMX7qUuDTWuv2Qhhrx9T2h645jqNHDyAaCfHG985gYG20GIcTBEEoG4J47m3AqVrracBRwFyl1HHAfwJ3aa3HA3uBq4Ob6YwZlulfU0U0kjgVEXZBEIQA4q4THDQmq4w/DZwKzDfmzwMuDGShB6a4hyXILgiCkEagmLtSKqyUWg7sABYC7wNNWutOY5VNwEiXba9RSi1RSi3ZuXNnXsc3wzKS+igIgpBOIHHXWse01kcBDcBMYFIO296rtZ6htZ4xePDgvI5v9i0TEm0XBEFIoyDZMlrrJuAF4HigTillVtQ2AJsLcQwnkmEZUXdBEIQ08hZ3pdRgpVSd8bs3cAbwNgmRv9hY7UpgQVAj3TDDMiEJywiCIKSRdyokMByYp5QKkygkHtZaP6mUWg08qJT6d2AZcF8B7HTEDMuItguCIKSTt7hrrVcARzvM/4BE/L3oSFhGEATBmfJuoarNClURd0EQBCtlLe4ScxcEQXCmrMVda0mFFARBcKKsxT0Wl7CMIAiCE2Ut7smwjLjugiAIaZS3uEsLVUEQBEfKW9wlFVIQBMGRshb3MYNqOXfKcBF3QRAEG0FaqJacMycP48zJw0pthiAIQrejrD13QRAEwRkRd0EQhApExF0QBKECEXEXBEGoQETcBUEQKhARd0EQhApExF0QBKECEXEXBEGoQJTZbW5JjVBqJ7Ahz80HAbsKaE6hELtyp7vaJnblhtiVG0HsOkxrPdhpQbcQ9yAopZZorWeU2g47YlfudFfbxK7cELtyo1h2SVhGEAShAhFxFwRBqEAqQdzvLbUBLohdudNdbRO7ckPsyo2i2FX2MXdBEAQhk0rw3AVBEAQbIu6CIAgVSFmLu1JqrlLqXaXUe0qpm7r42L9VSu1QSq2yzBuolFqolFpr/B9gzFdKqZ8bdq5QSk0vol2jlFIvKKVWK6XeUkp9vTvYppTqpZT6p1LqTcOu7xvzxyilFhvHf0gpFTXmVxvT7xnLG4thl8W+sFJqmVLqye5il1JqvVJqpVJquVJqiTGvOzxjdUqp+Uqpd5RSbyulji+1XUqpicZ1Mv/2K6WuK7VdxrG+YTzzq5RSDxjvQvGfL611Wf4BYeB9YCwQBd4EjujC488GpgOrLPN+BNxk/L4J+E/j9znAXwEFHAcsLqJdw4Hpxu++wBrgiFLbZuy/j/G7ClhsHO9h4DJj/v8AXzZ+fwX4H+P3ZcBDRb6f3wTuB540pktuF7AeGGSb1x2esXnA543fUaCuO9hlsS8MbAMOK7VdwEhgHdDb8lx9tiuer6Je5CLfwOOBZy3TNwM3d7ENjaSL+7vAcOP3cOBd4/c9wKec1usCGxcAZ3Qn24Aa4A1gFomWeRH7PQWeBY43fkeM9VSR7GkAFgGnAk8aL3x3sGs9meJe0vsI9DfESnUnu2y2nAm82h3sIiHuG4GBxvPyJHBWVzxf5RyWMS+aySZjXikZqrXeavzeBgw1fpfEVuOT7mgSXnLJbTNCH8uBHcBCEl9eTVrrTodjJ+0ylu8D6othF/BfwA1A3Jiu7yZ2aeBvSqmlSqlrjHmlvo9jgJ3A74ww1m+UUrXdwC4rlwEPGL9LapfWejNwJ/AhsJXE87KULni+ylncuzU6UfSWLM9UKdUHeBS4Tmu937qsVLZprWNa66NIeMozgUldbYMdpdR5wA6t9dJS2+LAR7XW04GzgWuVUrOtC0t0HyMkwpG/0lofDTSTCHeU2i4AjNj1+cAj9mWlsMuI8V9AolAcAdQCc7vi2OUs7puBUZbpBmNeKdmulBoOYPzfYczvUluVUlUkhP1PWuvHupNtAFrrJuAFEp+jdUqpiMOxk3YZy/sDu4tgzonA+Uqp9cCDJEIzP+sGdpleH1rrHcDjJArEUt/HTcAmrfViY3o+CbEvtV0mZwNvaK23G9Oltut0YJ3WeqfWugN4jMQzV/Tnq5zF/XVgglHrHCXxKfZEiW16ArjS+H0liXi3Of8zRg39ccA+y6diQVFKKeA+4G2t9U+7i21KqcFKqTrjd28S9QBvkxD5i13sMu29GHje8LwKitb6Zq11g9a6kcQz9LzW+opS26WUqlVK9TV/k4gjr6LE91FrvQ3YqJSaaMw6DVhdarssfIpUSMY8fint+hA4TilVY7yb5vUq/vNVzIqNYv+RqPFeQyJ2+29dfOwHSMTQOkh4M1eTiI0tAtYCzwEDjXUV8EvDzpXAjCLa9VESn54rgOXG3zmltg2YCiwz7FoF/D9j/ljgn8B7JD6lq435vYzp94zlY7vgnp5CKlumpHYZx3/T+HvLfL5LfR+NYx0FLDHu5Z+BAd3ErloSXER1QgAAAFJJREFUXm5/y7zuYNf3gXeM5/6PQHVXPF/S/YAgCEIFUs5hGUEQBMEFEXdBEIQKRMRdEAShAhFxFwRBqEBE3AVBECoQEXdBEIQKRMRdEAShAvn/o/zUR2xyYQMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "sdSM9uiydwoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e4e53f-ea2b-48be-d84e-7f00318cc26c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional import precision_recall\n",
        "from torchmetrics import F1Score\n",
        "from torchmetrics import ConfusionMatrix\n",
        "perds1 = torch.stack(perds)\n",
        "target1 = torch.stack(target)\n",
        "f1 = F1Score(num_classes=3).to(device)\n",
        "print(f1(perds1, target1))\n",
        "print(precision_recall(perds1, target1, average='macro', num_classes=3))\n",
        "confmat = ConfusionMatrix(num_classes=3).to(device)\n",
        "confmat(perds1, target1)"
      ],
      "metadata": {
        "id": "VVfQzdWLdwkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05bdd1b-e482-40ae-9414-d646d72dfc8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9305, device='cuda:0')\n",
            "(tensor(0.9356, device='cuda:0'), tensor(0.9290, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[538,  27,   2],\n",
              "        [ 18, 588,   4],\n",
              "        [ 21,  48, 480]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "We6bEeLsCKmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}